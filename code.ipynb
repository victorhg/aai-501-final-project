{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import os # file \n",
    "import shutil\n",
    "import cv2 # opencv for images\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from ultralytics import YOLO #for obeject detection\n",
    "import albumentations as A # for image augmentation\n",
    "from albumentations.pytorch import ToTensorV2 # for image formating\n",
    "# from tqdm import tqdm  # to show processing progress\n",
    "# Suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing directory: datasets/images/train\n",
      "Recreated directory: datasets/images/train\n",
      "Deleted existing directory: datasets/images/valid\n",
      "Recreated directory: datasets/images/valid\n",
      "Deleted existing directory: datasets/images/test\n",
      "Recreated directory: datasets/images/test\n",
      "Deleted existing directory: datasets/labels/train\n",
      "Recreated directory: datasets/labels/train\n",
      "Deleted existing directory: datasets/labels/valid\n",
      "Recreated directory: datasets/labels/valid\n",
      "Deleted existing directory: datasets/labels/test\n",
      "Recreated directory: datasets/labels/test\n",
      "Directories reset and ready for use.\n"
     ]
    }
   ],
   "source": [
    "# create direcories to organize images and cleanup for a new to avoid duplicate images \n",
    "def reset_directories(directories):\n",
    "    \"\"\"\n",
    "    Check if the specified directories exist. If they do, delete them and recreate them.\n",
    "    Ensures the directories are clean before use.\n",
    "\n",
    "    Parameters:\n",
    "        directories (list): List of directories to reset.\n",
    "    \"\"\"\n",
    "    for dir_path in directories:\n",
    "        if os.path.exists(dir_path):\n",
    "            # delete the directory and all its contents\n",
    "            try:\n",
    "                shutil.rmtree(dir_path)\n",
    "                print(f\"Deleted existing directory: {dir_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to delete {dir_path}. Reason: {e}\")\n",
    "        \n",
    "        # Recreate the directory\n",
    "        try:\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "            print(f\"Recreated directory: {dir_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to create directory {dir_path}. Reason: {e}\")\n",
    "\n",
    "# Define directories to reset\n",
    "directories_to_reset = [\n",
    "    \"datasets/images/train\",\n",
    "    \"datasets/images/valid\",\n",
    "    \"datasets/images/test\",\n",
    "    \"datasets/labels/train\",\n",
    "    \"datasets/labels/valid\",\n",
    "    \"datasets/labels/test\"\n",
    "]\n",
    "\n",
    "# Reset directories\n",
    "reset_directories(directories_to_reset)\n",
    "\n",
    "print(\"Directories reset and ready for use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG_0871_MOV-39_jpg.rf.41a6a9b70c2a41fa45e3960...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004720_jpg.rf.afc486560a4004c7cfd67910af31a29c...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG_0871_mp4-9_jpg.rf.2f7c21e75f95f0f1b1803a70...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>construction-872-_jpg.rf.3403cad2f0566950b2322...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n457047_jpg.rf.254d1968e99ec5d7bc5e946c03f0c5a...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  split\n",
       "0  IMG_0871_MOV-39_jpg.rf.41a6a9b70c2a41fa45e3960...  train\n",
       "1  004720_jpg.rf.afc486560a4004c7cfd67910af31a29c...  train\n",
       "2  IMG_0871_mp4-9_jpg.rf.2f7c21e75f95f0f1b1803a70...  train\n",
       "3  construction-872-_jpg.rf.3403cad2f0566950b2322...  train\n",
       "4  n457047_jpg.rf.254d1968e99ec5d7bc5e946c03f0c5a...  train"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# source directory containing all raw images\n",
    "source_image_dir = \"datasets/raw_images\"\n",
    "\n",
    "# organize dataset directories\n",
    "base_dir = \"datasets\"\n",
    "image_dirs = {\n",
    "    \"train\": os.path.join(base_dir, \"images/train\"),\n",
    "    \"valid\": os.path.join(base_dir, \"images/valid\"),\n",
    "    \"test\": os.path.join(base_dir, \"images/test\")\n",
    "}\n",
    "label_dirs = {\n",
    "    \"train\": os.path.join(base_dir, \"labels/train\"),\n",
    "    \"valid\": os.path.join(base_dir, \"labels/valid\"),\n",
    "    \"test\": os.path.join(base_dir, \"labels/test\")\n",
    "}\n",
    "\n",
    "# extract the image files\n",
    "image_files = [f for f in os.listdir(source_image_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "random.shuffle(image_files)\n",
    "\n",
    "# Create DataFrame with file paths and dataset split assignments\n",
    "df = pd.DataFrame({\"filename\": image_files})\n",
    "# dynamically split dataset into train, valid, and test\n",
    "# split sizes\n",
    "train_size = int(0.7 * len(df))  # 70% for training\n",
    "valid_size = int(0.2 * len(df))  # 20% for validation\n",
    "test_size = len(df) - train_size - valid_size  # remaining 10% for testing\n",
    "\n",
    "# split labels\n",
    "train_labels = [\"train\"] * train_size\n",
    "valid_labels = [\"valid\"] * valid_size\n",
    "test_labels = [\"test\"] * test_size\n",
    "\n",
    "# combine and assign to DataFrame\n",
    "df[\"split\"] = train_labels + valid_labels + test_labels\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_MOV-39_jpg.rf.41a6a9b70c2a41fa45e39600600ce0ed.jpg: 640x640 1 bus, 1 truck, 54.4ms\n",
      "Speed: 0.7ms preprocess, 54.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/004720_jpg.rf.afc486560a4004c7cfd67910af31a29c.jpg: 640x640 1 person, 4 cars, 1 cow, 56.1ms\n",
      "Speed: 0.7ms preprocess, 56.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-9_jpg.rf.2f7c21e75f95f0f1b1803a708e06f342.jpg: 640x640 3 persons, 73.4ms\n",
      "Speed: 0.7ms preprocess, 73.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-872-_jpg.rf.3403cad2f0566950b232268f3685fc9d.jpg: 640x640 2 persons, 1 motorcycle, 55.2ms\n",
      "Speed: 0.8ms preprocess, 55.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/n457047_jpg.rf.254d1968e99ec5d7bc5e946c03f0c5ae.jpg: 640x640 5 persons, 1 truck, 52.3ms\n",
      "Speed: 0.7ms preprocess, 52.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-407_jpg.rf.1b0ab03157f1b44aa5afca50be370206.jpg: 640x640 2 persons, 1 bus, 55.7ms\n",
      "Speed: 0.7ms preprocess, 55.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0550_jpg.rf.56385e14f5f45b8e32f1bde53ce0fec3.jpg: 640x640 1 person, 1 train, 1 couch, 1 tv, 51.3ms\n",
      "Speed: 0.8ms preprocess, 51.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class1_199_jpg.rf.25ac2f354750de8592d134101f96dec8.jpg: 640x640 3 persons, 2 trains, 45.8ms\n",
      "Speed: 0.7ms preprocess, 45.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-212-_jpg.rf.0f02bc1536288f419c6d04b5f81ce251.jpg: 640x640 2 persons, 1 truck, 1 traffic light, 51.1ms\n",
      "Speed: 1.2ms preprocess, 51.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/additional_tests-Nomask-wearing_mp4-35_jpg.rf.5cc8c4f2191c8dd3960db8e35aa92a1e.jpg: 640x640 6 persons, 1 cup, 43.7ms\n",
      "Speed: 0.8ms preprocess, 43.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox4_mp4-111_jpg.rf.670b776d44304ea66fd4bae077abee1d.jpg: 640x640 1 fire hydrant, 40.0ms\n",
      "Speed: 0.7ms preprocess, 40.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/helmet999863_jpg.rf.ce83ac1b7c9d2df9a6bff93f6ced0f89.jpg: 640x640 1 traffic light, 44.4ms\n",
      "Speed: 0.6ms preprocess, 44.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-684-_jpg.rf.22733637c2460c60fc4cbaaf26b1a722.jpg: 640x640 1 person, 3 trucks, 1 fire hydrant, 42.6ms\n",
      "Speed: 0.6ms preprocess, 42.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_151_jpg.rf.7c9b4ff5801d8817a3da4485cb3a52d2.jpg: 640x640 1 person, 1 car, 1 truck, 44.2ms\n",
      "Speed: 0.7ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/fnacc_corridor_jpg.rf.993a63fd48562fe2570d51030616212f.jpg: 640x640 2 persons, 1 truck, 1 bench, 1 book, 43.5ms\n",
      "Speed: 0.6ms preprocess, 43.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-246_jpg.rf.9a231d454c623fc354c903391dbf2515.jpg: 640x640 2 persons, 44.5ms\n",
      "Speed: 0.7ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-2_jpg.rf.58de1db8826e4221df63fd980b823844.jpg: 640x640 3 persons, 44.6ms\n",
      "Speed: 0.7ms preprocess, 44.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-763-_jpg.rf.1f60ab1eaefee1f11c673ea202888bbd.jpg: 640x640 (no detections), 43.3ms\n",
      "Speed: 0.7ms preprocess, 43.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-480_jpg.rf.89afcc56a64d10e3d0b7c1d6a49b3c27.jpg: 640x640 2 persons, 1 truck, 39.1ms\n",
      "Speed: 0.6ms preprocess, 39.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/img17_jpg.rf.f86a56da765e0be917a7e394bb830282.jpg: 640x640 1 person, 1 car, 1 truck, 41.7ms\n",
      "Speed: 0.7ms preprocess, 41.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_7286_JPG_jpg.rf.68ad9f1a3104a6a4c22786cc33552e9c.jpg: 640x640 10 persons, 1 truck, 1 laptop, 43.9ms\n",
      "Speed: 0.6ms preprocess, 43.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_000280_jpg.rf.90c8b34923112435cd8778196f2a2100.jpg: 640x640 1 person, 42.5ms\n",
      "Speed: 0.7ms preprocess, 42.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-5_jpg.rf.074ef90b407a15d79870f6408e7a7da9.jpg: 640x640 3 persons, 1 train, 1 truck, 42.2ms\n",
      "Speed: 0.7ms preprocess, 42.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-61_jpg.rf.2f8ea247e5f46e06042d18ba0dec8fdb.jpg: 640x640 6 persons, 1 traffic light, 1 tie, 44.7ms\n",
      "Speed: 0.8ms preprocess, 44.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-137_jpg.rf.31d83b8a75abe31cb4d45ec7a18b42f8.jpg: 640x640 4 persons, 46.0ms\n",
      "Speed: 0.7ms preprocess, 46.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-142-_jpg.rf.c3ba99b04533582e3fc60dbeae85ab17.jpg: 640x640 1 person, 1 surfboard, 1 cell phone, 1 toothbrush, 58.3ms\n",
      "Speed: 0.7ms preprocess, 58.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-14_jpg.rf.a1be1dc990daed465af91ca0a205e591.jpg: 640x640 9 persons, 1 motorcycle, 1 bus, 1 truck, 1 boat, 54.9ms\n",
      "Speed: 0.8ms preprocess, 54.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5847_jpg.rf.8a3aa99c015f474af592cf6196d767b5.jpg: 640x640 9 persons, 2 trucks, 1 suitcase, 55.0ms\n",
      "Speed: 0.8ms preprocess, 55.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_241_jpg.rf.53b2134f52e6617c58be5484c5b78667.jpg: 640x640 1 bus, 52.8ms\n",
      "Speed: 0.7ms preprocess, 52.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0460_jpg.rf.e493c05d450ed8129338e21610922199.jpg: 640x640 1 person, 57.2ms\n",
      "Speed: 0.8ms preprocess, 57.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/727_jpg.rf.88b4842b25f06d9a0abc65e5200ae5b5.jpg: 640x640 1 person, 1 chair, 57.1ms\n",
      "Speed: 1.0ms preprocess, 57.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_818_jpg.rf.1d3a358731fc9e39e5ee58afa7f0e5e5.jpg: 640x640 3 persons, 1 train, 1 tie, 1 toothbrush, 52.5ms\n",
      "Speed: 0.9ms preprocess, 52.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_4921-2_mp4-40_jpg.rf.656442519b415c3574dcf2468c7d93c6.jpg: 640x640 1 person, 1 train, 52.6ms\n",
      "Speed: 0.8ms preprocess, 52.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox4_mp4-42_jpg.rf.b99f0b25bd84cdd7fb96017ebd68e303.jpg: 640x640 15 persons, 1 motorcycle, 1 truck, 64.4ms\n",
      "Speed: 2.2ms preprocess, 64.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-726_jpg.rf.fb84745ec01c66f2b69157d913cab155.jpg: 640x640 1 person, 1 car, 3 trucks, 1 chair, 48.6ms\n",
      "Speed: 0.7ms preprocess, 48.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Apple-Tests-Face-ID-Feature-While-Wearing-a-Mask-Shorts_mp4-51_jpg.rf.c943db9b286389250ee78674432c1ccb.jpg: 640x640 1 motorcycle, 1 tv, 60.7ms\n",
      "Speed: 0.7ms preprocess, 60.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005139_jpg.rf.264f7aac166fc2d8628473d964339aa2.jpg: 640x640 3 persons, 56.8ms\n",
      "Speed: 0.9ms preprocess, 56.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_314_jpg.rf.f06eff57647e89b591bbc8705bec3475.jpg: 640x640 2 persons, 1 truck, 1 toilet, 54.3ms\n",
      "Speed: 0.7ms preprocess, 54.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-234_jpg.rf.97ccb9f5b78f4ec728aadd30b1a58446.jpg: 640x640 1 person, 51.6ms\n",
      "Speed: 0.7ms preprocess, 51.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-15_jpg.rf.50d17fb072207d6adc1aa10293ea50bd.jpg: 640x640 2 persons, 1 train, 1 toilet, 53.2ms\n",
      "Speed: 0.7ms preprocess, 53.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_986_jpg.rf.d2cec1db2c71cf8a8328440a6c165e0b.jpg: 640x640 1 truck, 1 toothbrush, 49.3ms\n",
      "Speed: 0.8ms preprocess, 49.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/londres_023_jpg.rf.5285d3173b933fcec7a18be4a6937074.jpg: 640x640 6 persons, 1 truck, 1 tie, 51.4ms\n",
      "Speed: 0.7ms preprocess, 51.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-497_jpg.rf.b8b5f459b6bf69cc2383c6f8f7de916d.jpg: 640x640 1 person, 2 trucks, 40.4ms\n",
      "Speed: 0.7ms preprocess, 40.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-370_jpg.rf.1a532f9ab681b2a276aaba111cec7f1a.jpg: 640x640 2 persons, 1 toothbrush, 41.9ms\n",
      "Speed: 0.7ms preprocess, 41.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-11_jpg.rf.860d91386672578b17948da9b06f7c21.jpg: 640x640 2 persons, 1 truck, 40.3ms\n",
      "Speed: 0.7ms preprocess, 40.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-188_jpg.rf.74d1b2d1747d25f44bf4d2c8f1fee247.jpg: 640x640 1 person, 1 car, 1 truck, 49.1ms\n",
      "Speed: 0.6ms preprocess, 49.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-276_jpg.rf.a805c0570527ab12069eb5c77b6caf83.jpg: 640x640 1 person, 41.7ms\n",
      "Speed: 0.6ms preprocess, 41.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0363_jpg.rf.80fddb2e754c830ff538e01dc1366296.jpg: 640x640 1 person, 42.5ms\n",
      "Speed: 0.7ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_61_jpg.rf.29cef9c1e3298c6c56c69489d47dd7e1.jpg: 640x640 1 person, 44.7ms\n",
      "Speed: 0.7ms preprocess, 44.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008526_jpg.rf.4c032b16756eb8ad94db6a8a224fb076.jpg: 640x640 10 persons, 1 umbrella, 1 couch, 1 bed, 40.8ms\n",
      "Speed: 0.6ms preprocess, 40.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-572-_jpg.rf.e2b425bdd9d13b5d0f5c6362a81f21f4.jpg: 640x640 2 persons, 1 truck, 40.9ms\n",
      "Speed: 0.7ms preprocess, 40.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_1212_jpg.rf.3fb3352674da0bad368f663c349f98c3.jpg: 640x640 2 persons, 1 train, 40.8ms\n",
      "Speed: 0.7ms preprocess, 40.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3094_mp4-45_jpg.rf.b65aa0f84dbec2f2cb4e46553b791704.jpg: 640x640 2 persons, 1 tv, 1 toothbrush, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-816-_jpg.rf.62e21625240b95a16c38763d900eec32.jpg: 640x640 1 person, 42.5ms\n",
      "Speed: 0.7ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-137_jpg.rf.1ab866f667b59aebe91a95912bc348be.jpg: 640x640 4 persons, 1 airplane, 40.2ms\n",
      "Speed: 0.7ms preprocess, 40.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-646_jpg.rf.ccad877b36f0a6ba6e3ebf50bb96883f.jpg: 640x640 3 persons, 39.3ms\n",
      "Speed: 0.6ms preprocess, 39.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-10_jpg.rf.5029e6b54c840d58a76479bfc12f73fc.jpg: 640x640 2 persons, 2 trucks, 41.1ms\n",
      "Speed: 0.6ms preprocess, 41.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_829_jpg.rf.420038a253fd4309e6030e78be9590f5.jpg: 640x640 8 persons, 42.4ms\n",
      "Speed: 0.7ms preprocess, 42.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-547-_jpg.rf.a5de127a542ce69a5a53d96be88fd539.jpg: 640x640 2 persons, 1 truck, 1 chair, 41.4ms\n",
      "Speed: 0.7ms preprocess, 41.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/img_037_jpg.rf.443cb1ae396e00501bef3e2b8eac8af4.jpg: 640x640 1 truck, 1 toilet, 1 vase, 46.6ms\n",
      "Speed: 0.6ms preprocess, 46.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-645_jpg.rf.b1b8eab76ceffb9ed93fee8ed2bbed86.jpg: 640x640 3 persons, 4 surfboards, 46.6ms\n",
      "Speed: 0.8ms preprocess, 46.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/amz_04178_png_jpg.rf.8fdfcf920dc831c8c53c357531f5e7d7.jpg: 640x640 3 persons, 1 traffic light, 45.4ms\n",
      "Speed: 0.7ms preprocess, 45.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-528-_jpg.rf.3578451e1fd09479e3ddb770aafd00e5.jpg: 640x640 1 person, 1 motorcycle, 1 train, 1 truck, 45.7ms\n",
      "Speed: 0.7ms preprocess, 45.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-49_jpg.rf.6b186aca14e415e245c0d9c01ae3865b.jpg: 640x640 1 person, 4 trucks, 47.2ms\n",
      "Speed: 0.7ms preprocess, 47.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005239_jpg.rf.e2238d4058c251acf13fce7ed0319bae.jpg: 640x640 5 persons, 1 tv, 44.7ms\n",
      "Speed: 0.8ms preprocess, 44.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-506_jpg.rf.514b3b151b1e7ab2758985145e88355d.jpg: 640x640 3 persons, 1 car, 1 train, 45.6ms\n",
      "Speed: 0.7ms preprocess, 45.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-98_jpg.rf.05762e5e45e5c6a0583810b8b628b8e8.jpg: 640x640 1 person, 46.0ms\n",
      "Speed: 0.7ms preprocess, 46.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-270_jpg.rf.88395477ace654dae25982a1d09f1167.jpg: 640x640 1 person, 1 truck, 2 horses, 1 dining table, 39.1ms\n",
      "Speed: 0.6ms preprocess, 39.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-189_jpg.rf.61bdf5db12b5dac593e742763da5043d.jpg: 640x640 1 train, 1 truck, 39.1ms\n",
      "Speed: 0.6ms preprocess, 39.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-187_jpg.rf.dd06929c6ea565648b8156753b8b00c9.jpg: 640x640 8 persons, 2 bottles, 1 dining table, 1 clock, 45.4ms\n",
      "Speed: 0.7ms preprocess, 45.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-813_jpg.rf.f0b08055ea368a39e7846182b7af0102.jpg: 640x640 2 persons, 3 bottles, 1 cup, 1 refrigerator, 41.8ms\n",
      "Speed: 0.7ms preprocess, 41.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-567_jpg.rf.290d0d726e3263a6dd0985a5641acdb6.jpg: 640x640 (no detections), 47.6ms\n",
      "Speed: 0.7ms preprocess, 47.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-361_jpg.rf.2db640272b60b264138c07d0a9a9fe9a.jpg: 640x640 1 car, 1 dog, 42.5ms\n",
      "Speed: 0.7ms preprocess, 42.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/YouTube_FreeStockFootage_People-wearing-face-mask_Empty-Street_Covid19-D_DbgrvhlGs-720p_mp4-11_jpg.rf.057bb111725e4c37ef3a24e9fe9c76e0.jpg: 640x640 5 persons, 41.7ms\n",
      "Speed: 0.7ms preprocess, 41.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-731_jpg.rf.47b70ce0a8b8a93aca5916119175a04c.jpg: 640x640 1 person, 1 horse, 45.6ms\n",
      "Speed: 0.7ms preprocess, 45.6ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_498_jpg.rf.0a2642929e878c561b35e7eb1d8ece8a.jpg: 640x640 10 persons, 44.7ms\n",
      "Speed: 1.6ms preprocess, 44.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mask-wearing-1632932085584_png_jpg.rf.20c1b33f4b3995a29499e671565617e5.jpg: 640x640 4 persons, 1 bird, 1 chair, 51.1ms\n",
      "Speed: 0.7ms preprocess, 51.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/front_crawling_00088_jpg.rf.538a4f0a7b1b14a1e2c0295ec55e3b53.jpg: 640x640 2 persons, 45.9ms\n",
      "Speed: 0.7ms preprocess, 45.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-554_jpg.rf.dcdb088f996430efdc855565535f7c50.jpg: 640x640 6 persons, 1 handbag, 1 surfboard, 1 teddy bear, 45.4ms\n",
      "Speed: 0.7ms preprocess, 45.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-18_jpg.rf.eece44b86f6a81571decd1bb9ad11578.jpg: 640x640 1 person, 1 car, 1 truck, 1 clock, 45.8ms\n",
      "Speed: 0.9ms preprocess, 45.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-573_jpg.rf.55bbcdf0ada291ba06c267099e0c2138.jpg: 640x640 1 person, 1 truck, 1 bird, 44.9ms\n",
      "Speed: 0.7ms preprocess, 44.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/londres_023_jpg.rf.f769008a6a62c2c3fad47b312f95a5cc.jpg: 640x640 2 persons, 1 traffic light, 1 refrigerator, 47.8ms\n",
      "Speed: 0.6ms preprocess, 47.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-28_jpg.rf.34703946fabeb4f2f48029381dd98237.jpg: 640x640 1 person, 1 bicycle, 1 truck, 46.2ms\n",
      "Speed: 0.8ms preprocess, 46.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-5_jpg.rf.d8a9e349bf878db698469433d9778d75.jpg: 640x640 7 persons, 1 bicycle, 1 truck, 43.3ms\n",
      "Speed: 0.6ms preprocess, 43.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-345_jpg.rf.894913690905774e15b79590f76b14d2.jpg: 640x640 1 person, 1 bus, 1 train, 49.0ms\n",
      "Speed: 0.7ms preprocess, 49.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-55_jpg.rf.649bf9625a99a02aeb0a3e663316c5fd.jpg: 640x640 2 persons, 45.3ms\n",
      "Speed: 0.7ms preprocess, 45.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-64_jpg.rf.82630b3884bea0665bee75d3f3251c15.jpg: 640x640 1 truck, 39.3ms\n",
      "Speed: 0.7ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-254_jpg.rf.6b36672be6f16090ce5afef24fa83f1d.jpg: 640x640 2 persons, 1 train, 1 chair, 41.4ms\n",
      "Speed: 0.7ms preprocess, 41.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-51_jpg.rf.918a7bdc4ca148b6af590b9aa79bb890.jpg: 640x640 1 person, 1 bus, 1 truck, 39.1ms\n",
      "Speed: 0.6ms preprocess, 39.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-639_jpg.rf.49797bc26a8488409cdeeda6e6b8bae7.jpg: 640x640 2 persons, 1 surfboard, 41.9ms\n",
      "Speed: 0.7ms preprocess, 41.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_50_jpg.rf.ff8f3b4fd53f276bc9f14de2ac0924dd.jpg: 640x640 1 person, 1 truck, 42.9ms\n",
      "Speed: 0.6ms preprocess, 42.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_379_jpg.rf.dc648cd829811bb21fb009c79ca313e4.jpg: 640x640 3 persons, 1 bus, 45.5ms\n",
      "Speed: 0.7ms preprocess, 45.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-1670-_png_jpg.rf.3cb172ea2c4165c19ae2dd498b38f929.jpg: 640x640 3 persons, 43.4ms\n",
      "Speed: 0.7ms preprocess, 43.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-96_jpg.rf.ec065525e23bd20e778db05a8cb92042.jpg: 640x640 3 persons, 1 baseball bat, 40.9ms\n",
      "Speed: 0.7ms preprocess, 40.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005180_jpg.rf.3c83b15d5bed446651582525866783fa.jpg: 640x640 2 persons, 1 truck, 38.5ms\n",
      "Speed: 0.7ms preprocess, 38.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-560-_jpg.rf.a353d8779de14a95c1cd52bfbf47c368.jpg: 640x640 2 persons, 1 bus, 1 truck, 41.1ms\n",
      "Speed: 0.6ms preprocess, 41.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/fnacc_corridor_jpg.rf.e3e6e90eff2980c874604d993ae05c8f.jpg: 640x640 2 persons, 40.5ms\n",
      "Speed: 0.6ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-523-_jpg.rf.39fe60c11ac70b73c2cc469124bb1762.jpg: 640x640 3 persons, 2 clocks, 41.0ms\n",
      "Speed: 0.7ms preprocess, 41.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-I1-MS09uaqsLdGTFkgnS0Rcg1mmPyAj95ySg_eckoM_jpeg_jpg.rf.10828c2a406f3e985c87926751704f49.jpg: 640x640 4 persons, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-9_jpg.rf.9c151802b6a69d088e7a9c25c567f3dd.jpg: 640x640 1 person, 1 chair, 40.9ms\n",
      "Speed: 0.7ms preprocess, 40.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_662_jpg.rf.884cebb84cbee6e965a07fc98156768c.jpg: 640x640 1 person, 1 airplane, 1 truck, 1 boat, 42.5ms\n",
      "Speed: 0.6ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-14_jpg.rf.48abbd1245bad1c0b012ec3b52cad710.jpg: 640x640 3 persons, 1 car, 1 truck, 45.5ms\n",
      "Speed: 0.6ms preprocess, 45.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008337_jpg.rf.b3d479181e4c04ff814ab55502b8055d.jpg: 640x640 2 persons, 1 bicycle, 51.2ms\n",
      "Speed: 0.7ms preprocess, 51.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-710_jpg.rf.d08ee99ca13439d01a7043769a077240.jpg: 640x640 1 person, 45.1ms\n",
      "Speed: 0.7ms preprocess, 45.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/front_crawling_00088_jpg.rf.a2d51b171dfaa47798690e0a4150423a.jpg: 640x640 2 persons, 2 trucks, 43.1ms\n",
      "Speed: 0.6ms preprocess, 43.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Apple-Tests-Face-ID-Feature-While-Wearing-a-Mask-Shorts_mp4-51_jpg.rf.ffa08318a536c7ee18b57f9dbcc6616f.jpg: 640x640 3 persons, 3 trucks, 1 laptop, 40.3ms\n",
      "Speed: 0.7ms preprocess, 40.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-295_jpg.rf.91d8f30e9ef707a29bc71993bafc3cc0.jpg: 640x640 1 person, 1 wine glass, 45.5ms\n",
      "Speed: 0.7ms preprocess, 45.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_426_jpg.rf.4580f9223554a212044814714cc75586.jpg: 640x640 1 car, 1 truck, 1 parking meter, 37.7ms\n",
      "Speed: 0.6ms preprocess, 37.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008364_jpg.rf.7e993c289a92cc10642f3c86fd49615e.jpg: 640x640 4 persons, 2 trains, 41.0ms\n",
      "Speed: 0.7ms preprocess, 41.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_991_jpg.rf.bcf09e9cb1b50e75676d26026b1dd6e6.jpg: 640x640 5 persons, 2 cars, 1 airplane, 1 traffic light, 1 parking meter, 41.6ms\n",
      "Speed: 0.7ms preprocess, 41.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-112-_jpg.rf.aff73a376ef301a11e45c58fb084e7a5.jpg: 640x640 2 persons, 1 toilet, 42.9ms\n",
      "Speed: 0.6ms preprocess, 42.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mo-justin-mask-NoMask_mov-34_jpg.rf.94fc350ee2eec538a35e13245f61b5a3.jpg: 640x640 2 persons, 4 books, 42.1ms\n",
      "Speed: 0.7ms preprocess, 42.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008593_jpg.rf.fa226868652307ad79a6e9a0ec013a1e.jpg: 640x640 5 persons, 1 truck, 1 bed, 45.4ms\n",
      "Speed: 0.6ms preprocess, 45.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-726_jpg.rf.22b3d2e534ca2afcc1e861a85e1ea167.jpg: 640x640 2 persons, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-49_jpg.rf.dd69eec01082ff31e87b46c4b616b5b0.jpg: 640x640 1 person, 2 trucks, 41.0ms\n",
      "Speed: 0.7ms preprocess, 41.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-480_jpg.rf.77f9c16588cc063d8996df3d0b484f67.jpg: 640x640 1 person, 40.6ms\n",
      "Speed: 0.7ms preprocess, 40.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_326_jpg.rf.ba69aade4530c10c5c29ebd0f357c225.jpg: 640x640 1 person, 2 horses, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_255_jpg.rf.ff0491219f776632d3ef7fd16ea9abf8.jpg: 640x640 1 person, 2 trucks, 1 boat, 40.0ms\n",
      "Speed: 0.6ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-48_jpg.rf.869646c7e34f2451c66b6d9487b68281.jpg: 640x640 1 person, 1 bus, 1 truck, 1 traffic light, 44.1ms\n",
      "Speed: 0.7ms preprocess, 44.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-649-_jpg.rf.99870a2bf5ae5405710b62306f58a3ae.jpg: 640x640 1 motorcycle, 1 bus, 2 trucks, 39.9ms\n",
      "Speed: 0.6ms preprocess, 39.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_1212_jpg.rf.5d9175173a153a8b5bf1643129b3a349.jpg: 640x640 4 persons, 2 trucks, 42.9ms\n",
      "Speed: 0.6ms preprocess, 42.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_246_jpg.rf.5b09f63561fa416c6e982b459acf98d4.jpg: 640x640 3 persons, 3 surfboards, 42.7ms\n",
      "Speed: 0.7ms preprocess, 42.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-60_jpg.rf.17608ba2791115490e8624a0c0834f31.jpg: 640x640 1 person, 1 truck, 1 bed, 44.2ms\n",
      "Speed: 0.6ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-13_jpg.rf.92820cdc1cba18b698ae508059efc4fc.jpg: 640x640 4 persons, 1 horse, 1 chair, 42.2ms\n",
      "Speed: 0.6ms preprocess, 42.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_MOV-39_jpg.rf.b1ef6aecc28e153eeb71c698cee34c0f.jpg: 640x640 2 persons, 41.1ms\n",
      "Speed: 0.7ms preprocess, 41.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/006858_jpg.rf.01d202a11c3bf4914ee7e1875bf5b8de.jpg: 640x640 3 persons, 1 truck, 1 boat, 38.1ms\n",
      "Speed: 0.7ms preprocess, 38.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-459_jpg.rf.c9ac0b0598c3d80339b8e71c6bd00cc7.jpg: 640x640 5 persons, 1 train, 2 trucks, 38.4ms\n",
      "Speed: 0.6ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-21_jpg.rf.b43a82de9b1f1db1f9fcf8b57fe636e7.jpg: 640x640 2 persons, 41.8ms\n",
      "Speed: 0.7ms preprocess, 41.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-567_jpg.rf.f8bd150bb94a697fcef528db89ed716a.jpg: 640x640 3 persons, 39.4ms\n",
      "Speed: 0.7ms preprocess, 39.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_002883_jpg.rf.e9b784c222a40531120bae836f293598.jpg: 640x640 2 persons, 2 horses, 1 refrigerator, 43.4ms\n",
      "Speed: 0.6ms preprocess, 43.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/REVZGCBIJNQPMIIXOKDCQA3GJI_jpg.rf.12108ff6f8823fb661f2e8bb18b573cf.jpg: 640x640 4 persons, 41.3ms\n",
      "Speed: 0.7ms preprocess, 41.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_941_jpg.rf.0d7df052dcf719eb98f3c4de6c663af4.jpg: 640x640 (no detections), 39.2ms\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/01261_jpg.rf.a2f9b65be201cebad78a1c25a855b0f2.jpg: 640x640 4 persons, 1 truck, 42.2ms\n",
      "Speed: 0.7ms preprocess, 42.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-137_jpg.rf.90bf389d1e857adcc5f447325cb571c6.jpg: 640x640 4 persons, 1 car, 1 truck, 1 cat, 48.4ms\n",
      "Speed: 0.7ms preprocess, 48.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005310_jpg.rf.5b524ed76d3e591d22c323212f22943f.jpg: 640x640 1 truck, 1 horse, 44.9ms\n",
      "Speed: 0.7ms preprocess, 44.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-41_jpg.rf.c5e4bcc5976beec3e62122474353665b.jpg: 640x640 1 person, 1 truck, 42.9ms\n",
      "Speed: 0.7ms preprocess, 42.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-347-_jpg.rf.135164f845ccb489767b2085e6bf4580.jpg: 640x640 1 car, 1 truck, 41.6ms\n",
      "Speed: 0.6ms preprocess, 41.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1099-_jpg.rf.bb495a41d6ea301e0032d76b262640dd.jpg: 640x640 4 persons, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-69_jpg.rf.23a3f9feb8b2a30b45189f742b62abd2.jpg: 640x640 2 trucks, 40.5ms\n",
      "Speed: 0.7ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_965_jpg.rf.b32ac9c5c122adb5851e5a680a6d745d.jpg: 640x640 5 persons, 39.2ms\n",
      "Speed: 0.7ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.a988e2e512aa158adc5f82945a436de6.jpg: 640x640 1 person, 2 buss, 1 truck, 41.2ms\n",
      "Speed: 0.7ms preprocess, 41.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-188_jpg.rf.2b59761677c691be543a13bd9792f616.jpg: 640x640 (no detections), 46.8ms\n",
      "Speed: 0.8ms preprocess, 46.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-112-_jpg.rf.699d3c5a3155bb76ee6e10e842cc24de.jpg: 640x640 1 person, 1 book, 39.5ms\n",
      "Speed: 0.7ms preprocess, 39.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-210_jpg.rf.97c7ed3b362a658e69e582e794a29994.jpg: 640x640 2 trucks, 39.9ms\n",
      "Speed: 0.6ms preprocess, 39.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-44_jpg.rf.44c112804b26c917732c97277de4842c.jpg: 640x640 7 persons, 1 airplane, 49.4ms\n",
      "Speed: 0.6ms preprocess, 49.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_527_jpg.rf.63975658973acf5c51a5dcd10289ce86.jpg: 640x640 1 person, 41.3ms\n",
      "Speed: 0.9ms preprocess, 41.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-844-_jpg.rf.5ffd5589cd69ddbbb3b14b5846753908.jpg: 640x640 1 truck, 45.2ms\n",
      "Speed: 0.7ms preprocess, 45.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-618-_jpg.rf.7519c6fdc08f7146cc7a75a6437e2c5e.jpg: 640x640 2 persons, 1 bed, 1 tv, 39.1ms\n",
      "Speed: 0.7ms preprocess, 39.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-1_jpg.rf.a85e4a0f9df714dac02831fb88082d2c.jpg: 640x640 2 persons, 1 bed, 43.9ms\n",
      "Speed: 0.7ms preprocess, 43.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-615_jpg.rf.ef4781ab78ef34a83cae9a6c44658dcf.jpg: 640x640 2 persons, 1 bottle, 44.0ms\n",
      "Speed: 0.7ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/931_jpg.rf.3fbfec4632048a0d850726a04954a2d6.jpg: 640x640 1 person, 1 truck, 1 bench, 1 umbrella, 43.6ms\n",
      "Speed: 0.9ms preprocess, 43.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/1582_jpg.rf.80ca40b216072d7fbf6a8a2f4e84ed7f.jpg: 640x640 2 persons, 1 car, 1 bottle, 41.0ms\n",
      "Speed: 0.8ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-42_jpg.rf.e70816c9d42dc92bed2a6d1e1feb21d9.jpg: 640x640 3 persons, 1 potted plant, 46.8ms\n",
      "Speed: 0.7ms preprocess, 46.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_418_jpg.rf.94cdaf3339a7193dc00d0f07da971d4d.jpg: 640x640 1 person, 1 car, 1 bus, 1 bear, 46.5ms\n",
      "Speed: 0.7ms preprocess, 46.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_003000_jpg.rf.16e6d9c2516e182a4343111e8d26a81b.jpg: 640x640 4 persons, 1 bottle, 1 refrigerator, 48.4ms\n",
      "Speed: 0.7ms preprocess, 48.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_120_jpg.rf.530c86dfc54a97d88c9b090eeaafb7c2.jpg: 640x640 1 person, 1 truck, 1 backpack, 42.3ms\n",
      "Speed: 0.7ms preprocess, 42.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_426_jpg.rf.c7cde73ba46e86874c22e8b1bb2cf0fe.jpg: 640x640 3 persons, 1 bus, 1 truck, 1 boat, 1 cell phone, 46.5ms\n",
      "Speed: 0.6ms preprocess, 46.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_4921-2_mp4-40_jpg.rf.89c53f3f884478413a868cd4c6bf1067.jpg: 640x640 1 person, 1 car, 2 trucks, 1 couch, 74.3ms\n",
      "Speed: 0.7ms preprocess, 74.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-64_jpg.rf.92efd1b50f4e66f245f5705e2d6b7342.jpg: 640x640 4 persons, 1 truck, 1 tie, 1 bottle, 45.6ms\n",
      "Speed: 0.6ms preprocess, 45.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_31_jpg.rf.226995ca044d4a0348dcea8ae45d537a.jpg: 640x640 3 persons, 1 truck, 41.3ms\n",
      "Speed: 0.8ms preprocess, 41.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ins30_jpg.rf.cd7d441fa802b4042ff89c2bf9a6a013.jpg: 640x640 3 persons, 2 trucks, 1 zebra, 40.1ms\n",
      "Speed: 0.6ms preprocess, 40.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_321_jpg.rf.7cc6643afa0d1d377bb7b3e593e43acd.jpg: 640x640 1 airplane, 40.3ms\n",
      "Speed: 0.6ms preprocess, 40.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-67_jpg.rf.898b193561a91c94889cce6a30bcc4f2.jpg: 640x640 5 persons, 1 truck, 1 toilet, 42.7ms\n",
      "Speed: 0.6ms preprocess, 42.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_647_jpg.rf.c52de236dce0a5e626062efce6251534.jpg: 640x640 1 person, 1 bicycle, 2 trucks, 43.2ms\n",
      "Speed: 0.7ms preprocess, 43.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-813_jpg.rf.b9c7825c3711b9f313376a12b75553f3.jpg: 640x640 1 person, 1 truck, 41.4ms\n",
      "Speed: 0.6ms preprocess, 41.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-212-_jpg.rf.dfc3cd38ed63f7b7f642f8b1cbb1b68e.jpg: 640x640 3 trucks, 1 bench, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_9949-1-_mp4-63_jpg.rf.6d04c0ff1a95e4309a859fe65031ebe3.jpg: 640x640 2 persons, 1 truck, 46.7ms\n",
      "Speed: 0.7ms preprocess, 46.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-507_jpg.rf.d92c828e6ccb5167f91263e147c80e61.jpg: 640x640 4 persons, 45.9ms\n",
      "Speed: 0.8ms preprocess, 45.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-435_jpg.rf.a4e40a48df58eaed819a210dc833d3e4.jpg: 640x640 2 persons, 2 trucks, 44.9ms\n",
      "Speed: 0.7ms preprocess, 44.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-571_jpg.rf.c6146b84a8ca2869cb5c52f72eded67b.jpg: 640x640 3 persons, 38.1ms\n",
      "Speed: 0.7ms preprocess, 38.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-730_jpg.rf.9cb949c7d69958d412a7eb3fb8d4e0c7.jpg: 640x640 2 persons, 1 bench, 1 cell phone, 1 toothbrush, 40.9ms\n",
      "Speed: 0.6ms preprocess, 40.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1029-_jpg.rf.dd6bee328a829fc5e57997df9428ab4b.jpg: 640x640 1 person, 1 truck, 42.2ms\n",
      "Speed: 0.7ms preprocess, 42.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-235_jpg.rf.426511762b282049df69f0463aed5d93.jpg: 640x640 1 person, 2 trucks, 1 kite, 39.1ms\n",
      "Speed: 0.7ms preprocess, 39.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5851_jpg.rf.1e2a9117128d23630020de5b6b717ae2.jpg: 640x640 14 persons, 1 truck, 40.8ms\n",
      "Speed: 0.7ms preprocess, 40.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_13_jpg.rf.d2935ec7b305c381c6b298ca98f24a1a.jpg: 640x640 1 person, 42.8ms\n",
      "Speed: 0.7ms preprocess, 42.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-272_jpg.rf.a40270b67814f8d7cf05eedcdfda4d35.jpg: 640x640 4 persons, 40.4ms\n",
      "Speed: 0.6ms preprocess, 40.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-79_jpg.rf.9f5c8a5244382d17fe658ee89e56198a.jpg: 640x640 4 persons, 1 truck, 1 elephant, 43.1ms\n",
      "Speed: 0.6ms preprocess, 43.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-999-_jpg.rf.0ed1dc47f25c88ee8da807e857fe4c41.jpg: 640x640 1 person, 1 truck, 40.4ms\n",
      "Speed: 0.6ms preprocess, 40.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Inside-merge_mov-16_jpg.rf.2d9d3295904e1c9452977ff359637d27.jpg: 640x640 2 persons, 1 car, 1 surfboard, 47.5ms\n",
      "Speed: 0.6ms preprocess, 47.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-51_jpg.rf.30dd5864d56e613fd5cbfa17c6c8d2fe.jpg: 640x640 3 persons, 1 train, 45.4ms\n",
      "Speed: 0.8ms preprocess, 45.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-162_jpg.rf.7c643844819ddd3253bfdbe453045403.jpg: 640x640 1 truck, 1 horse, 41.4ms\n",
      "Speed: 0.6ms preprocess, 41.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_841_jpg.rf.470e52ac15350bbf6b2a13a2e70ec588.jpg: 640x640 1 truck, 43.0ms\n",
      "Speed: 0.7ms preprocess, 43.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-221_jpg.rf.14f433ce625eee736701c289e21bc013.jpg: 640x640 1 person, 1 airplane, 1 clock, 40.6ms\n",
      "Speed: 0.8ms preprocess, 40.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (17).jpeg: 224x640 1 person, 31.1ms\n",
      "Speed: 0.4ms preprocess, 31.1ms inference, 0.4ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_257_jpg.rf.ab68fb78a1ff77d6e41ec5f8fb17a8dd.jpg: 640x640 2 persons, 1 train, 1 chair, 48.4ms\n",
      "Speed: 0.8ms preprocess, 48.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/n457047_jpg.rf.d5ac5acbe81846a58350414fc5343b78.jpg: 640x640 4 persons, 1 baseball glove, 2 chairs, 39.3ms\n",
      "Speed: 0.6ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-19_jpg.rf.ae9b311efa6de4566e5c8ec20c3718fb.jpg: 640x640 1 truck, 1 traffic light, 47.5ms\n",
      "Speed: 0.6ms preprocess, 47.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-135_jpg.rf.ee1df1fe116d2b73503f786f2893aadd.jpg: 640x640 1 person, 1 train, 42.7ms\n",
      "Speed: 0.6ms preprocess, 42.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-434-_jpg.rf.0231dd3ec327871fc54469027144ebd6.jpg: 640x640 3 persons, 42.6ms\n",
      "Speed: 0.6ms preprocess, 42.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_002883_jpg.rf.33d18b918997b24639bd3b38944059da.jpg: 640x640 2 persons, 1 horse, 42.6ms\n",
      "Speed: 0.6ms preprocess, 42.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_622_jpg.rf.f659ef57ff19cb4e18962d96e8418d73.jpg: 640x640 2 persons, 1 laptop, 45.1ms\n",
      "Speed: 0.6ms preprocess, 45.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-395_jpg.rf.bfba865be239a85c5a67c5c9d97f6309.jpg: 640x640 1 person, 1 cat, 44.0ms\n",
      "Speed: 0.6ms preprocess, 44.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-730_jpg.rf.b55e41b07155a1b30073fb0e4da9e1b7.jpg: 640x640 2 persons, 1 traffic light, 43.2ms\n",
      "Speed: 0.7ms preprocess, 43.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-435-_jpg.rf.af852baf4acdd1cf317e509d1609464e.jpg: 640x640 1 bicycle, 2 motorcycles, 1 bus, 1 train, 1 boat, 43.8ms\n",
      "Speed: 0.6ms preprocess, 43.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2_jpg.rf.5d1d2457d0de245aa673442ac06891df.jpg: 640x640 2 trains, 2 trucks, 42.2ms\n",
      "Speed: 0.7ms preprocess, 42.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-396_jpg.rf.92106c943a67e2d642d6a26040970f9f.jpg: 640x640 3 persons, 1 truck, 1 dog, 42.3ms\n",
      "Speed: 0.6ms preprocess, 42.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-30_jpg.rf.f671ac8915234f2ca8b9246d095055e9.jpg: 640x640 (no detections), 40.9ms\n",
      "Speed: 0.7ms preprocess, 40.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_170_jpg.rf.2f38597bb6655852af47e376e052feec.jpg: 640x640 3 persons, 39.5ms\n",
      "Speed: 0.7ms preprocess, 39.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-15_jpg.rf.1d604f33faa22ae8a795623c6b37ae3e.jpg: 640x640 4 persons, 1 train, 1 truck, 1 laptop, 43.0ms\n",
      "Speed: 0.7ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-464_jpg.rf.355495bd54c66f71e909fa906b77e184.jpg: 640x640 3 persons, 1 truck, 38.7ms\n",
      "Speed: 0.7ms preprocess, 38.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_784_jpg.rf.41090f7f0ee0910e7726080756d0f2ea.jpg: 640x640 4 persons, 43.1ms\n",
      "Speed: 0.7ms preprocess, 43.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_965_jpg.rf.0d903559d161c9be66f5508439656ec9.jpg: 640x640 4 persons, 1 horse, 1 backpack, 46.5ms\n",
      "Speed: 0.6ms preprocess, 46.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-210_jpg.rf.975a658362fc68236a1bbb411f7ae1ad.jpg: 640x640 5 persons, 1 umbrella, 46.2ms\n",
      "Speed: 0.7ms preprocess, 46.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-25_jpg.rf.c1935205aef4196ed125487d5ba2b8e8.jpg: 640x640 2 persons, 43.5ms\n",
      "Speed: 0.6ms preprocess, 43.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_28_jpg.rf.188dcca832e3ca1c9e9597e352ca7aa1.jpg: 640x640 1 person, 1 bus, 2 trucks, 44.0ms\n",
      "Speed: 0.6ms preprocess, 44.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-543-_jpg.rf.4ac68b4606a6eecb76a48df1ae8ae96a.jpg: 640x640 1 person, 41.2ms\n",
      "Speed: 0.7ms preprocess, 41.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008618_jpg.rf.36f88cd9160d2a0be857a1f22210540b.jpg: 640x640 5 persons, 1 train, 1 suitcase, 38.6ms\n",
      "Speed: 0.6ms preprocess, 38.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/move_in_corridor_jpg.rf.370d9cb06aac096c65e2973a720c2afc.jpg: 640x640 1 person, 40.6ms\n",
      "Speed: 0.6ms preprocess, 40.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-344_jpg.rf.9472f9782daff130af5075a01fbf89f0.jpg: 640x640 6 persons, 1 train, 1 bottle, 43.2ms\n",
      "Speed: 0.6ms preprocess, 43.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_833_jpg.rf.a760d2cfd7ae0325593e33a966b49f83.jpg: 640x640 (no detections), 40.2ms\n",
      "Speed: 0.6ms preprocess, 40.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (14).jpeg: 224x640 2 persons, 18.4ms\n",
      "Speed: 0.5ms preprocess, 18.4ms inference, 0.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_241_jpg.rf.c2f08574bd8aa86dd1987a8ad991120d.jpg: 640x640 2 persons, 2 clocks, 44.7ms\n",
      "Speed: 0.6ms preprocess, 44.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_757_jpg.rf.7b0a8bc8ca385ef69f92a05a4d7cabe2.jpg: 640x640 1 person, 41.8ms\n",
      "Speed: 0.7ms preprocess, 41.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/smartmi-3pcs-filter-mask-pm25-haze-dustproof-mask-with-vent_jpg.rf.fafba71146172ece742c0a49188bb99b.jpg: 640x640 3 persons, 1 fire hydrant, 45.4ms\n",
      "Speed: 0.6ms preprocess, 45.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_000063_jpg.rf.6ec3137de0a8c1ecdfd20ade2706e078.jpg: 640x640 5 persons, 41.7ms\n",
      "Speed: 0.7ms preprocess, 41.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-13_jpg.rf.d8e40959c6947386bf3885280312b58c.jpg: 640x640 3 persons, 41.7ms\n",
      "Speed: 0.7ms preprocess, 41.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_7211_PNG_jpg.rf.fd9624eec1df134b37ca87b492398d07.jpg: 640x640 1 person, 1 truck, 39.9ms\n",
      "Speed: 0.7ms preprocess, 39.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Bookstore111_jpg.rf.2d384f1bdffb03527cd30bf40e210d6a.jpg: 640x640 2 books, 44.2ms\n",
      "Speed: 0.7ms preprocess, 44.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-348_jpg.rf.d60c9d67699236d8bf1be01b619db6fd.jpg: 640x640 (no detections), 42.6ms\n",
      "Speed: 0.6ms preprocess, 42.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-682-_jpg.rf.7161480fa0134c8ed4985baec0b325c8.jpg: 640x640 1 person, 42.6ms\n",
      "Speed: 0.7ms preprocess, 42.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Screenshot_20210830-123141_Instagram_jpg.rf.ab3ed7ef93b1cc4763e8b15a2eda02a1.jpg: 640x640 1 person, 39.8ms\n",
      "Speed: 0.6ms preprocess, 39.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-224_jpg.rf.e9877c51ff8b8cae6c2b865faa2e01df.jpg: 640x640 1 person, 43.8ms\n",
      "Speed: 0.7ms preprocess, 43.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-332_jpg.rf.82f4c8313fe8be426230e99f36c15fdb.jpg: 640x640 1 person, 4 cars, 1 train, 2 trucks, 45.3ms\n",
      "Speed: 0.7ms preprocess, 45.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_004301_jpg.rf.dcb85d0f7d931a7de69072529b41a5df.jpg: 640x640 3 persons, 49.7ms\n",
      "Speed: 0.7ms preprocess, 49.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2297-_png_jpg.rf.9fff3740d864fbec9cda50d783ad805e.jpg: 640x640 6 persons, 1 car, 1 bus, 1 truck, 1 tie, 68.1ms\n",
      "Speed: 0.7ms preprocess, 68.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_620_jpg.rf.491476468415f41cd5c4be5debe9b6ba.jpg: 640x640 6 persons, 1 train, 1 fire hydrant, 43.1ms\n",
      "Speed: 0.7ms preprocess, 43.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_55_jpg.rf.4f4acd932047860fa58ac1e9e5c91c46.jpg: 640x640 2 potted plants, 2 vases, 39.9ms\n",
      "Speed: 0.7ms preprocess, 39.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-41_jpg.rf.7b69173a420f4e678956e3796fed8ee5.jpg: 640x640 1 person, 1 truck, 39.3ms\n",
      "Speed: 0.6ms preprocess, 39.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005180_jpg.rf.77e5bbc190a7bde710749bae284e6fff.jpg: 640x640 4 persons, 2 ties, 2 bottles, 1 refrigerator, 43.0ms\n",
      "Speed: 0.6ms preprocess, 43.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_000379_jpg.rf.fc46b82ce969c13ab1d3423c5e813105.jpg: 640x640 2 persons, 1 umbrella, 1 couch, 1 microwave, 40.3ms\n",
      "Speed: 0.7ms preprocess, 40.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-362_jpg.rf.def70d3c298a3444fa7c6c64e5cacddf.jpg: 640x640 1 person, 43.5ms\n",
      "Speed: 0.6ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_624_jpg.rf.e535adb62ea33ee97c2df2b13113c4f5.jpg: 640x640 3 persons, 1 boat, 2 bottles, 38.5ms\n",
      "Speed: 0.6ms preprocess, 38.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-1975-_png_jpg.rf.d6c068e0d3eebc3b8e002413529c5e84.jpg: 640x640 5 persons, 1 bicycle, 1 truck, 1 parking meter, 39.5ms\n",
      "Speed: 0.7ms preprocess, 39.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-27_jpg.rf.6e128e68e8731b6daca9271077e4f8a0.jpg: 640x640 2 trucks, 46.8ms\n",
      "Speed: 0.7ms preprocess, 46.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0363_jpg.rf.365291e514d607750e19f54ac0c9fd8c.jpg: 640x640 7 persons, 44.1ms\n",
      "Speed: 0.8ms preprocess, 44.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-116_jpg.rf.824079ec283281c08f2004e9b3eebc42.jpg: 640x640 3 persons, 42.6ms\n",
      "Speed: 0.7ms preprocess, 42.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1050-_jpg.rf.03312445567fc60f4ddd13341d2614cd.jpg: 640x640 3 persons, 40.1ms\n",
      "Speed: 0.7ms preprocess, 40.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-618-_jpg.rf.56a444a99835f33971ab324800b81b7b.jpg: 640x640 1 car, 1 train, 1 umbrella, 1 clock, 42.0ms\n",
      "Speed: 5.7ms preprocess, 42.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-589_jpg.rf.9a14d2e0175cb632b827a4e6f8e51328.jpg: 640x640 (no detections), 40.1ms\n",
      "Speed: 0.7ms preprocess, 40.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2_jpg.rf.2a2cafa3fd6db594c2f3a46f971b1c14.jpg: 640x640 1 person, 1 bicycle, 1 train, 1 giraffe, 38.4ms\n",
      "Speed: 0.6ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-188_jpg.rf.c1a0568e41d5309293800c0e99cdc65b.jpg: 640x640 1 person, 41.9ms\n",
      "Speed: 0.6ms preprocess, 41.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-628_jpg.rf.062f20d445a5c8951bdebb2e64e3fd91.jpg: 640x640 3 persons, 1 banana, 43.0ms\n",
      "Speed: 0.6ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-14_jpg.rf.1346121356493c3795a0f7f42d3fcc88.jpg: 640x640 3 persons, 1 bus, 1 train, 1 truck, 1 surfboard, 38.6ms\n",
      "Speed: 0.6ms preprocess, 38.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_829_jpg.rf.39f673b4372b452d8c687e3fcdce765d.jpg: 640x640 7 persons, 1 motorcycle, 43.2ms\n",
      "Speed: 0.7ms preprocess, 43.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_732_jpg.rf.ff1ef6132b5697473bd7c4193f95b996.jpg: 640x640 1 person, 1 train, 1 truck, 40.8ms\n",
      "Speed: 0.7ms preprocess, 40.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/4c43875bc97cdaece84ac6ce555235f1_jpg.rf.f0ababbd27b5c11652961e9e5b4da88b.jpg: 640x640 2 trucks, 41.7ms\n",
      "Speed: 0.7ms preprocess, 41.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5851_jpg.rf.dd0dba7394062139823bef376062dd24.jpg: 640x640 8 persons, 44.5ms\n",
      "Speed: 0.6ms preprocess, 44.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_721_jpg.rf.65605ae6d8fa269e1a191c78ccb17894.jpg: 640x640 1 bicycle, 1 car, 2 trucks, 39.1ms\n",
      "Speed: 0.7ms preprocess, 39.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/494_jpg.rf.44f6e7003c8d642d073affd1936673ec.jpg: 640x640 1 person, 1 car, 43.2ms\n",
      "Speed: 0.7ms preprocess, 43.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-252_jpg.rf.778acded6daca1e48855fff20c04cc6f.jpg: 640x640 5 persons, 2 cars, 1 bus, 1 tie, 1 cup, 1 cake, 41.0ms\n",
      "Speed: 0.7ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-407_jpg.rf.c9d017f8efbd7555d23f79504a2dfbaf.jpg: 640x640 2 trucks, 39.0ms\n",
      "Speed: 0.6ms preprocess, 39.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-10_jpg.rf.8dc2241f467f75b7aec103f9a75b4321.jpg: 640x640 2 persons, 40.6ms\n",
      "Speed: 0.7ms preprocess, 40.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-334_jpg.rf.1e326e46bbffaa3205105d6db73fc7e9.jpg: 640x640 4 persons, 38.1ms\n",
      "Speed: 0.7ms preprocess, 38.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-369-_jpg.rf.23dd790f943919d62800543641ea8474.jpg: 640x640 2 persons, 37.1ms\n",
      "Speed: 0.7ms preprocess, 37.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/amz_04178_png_jpg.rf.66878feb10ab848f3eb8cba2f05f0c31.jpg: 640x640 2 persons, 1 cat, 42.1ms\n",
      "Speed: 0.6ms preprocess, 42.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0029_jpg.rf.3c177b00342fbffb26ee62203529551c.jpg: 640x640 2 persons, 1 bus, 1 truck, 1 dog, 1 book, 40.5ms\n",
      "Speed: 0.7ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-3394-_png_jpg.rf.23b668cbcad07f1e0d9cfdedd151fd46.jpg: 640x640 9 persons, 41.8ms\n",
      "Speed: 0.6ms preprocess, 41.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-507_jpg.rf.e3928fd0a5c1e25ab42359aa1a34a6ad.jpg: 640x640 1 person, 1 train, 1 truck, 1 tv, 43.6ms\n",
      "Speed: 0.7ms preprocess, 43.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/000415_jpg.rf.6e1ef08de110baace091eb9f5b5867a2.jpg: 640x640 3 persons, 2 trucks, 42.2ms\n",
      "Speed: 0.7ms preprocess, 42.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_1006_jpg.rf.f3a3c81a1ad91fc3f4432c9e3233a348.jpg: 640x640 2 persons, 1 motorcycle, 1 train, 1 truck, 1 boat, 42.7ms\n",
      "Speed: 0.8ms preprocess, 42.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-9_jpg.rf.85b15a3da946c2c749da4c447eaf1592.jpg: 640x640 8 persons, 1 motorcycle, 40.9ms\n",
      "Speed: 0.7ms preprocess, 40.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/REVZGCBIJNQPMIIXOKDCQA3GJI_jpg.rf.3124ccef91e9365ec39c23549e26d3ec.jpg: 640x640 6 persons, 41.2ms\n",
      "Speed: 0.7ms preprocess, 41.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-976-_jpg.rf.fc85a7cb525c1168c7ce7a7e26b53a07.jpg: 640x640 5 persons, 1 motorcycle, 1 train, 1 truck, 43.0ms\n",
      "Speed: 0.6ms preprocess, 43.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_704_jpg.rf.b020f3c4d3817254f832c3153d5d4047.jpg: 640x640 2 persons, 41.7ms\n",
      "Speed: 0.7ms preprocess, 41.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/235_jpg.rf.f5758d235eb011824ff40d7188b17bdf.jpg: 640x640 (no detections), 41.6ms\n",
      "Speed: 0.6ms preprocess, 41.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_875_jpg.rf.5deddf512753ad8bc975db3f71810b82.jpg: 640x640 1 person, 1 motorcycle, 1 truck, 40.9ms\n",
      "Speed: 0.7ms preprocess, 40.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RTX7CD4D-e1580252893876_jpg.rf.7781041fba565aa3f08b820e1220ad2e.jpg: 640x640 2 persons, 43.8ms\n",
      "Speed: 0.6ms preprocess, 43.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Inside-merge_mov-16_jpg.rf.7497b66a211972c0baaf43831553d347.jpg: 640x640 3 persons, 2 trucks, 39.6ms\n",
      "Speed: 0.6ms preprocess, 39.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-29_jpg.rf.3ab6fb82c7b98c1cdb491e40508707a8.jpg: 640x640 6 persons, 1 tie, 41.1ms\n",
      "Speed: 0.6ms preprocess, 41.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008600_jpg.rf.5fd794e6172b7258cb20bdefccf7af67.jpg: 640x640 1 person, 1 umbrella, 1 bottle, 1 pizza, 46.1ms\n",
      "Speed: 0.7ms preprocess, 46.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-75_jpg.rf.7d2e2174dc9edfdc8a1bab63ca89c39b.jpg: 640x640 1 person, 1 bus, 40.8ms\n",
      "Speed: 0.7ms preprocess, 40.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_620_jpg.rf.b3b9b3a6188d381d8b98f0f29f8cda3c.jpg: 640x640 1 motorcycle, 41.7ms\n",
      "Speed: 0.7ms preprocess, 41.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/135e-huxwryw6451820_jpg.rf.47219072cbbb4ed0d05bbfb4a495530a.jpg: 640x640 1 person, 41.5ms\n",
      "Speed: 0.7ms preprocess, 41.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-347-_jpg.rf.019a625d11ee3deb1aae360a2755d707.jpg: 640x640 10 persons, 1 surfboard, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mms_00691_jpg.rf.1d6b11c8456794ca415e4e5f1e96e807.jpg: 640x640 2 persons, 1 car, 39.3ms\n",
      "Speed: 0.6ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/w1240-p16x9-fa978043deff83fed485af12d16e39c61398fc30_jpg.rf.ed6e2c2cfd30a52bfeb2e2a7eafc93c0.jpg: 640x640 3 persons, 1 truck, 40.7ms\n",
      "Speed: 0.7ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-274_jpg.rf.cad3d673d4f2730f63202db35975429b.jpg: 640x640 4 persons, 41.9ms\n",
      "Speed: 0.6ms preprocess, 41.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/img_037_jpg.rf.174d9dde8845756e06baacc06c2098a3.jpg: 640x640 6 persons, 42.0ms\n",
      "Speed: 0.7ms preprocess, 42.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-519_jpg.rf.23a11f97358aa93798f743b3fa8d5ffb.jpg: 640x640 1 person, 39.0ms\n",
      "Speed: 0.6ms preprocess, 39.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-695_jpg.rf.8cb0e9aacc4be7b425ce1bac55459916.jpg: 640x640 2 persons, 42.8ms\n",
      "Speed: 0.6ms preprocess, 42.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/maksssksksss795_png_jpg.rf.59b5e25dc4ac635fe5a0ce57e87cbf99.jpg: 640x640 4 persons, 2 trains, 1 horse, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-860-_jpg.rf.8d0a63a9c38cadbae1e5c9ff94f2aa49.jpg: 640x640 1 person, 1 train, 4 trucks, 46.5ms\n",
      "Speed: 1.0ms preprocess, 46.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_191_jpg.rf.71069501abb9c1241f65f97034042a1c.jpg: 640x640 3 persons, 3 trucks, 1 bed, 43.3ms\n",
      "Speed: 0.7ms preprocess, 43.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-23_jpg.rf.ceb0438cf124f0128fd85d689bffe22d.jpg: 640x640 3 persons, 1 truck, 40.8ms\n",
      "Speed: 0.7ms preprocess, 40.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005577_jpg.rf.fef11b597712c48f52d5887ff414097d.jpg: 640x640 4 persons, 39.8ms\n",
      "Speed: 0.7ms preprocess, 39.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-360_jpg.rf.9bccf41e7070b3ed0f24dc61e71609a9.jpg: 640x640 2 persons, 42.3ms\n",
      "Speed: 0.7ms preprocess, 42.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-228_jpg.rf.c2556222492905d23da402b351eba2e5.jpg: 640x640 2 persons, 40.5ms\n",
      "Speed: 0.7ms preprocess, 40.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008652_jpg.rf.2ac7d064035687d4b82c8edeafbafd31.jpg: 640x640 2 persons, 1 chair, 43.5ms\n",
      "Speed: 0.6ms preprocess, 43.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_498_jpg.rf.76a2ee3fe770f86e7317163422598abf.jpg: 640x640 3 persons, 41.2ms\n",
      "Speed: 0.6ms preprocess, 41.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-188_jpg.rf.7ea2bff688373c2690369aa4b4d9862a.jpg: 640x640 1 person, 1 car, 2 trucks, 40.5ms\n",
      "Speed: 0.6ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1015-_jpg.rf.430489f60abd9b982a14dd7425e577c7.jpg: 640x640 1 person, 1 truck, 38.0ms\n",
      "Speed: 0.7ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-347-_jpg.rf.da66417ec4dc8d612f5613fa67c262c7.jpg: 640x640 1 traffic light, 2 benchs, 44.3ms\n",
      "Speed: 0.6ms preprocess, 44.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-229_jpg.rf.d5f55a3c41b3bbc9c0408db11fd3182f.jpg: 640x640 3 persons, 1 truck, 51.0ms\n",
      "Speed: 0.7ms preprocess, 51.0ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-189_jpg.rf.f2e4339a999eb718ff43ad57e06b4da6.jpg: 640x640 1 person, 1 traffic light, 42.9ms\n",
      "Speed: 1.3ms preprocess, 42.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/165_jpg.rf.8b803b2c10eb3a316412e867ee14eaf5.jpg: 640x640 2 persons, 1 car, 39.1ms\n",
      "Speed: 0.6ms preprocess, 39.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/707_jpg.rf.f80fe033acefd7b34b04a0cd7fd162db.jpg: 640x640 9 persons, 1 chair, 40.0ms\n",
      "Speed: 0.6ms preprocess, 40.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-44_jpg.rf.351f8c18ae37da178142849149686102.jpg: 640x640 1 car, 3 trucks, 40.9ms\n",
      "Speed: 0.7ms preprocess, 40.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-51_jpg.rf.454b78e6417bac086bca70a98b9f6f79.jpg: 640x640 1 person, 3 trucks, 1 boat, 1 horse, 46.5ms\n",
      "Speed: 0.6ms preprocess, 46.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/627_jpg.rf.1b053bc38bc4bb2037225b6bf402e93e.jpg: 640x640 2 bottles, 40.8ms\n",
      "Speed: 0.6ms preprocess, 40.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-12_jpg.rf.26f2ced069d37f4b768da48c5ef0f5e2.jpg: 640x640 1 person, 1 truck, 39.8ms\n",
      "Speed: 0.6ms preprocess, 39.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_937_jpg.rf.dfdffde0e8f3b3a59aa0db75a4fcc8dc.jpg: 640x640 1 person, 1 truck, 1 bottle, 1 tv, 48.2ms\n",
      "Speed: 0.6ms preprocess, 48.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.c0a0407a94e7eeb441a235b51752d178.jpg: 640x640 1 person, 1 airplane, 41.9ms\n",
      "Speed: 0.7ms preprocess, 41.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-1680-_png_jpg.rf.fc3fb462afe2de723f6bc348720198f5.jpg: 640x640 6 persons, 2 motorcycles, 1 chair, 41.9ms\n",
      "Speed: 0.6ms preprocess, 41.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/707_jpg.rf.bca714d4d4b04e93b580bf480cd071de.jpg: 640x640 2 persons, 44.9ms\n",
      "Speed: 0.8ms preprocess, 44.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/135e-huxwryw6451820_jpg.rf.c9c6258ad45ebf19f75149b6d5c69134.jpg: 640x640 4 persons, 1 train, 44.7ms\n",
      "Speed: 0.7ms preprocess, 44.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (9).jpeg: 288x640 2 persons, 23.4ms\n",
      "Speed: 0.6ms preprocess, 23.4ms inference, 0.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-137_jpg.rf.a761859e466a5a0599f0bb01c8742536.jpg: 640x640 2 persons, 1 cake, 42.2ms\n",
      "Speed: 0.7ms preprocess, 42.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-695_jpg.rf.2dc84311bfc79926ed58ca0b5842faf7.jpg: 640x640 1 person, 41.7ms\n",
      "Speed: 0.6ms preprocess, 41.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_002883_jpg.rf.41f48cf928eb3adba9c69e73c5b81e94.jpg: 640x640 3 persons, 5 bottles, 1 refrigerator, 41.9ms\n",
      "Speed: 0.6ms preprocess, 41.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_941_jpg.rf.9570ad17d6b6aea50acf4c523302de2c.jpg: 640x640 1 person, 1 car, 1 bus, 1 truck, 2 ties, 39.8ms\n",
      "Speed: 0.7ms preprocess, 39.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-89_jpg.rf.bfb1483dd3989a71df592291d66d94fe.jpg: 640x640 1 truck, 1 bird, 38.8ms\n",
      "Speed: 0.6ms preprocess, 38.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-507-_jpg.rf.61164c54bfdd0bb7f8b4ad85df86119f.jpg: 640x640 1 person, 1 train, 2 trucks, 1 cow, 1 refrigerator, 38.8ms\n",
      "Speed: 0.7ms preprocess, 38.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-242_jpg.rf.195cbbac8b1527fe62db390ae80f210f.jpg: 640x640 1 person, 3 trucks, 44.2ms\n",
      "Speed: 0.7ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-668_jpg.rf.4095d62a6fef2faf0b30f6434d8721e0.jpg: 640x640 2 persons, 1 car, 2 trucks, 1 handbag, 1 toothbrush, 40.9ms\n",
      "Speed: 0.6ms preprocess, 40.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-571_jpg.rf.445722ace33f1fd733756c215912b3a8.jpg: 640x640 1 person, 1 train, 1 sheep, 39.9ms\n",
      "Speed: 0.6ms preprocess, 39.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (4).jpeg: 448x640 1 person, 29.7ms\n",
      "Speed: 0.8ms preprocess, 29.7ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0449_jpg.rf.87b0d9fee1d40187fda42a192a59d5af.jpg: 640x640 2 bicycles, 3 trucks, 40.1ms\n",
      "Speed: 0.6ms preprocess, 40.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/1582_jpg.rf.484ffee7236baefd3d1e4434f99589b5.jpg: 640x640 1 train, 3 trucks, 1 traffic light, 1 cup, 46.0ms\n",
      "Speed: 0.6ms preprocess, 46.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox4_mp4-111_jpg.rf.007d84ad1f436206297bbc55b174fff9.jpg: 640x640 9 persons, 2 airplanes, 41.8ms\n",
      "Speed: 0.7ms preprocess, 41.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-618_jpg.rf.1657b2b21e87e95a776ec34f057b7a8b.jpg: 640x640 1 person, 1 bus, 1 truck, 1 cup, 1 mouse, 39.2ms\n",
      "Speed: 0.8ms preprocess, 39.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-228_jpg.rf.c84cc732daaafe38262dd837acb9f0a7.jpg: 640x640 5 persons, 1 skateboard, 40.2ms\n",
      "Speed: 0.7ms preprocess, 40.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-79_jpg.rf.cb6d55eeb92582ac4204e5799a080230.jpg: 640x640 2 persons, 39.8ms\n",
      "Speed: 0.6ms preprocess, 39.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-753-_jpg.rf.dd5aec5cecb776e35bf0f0b95627932f.jpg: 640x640 2 trucks, 1 fire hydrant, 1 suitcase, 40.7ms\n",
      "Speed: 0.7ms preprocess, 40.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-272_jpg.rf.5deef8fcfff4a93414b4051aefb4067f.jpg: 640x640 4 persons, 1 bicycle, 2 elephants, 1 chair, 41.9ms\n",
      "Speed: 0.6ms preprocess, 41.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/003184_jpg.rf.ff0c89d68480e029f33402d458c7531c.jpg: 640x640 5 persons, 1 boat, 41.5ms\n",
      "Speed: 0.7ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5848_jpg.rf.66334b93ee34ef38681c9b88f8b9c66a.jpg: 640x640 2 persons, 1 train, 38.2ms\n",
      "Speed: 0.6ms preprocess, 38.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-0_jpg.rf.5e50d287b0f246cc5f90e0db5ab5ec85.jpg: 640x640 4 persons, 2 cats, 41.4ms\n",
      "Speed: 0.7ms preprocess, 41.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_MOV-39_jpg.rf.20053de5df260249bf93e767a4c62c8b.jpg: 640x640 3 persons, 1 car, 39.7ms\n",
      "Speed: 0.7ms preprocess, 39.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-560-_jpg.rf.6c3e097caafb9f23de0e94b6bb9c9684.jpg: 640x640 2 persons, 2 buss, 2 trucks, 42.3ms\n",
      "Speed: 0.6ms preprocess, 42.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Mask2_mov-44_jpg.rf.43a0b2a020b8d09ce2449370403be44b.jpg: 640x640 9 persons, 47.6ms\n",
      "Speed: 0.7ms preprocess, 47.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/931_jpg.rf.fdd51314535382e1b440a98b49f060fd.jpg: 640x640 (no detections), 43.0ms\n",
      "Speed: 0.7ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_9949-1-_mp4-6_jpg.rf.8c85ef66b48a4e230dd2ce8138c9811d.jpg: 640x640 2 persons, 46.3ms\n",
      "Speed: 0.7ms preprocess, 46.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_740_jpg.rf.1cba9cb31d4c4bdae3a275b9491589b8.jpg: 640x640 7 persons, 1 truck, 40.4ms\n",
      "Speed: 0.6ms preprocess, 40.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-731_jpg.rf.ba052cf8e90a7e1ca93844b1730d152d.jpg: 640x640 2 persons, 1 truck, 1 boat, 38.9ms\n",
      "Speed: 0.6ms preprocess, 38.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-448_jpg.rf.08cb40c9d8a2813f6470fb2d2b1c61d4.jpg: 640x640 1 person, 1 train, 1 stop sign, 42.0ms\n",
      "Speed: 0.6ms preprocess, 42.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/istockphoto-1140837585-612x612.jpg: 448x640 3 persons, 30.4ms\n",
      "Speed: 0.9ms preprocess, 30.4ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/405_jpg.rf.0a37dfa7a6cc2efb13be8591aef13ca6.jpg: 640x640 1 clock, 39.4ms\n",
      "Speed: 0.6ms preprocess, 39.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-497_jpg.rf.fa62909c54b1927602668c56527571b4.jpg: 640x640 2 trucks, 37.2ms\n",
      "Speed: 0.6ms preprocess, 37.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-38_jpg.rf.c2c0e93cbde4fbde7e626a96ecfc03d8.jpg: 640x640 1 person, 1 airplane, 2 trucks, 1 traffic light, 39.5ms\n",
      "Speed: 0.6ms preprocess, 39.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2252-_png_jpg.rf.e294c55ec43d0a8f1eb80b7a52de697f.jpg: 640x640 6 persons, 42.9ms\n",
      "Speed: 0.6ms preprocess, 42.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3094_mp4-45_jpg.rf.c9ee577e1a6320f80e711a2d62a71ef0.jpg: 640x640 1 person, 2 trucks, 1 tv, 41.3ms\n",
      "Speed: 0.7ms preprocess, 41.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/video_CDC-YOUTUBE_mp4-50_jpg.rf.d2d78aa46f937c73fa1ebdb8c359face.jpg: 640x640 3 persons, 1 truck, 1 clock, 39.5ms\n",
      "Speed: 0.7ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/006118_jpg.rf.3bb10bffe280d9846dec2c95585a3658.jpg: 640x640 2 persons, 1 bottle, 43.8ms\n",
      "Speed: 0.7ms preprocess, 43.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-268-_jpg.rf.7f61f198051a137993ee8c2936c75ecb.jpg: 640x640 13 persons, 1 skateboard, 40.4ms\n",
      "Speed: 0.6ms preprocess, 40.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-57_jpg.rf.87a1f2203f761f29bdf0543239ec739d.jpg: 640x640 1 truck, 1 traffic light, 1 fire hydrant, 39.2ms\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-693-_jpg.rf.1b09f74fb2b1e1f685580241cb6c368f.jpg: 640x640 2 persons, 1 snowboard, 40.9ms\n",
      "Speed: 0.7ms preprocess, 40.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox6_mp4-20_jpg.rf.ba6134721c0c752e7142a6299d2f04e9.jpg: 640x640 3 persons, 2 couchs, 40.9ms\n",
      "Speed: 0.6ms preprocess, 40.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-127_jpg.rf.07956c5256292dc302a129cef45c39c0.jpg: 640x640 1 person, 1 truck, 44.9ms\n",
      "Speed: 0.6ms preprocess, 44.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/4c43875bc97cdaece84ac6ce555235f1_jpg.rf.8bffc5f836784d47dd928f9a50c72a2c.jpg: 640x640 2 persons, 1 refrigerator, 40.5ms\n",
      "Speed: 0.7ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Industrial-3-Part-Skymaster-insitu_jpg.rf.56bdfacf424d37bc7005ee6105f9f3f4.jpg: 640x640 2 persons, 2 trucks, 39.6ms\n",
      "Speed: 0.6ms preprocess, 39.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_000379_jpg.rf.f169216e75011872d9bbafd85c3b1010.jpg: 640x640 3 persons, 1 cup, 41.5ms\n",
      "Speed: 0.7ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1115-_jpg.rf.3e6520c600d6e3782916f8b157b8b46a.jpg: 640x640 1 person, 1 airplane, 1 truck, 39.5ms\n",
      "Speed: 0.6ms preprocess, 39.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_255_jpg.rf.b01b03cef655a3666e1152394a055b02.jpg: 640x640 1 person, 40.1ms\n",
      "Speed: 0.6ms preprocess, 40.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-46_jpg.rf.173fff469373f847a78f437636cbbfe7.jpg: 640x640 1 person, 45.4ms\n",
      "Speed: 0.7ms preprocess, 45.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (25).jpeg: 640x640 5 persons, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox6_mp4-20_jpg.rf.2ea83677536cb5929e57581ab983827b.jpg: 640x640 3 persons, 2 cars, 1 motorcycle, 44.6ms\n",
      "Speed: 0.7ms preprocess, 44.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/494_jpg.rf.4965b7246b576fccfc1032532369a048.jpg: 640x640 1 person, 1 chair, 1 book, 41.4ms\n",
      "Speed: 0.7ms preprocess, 41.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_93_jpg.rf.97948cc2b280754b3fb39d6b0318261a.jpg: 640x640 (no detections), 42.6ms\n",
      "Speed: 0.7ms preprocess, 42.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-41_jpg.rf.52ca8fcab8ce72c4dee7fefc91681934.jpg: 640x640 3 persons, 1 bus, 1 truck, 41.1ms\n",
      "Speed: 0.6ms preprocess, 41.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/video_CDC-YOUTUBE_mp4-50_jpg.rf.63232e24fd13597ca4fdd9895f0fbd0b.jpg: 640x640 9 persons, 1 truck, 1 dining table, 43.8ms\n",
      "Speed: 0.7ms preprocess, 43.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_743_jpg.rf.7619332475f77a5c1ad116257b1ecd9d.jpg: 640x640 1 person, 1 truck, 41.2ms\n",
      "Speed: 0.6ms preprocess, 41.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-726_jpg.rf.7ca57d637c5acb0d2772e0815a6d80e3.jpg: 640x640 1 person, 42.8ms\n",
      "Speed: 0.6ms preprocess, 42.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox4_mp4-112_jpg.rf.3b1a8122023b81e890aeff57ca8a1e04.jpg: 640x640 1 person, 44.8ms\n",
      "Speed: 0.6ms preprocess, 44.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Mask2_mov-44_jpg.rf.78134bef16472818ae01aaa08b2f9a65.jpg: 640x640 1 bed, 1 book, 43.1ms\n",
      "Speed: 0.7ms preprocess, 43.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-196_jpg.rf.b27679ce8ec2a7e46370da314efd0a44.jpg: 640x640 1 person, 46.0ms\n",
      "Speed: 0.8ms preprocess, 46.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-15_jpg.rf.1982fcb34cda55f30264c4e7c9cc5506.jpg: 640x640 3 persons, 1 parking meter, 1 book, 41.6ms\n",
      "Speed: 0.7ms preprocess, 41.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-571_jpg.rf.d380c7fde4b25c50887691ab5d5dcfac.jpg: 640x640 1 person, 1 car, 1 book, 44.1ms\n",
      "Speed: 0.7ms preprocess, 44.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (41).jpeg: 448x640 5 persons, 27.8ms\n",
      "Speed: 0.8ms preprocess, 27.8ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_074_jpg.rf.7f96a6a4219e4d934f7baf7cb8b4c41f.jpg: 640x640 3 persons, 39.6ms\n",
      "Speed: 0.7ms preprocess, 39.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-24_jpg.rf.09f84787b4dc125e5c1c7256d59b01aa.jpg: 640x640 2 persons, 40.3ms\n",
      "Speed: 0.7ms preprocess, 40.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_074_jpg.rf.d4fadd17507ab4d4dd45169d813be813.jpg: 640x640 1 person, 1 tie, 42.0ms\n",
      "Speed: 0.7ms preprocess, 42.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_662_jpg.rf.4987ba3969cb084b582b28d40cc841a8.jpg: 640x640 1 truck, 1 horse, 39.3ms\n",
      "Speed: 0.7ms preprocess, 39.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-832_jpg.rf.c023f5b9bb1c65636e5cab3064f7ab7b.jpg: 640x640 1 person, 1 truck, 40.4ms\n",
      "Speed: 0.8ms preprocess, 40.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-207_jpg.rf.dc738796008648ccf390c4bb1a721c76.jpg: 640x640 3 persons, 66.2ms\n",
      "Speed: 0.6ms preprocess, 66.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/004720_jpg.rf.2c90819deb7a595e4201b6be21fe29ec.jpg: 640x640 1 person, 1 truck, 47.1ms\n",
      "Speed: 0.7ms preprocess, 47.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (28).jpeg: 352x640 1 person, 1 dog, 30.2ms\n",
      "Speed: 0.6ms preprocess, 30.2ms inference, 0.5ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-499_jpg.rf.1c880d19f0139524ac072315afbada2d.jpg: 640x640 1 truck, 42.1ms\n",
      "Speed: 0.6ms preprocess, 42.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-14_jpg.rf.dda57d57a1548fc88345616715834657.jpg: 640x640 1 person, 2 cars, 1 refrigerator, 41.3ms\n",
      "Speed: 0.7ms preprocess, 41.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-395_jpg.rf.2aecddbbf7004c6240b8e0b20b6ad020.jpg: 640x640 1 person, 1 car, 1 truck, 46.5ms\n",
      "Speed: 0.7ms preprocess, 46.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-13_jpg.rf.8cf0592cc8621a5b9c3322bb071db031.jpg: 640x640 1 person, 1 truck, 1 stop sign, 42.5ms\n",
      "Speed: 0.6ms preprocess, 42.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-618_jpg.rf.215bc57133071439545a509f9f00d301.jpg: 640x640 9 persons, 1 handbag, 39.5ms\n",
      "Speed: 0.6ms preprocess, 39.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_000063_jpg.rf.c749876f44dd889271116bd4db04dc12.jpg: 640x640 8 persons, 1 bus, 41.8ms\n",
      "Speed: 0.6ms preprocess, 41.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1029-_jpg.rf.4b275026c8888b66ce2694d2dda856c3.jpg: 640x640 4 persons, 43.0ms\n",
      "Speed: 0.7ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-17_jpg.rf.2d4d89d339436c10ec2adc175b51b607.jpg: 640x640 1 dining table, 39.3ms\n",
      "Speed: 0.8ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_18_jpg.rf.f14536a170f479f50518e8d2e338ad10.jpg: 640x640 1 person, 1 chair, 40.8ms\n",
      "Speed: 0.6ms preprocess, 40.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (13).jpeg: 224x640 1 person, 19.8ms\n",
      "Speed: 0.5ms preprocess, 19.8ms inference, 0.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-187_jpg.rf.b93f4561b9a8e36014df11550075b9d4.jpg: 640x640 1 person, 41.3ms\n",
      "Speed: 0.6ms preprocess, 41.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1099-_jpg.rf.df1d160085e954901f2efa84fd4a2e91.jpg: 640x640 1 person, 1 truck, 50.4ms\n",
      "Speed: 0.7ms preprocess, 50.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-897-_jpg.rf.a26d42c31f4f84d40c077e063c6d5b0c.jpg: 640x640 4 persons, 1 car, 45.2ms\n",
      "Speed: 0.7ms preprocess, 45.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/bowling_0014_jpg.rf.d28f01392e1078bf8ad121aa9c94fcea.jpg: 640x640 1 person, 1 train, 2 trucks, 41.9ms\n",
      "Speed: 0.7ms preprocess, 41.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-829_jpg.rf.dea2669b7b26f62b24e48dbfcf6d28f3.jpg: 640x640 1 person, 1 truck, 1 bench, 40.6ms\n",
      "Speed: 0.7ms preprocess, 40.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1050-_jpg.rf.8da8dac323ed509151143b4251c66b6d.jpg: 640x640 2 persons, 48.5ms\n",
      "Speed: 0.6ms preprocess, 48.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-567_jpg.rf.d531bc4a7eb30dfe6bcaaf760ebad872.jpg: 640x640 2 persons, 1 car, 38.9ms\n",
      "Speed: 0.7ms preprocess, 38.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_498_jpg.rf.be7e844b9c7ed3a290bc19aa3be5ac20.jpg: 640x640 3 traffic lights, 41.1ms\n",
      "Speed: 0.6ms preprocess, 41.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.93dd6595c9b6f435a03af2e09588744c.jpg: 640x640 3 persons, 1 car, 2 trucks, 1 traffic light, 1 parking meter, 42.2ms\n",
      "Speed: 0.6ms preprocess, 42.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-15_jpg.rf.6b06d0ef6b013e80050b9224985a6e5d.jpg: 640x640 (no detections), 40.9ms\n",
      "Speed: 0.6ms preprocess, 40.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008753_jpg.rf.953a6b25662d9a832e9ef300e56edce9.jpg: 640x640 1 person, 1 bicycle, 39.8ms\n",
      "Speed: 0.6ms preprocess, 39.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-229_jpg.rf.72892899bc70a5c19c6313db73666df8.jpg: 640x640 2 persons, 1 airplane, 1 truck, 1 suitcase, 54.2ms\n",
      "Speed: 0.7ms preprocess, 54.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-170_jpg.rf.cc0e448b2db5c2583ed5a4de1b364edb.jpg: 640x640 2 persons, 1 bicycle, 1 car, 41.3ms\n",
      "Speed: 0.7ms preprocess, 41.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_418_jpg.rf.96b18c21f436813921dafcbd73075457.jpg: 640x640 1 person, 2 trucks, 41.5ms\n",
      "Speed: 0.7ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ins27_jpg.rf.21537e8ebf2f0a7fe02ebe6604272202.jpg: 640x640 (no detections), 46.8ms\n",
      "Speed: 0.6ms preprocess, 46.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_620_jpg.rf.8b25201db0567e624c5ee9b60f2bfc63.jpg: 640x640 1 truck, 1 fire hydrant, 1 horse, 45.9ms\n",
      "Speed: 0.7ms preprocess, 45.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008629_jpg.rf.85c2d54a785a02b9c6ee6e00321549aa.jpg: 640x640 1 person, 1 motorcycle, 1 truck, 43.0ms\n",
      "Speed: 0.8ms preprocess, 43.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_418_jpg.rf.d49e2182f8425681855e713b6d37839c.jpg: 640x640 1 car, 41.5ms\n",
      "Speed: 0.7ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2406-_png_jpg.rf.8819ae56f2a6b0101846514ded8ac8d7.jpg: 640x640 1 truck, 42.1ms\n",
      "Speed: 0.7ms preprocess, 42.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-809_jpg.rf.a21b56748f930ad24e3dd7c860430b22.jpg: 640x640 3 persons, 1 truck, 5 bottles, 1 refrigerator, 41.5ms\n",
      "Speed: 0.6ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Mask2_mov-44_jpg.rf.d4c35b8d62aefaf6f62f60c0a34a84aa.jpg: 640x640 1 potted plant, 2 scissorss, 1 toothbrush, 39.6ms\n",
      "Speed: 0.6ms preprocess, 39.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-682_jpg.rf.1b6032eab51a0902f1d56ff7425c5f2a.jpg: 640x640 7 persons, 1 truck, 41.6ms\n",
      "Speed: 0.6ms preprocess, 41.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-118-_jpg.rf.834d29e7ecd402dc301281478710eca5.jpg: 640x640 2 persons, 1 vase, 38.2ms\n",
      "Speed: 0.6ms preprocess, 38.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-699_jpg.rf.553ad81fae79c4e278ac25c772a9b9b8.jpg: 640x640 2 persons, 1 truck, 42.3ms\n",
      "Speed: 0.7ms preprocess, 42.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-0_jpg.rf.d2bb01a4ef36bd16b42499f4c8cad4d7.jpg: 640x640 3 persons, 44.9ms\n",
      "Speed: 0.6ms preprocess, 44.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-361_jpg.rf.76dc5c986bb992aa9aade5595df541d8.jpg: 640x640 1 person, 43.7ms\n",
      "Speed: 0.7ms preprocess, 43.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-228_jpg.rf.44fa319ea27db11bc2e5566fd4f72f3a.jpg: 640x640 1 person, 1 truck, 1 tie, 1 chair, 1 dining table, 44.5ms\n",
      "Speed: 0.7ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-10_jpg.rf.0438de9a621f30ef7c45cb49d9c4200c.jpg: 640x640 3 persons, 2 bicycles, 41.6ms\n",
      "Speed: 0.7ms preprocess, 41.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-435-_jpg.rf.8d45996f8bb473f29ce0b3733f40241b.jpg: 640x640 1 person, 2 trains, 1 truck, 1 suitcase, 41.2ms\n",
      "Speed: 0.7ms preprocess, 41.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_732_jpg.rf.af374ccbe8138d01281f7716a133c712.jpg: 640x640 3 trucks, 39.5ms\n",
      "Speed: 0.7ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-730_jpg.rf.16f81e031aa23796cb9714201fe841c8.jpg: 640x640 3 persons, 1 clock, 39.6ms\n",
      "Speed: 0.6ms preprocess, 39.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/006858_jpg.rf.fac7da50abd77496b63cb83cca271507.jpg: 640x640 2 persons, 1 chair, 2 cell phones, 38.6ms\n",
      "Speed: 0.6ms preprocess, 38.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-38_jpg.rf.2e5287c7925dbf5a8ef8422c0e6fee27.jpg: 640x640 1 person, 2 trucks, 1 potted plant, 2 books, 42.8ms\n",
      "Speed: 0.7ms preprocess, 42.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-15_jpg.rf.d8c4e4c2273020707d7d135ed2efb49a.jpg: 640x640 3 persons, 1 bottle, 42.5ms\n",
      "Speed: 0.6ms preprocess, 42.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-832_jpg.rf.ecb937433f6b83437779864849489079.jpg: 640x640 1 person, 45.3ms\n",
      "Speed: 0.8ms preprocess, 45.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/maksssksksss795_png_jpg.rf.e0d1ffebd3c883e5f78d371f2b12bb70.jpg: 640x640 7 persons, 1 horse, 47.2ms\n",
      "Speed: 0.7ms preprocess, 47.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (38).jpeg: 384x640 3 persons, 25.0ms\n",
      "Speed: 0.6ms preprocess, 25.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_120_jpg.rf.b4d103c7a293cc87c8ce4fda188d1096.jpg: 640x640 7 persons, 2 motorcycles, 1 cell phone, 44.9ms\n",
      "Speed: 0.6ms preprocess, 44.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-12_jpg.rf.303c49beb1cd6415e78e95affd27ec7e.jpg: 640x640 2 persons, 1 car, 2 trucks, 45.7ms\n",
      "Speed: 0.7ms preprocess, 45.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-246_jpg.rf.525a6596d54a9c90127b78128bb82855.jpg: 640x640 4 persons, 38.8ms\n",
      "Speed: 0.6ms preprocess, 38.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/01261_jpg.rf.ed956fe33a91f0a8537ffcbda6e8b3ab.jpg: 640x640 4 persons, 40.6ms\n",
      "Speed: 0.6ms preprocess, 40.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-448_jpg.rf.b29b6ae7868de9d3c673a9391e58eede.jpg: 640x640 2 persons, 2 trains, 1 truck, 38.1ms\n",
      "Speed: 0.7ms preprocess, 38.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-10_jpg.rf.83600aa22f9978a4f87c3f9fffc222d4.jpg: 640x640 3 persons, 40.0ms\n",
      "Speed: 0.6ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-1975-_png_jpg.rf.f0c6b10f9762a19849b0fb7f1654c001.jpg: 640x640 7 persons, 1 cake, 44.7ms\n",
      "Speed: 0.6ms preprocess, 44.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008652_jpg.rf.6b38069d24cf22969d271effcec92c03.jpg: 640x640 2 persons, 1 motorcycle, 39.4ms\n",
      "Speed: 0.6ms preprocess, 39.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/video_CDC-YOUTUBE_mp4-50_jpg.rf.95dcacf53d3e25b6eb8d595f84e47388.jpg: 640x640 1 person, 1 truck, 40.8ms\n",
      "Speed: 0.7ms preprocess, 40.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-376_jpg.rf.c61408e540dbf2dd48990d07543db9b4.jpg: 640x640 2 persons, 1 truck, 1 cake, 38.3ms\n",
      "Speed: 0.6ms preprocess, 38.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1050-_jpg.rf.f168e4351cfac6996af2ba1b29652cab.jpg: 640x640 4 persons, 59.5ms\n",
      "Speed: 3.5ms preprocess, 59.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0345_jpg.rf.e375bc7d5296cdb0c4f51f90c51c4b74.jpg: 640x640 2 persons, 46.5ms\n",
      "Speed: 0.6ms preprocess, 46.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1029-_jpg.rf.99a91e79d6e2bf58dc80922f7d7c3adf.jpg: 640x640 9 persons, 1 bus, 1 truck, 49.1ms\n",
      "Speed: 0.8ms preprocess, 49.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_16_jpg.rf.41406ef870f95a81bd1d0aa68c897b3f.jpg: 640x640 7 persons, 1 train, 40.3ms\n",
      "Speed: 0.6ms preprocess, 40.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-821-_jpg.rf.098b834846b3be5f1b24ef6dbc3a30a4.jpg: 640x640 1 bus, 2 bottles, 1 book, 42.1ms\n",
      "Speed: 0.7ms preprocess, 42.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2270-_png_jpg.rf.6455ef559e463c1fca6b0d6d69da3ffb.jpg: 640x640 3 persons, 39.4ms\n",
      "Speed: 0.6ms preprocess, 39.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_257_jpg.rf.bfff661ac6ac336ed8736646a4f214cb.jpg: 640x640 1 car, 2 trucks, 43.1ms\n",
      "Speed: 0.7ms preprocess, 43.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2406-_png_jpg.rf.90ca13003ffd103df1251e958b0fd135.jpg: 640x640 5 persons, 1 bus, 39.0ms\n",
      "Speed: 0.6ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-29_jpg.rf.b7652df82dc2ed8f6d3cf36fcebfe790.jpg: 640x640 4 persons, 1 backpack, 1 chair, 1 book, 44.6ms\n",
      "Speed: 0.7ms preprocess, 44.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-6_jpg.rf.216a0344d34eb56a4730e981474eecec.jpg: 640x640 3 persons, 41.8ms\n",
      "Speed: 0.6ms preprocess, 41.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-228_jpg.rf.29b0901283987da9bd0844bd373c2888.jpg: 640x640 1 person, 1 boat, 46.0ms\n",
      "Speed: 0.7ms preprocess, 46.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-161_jpg.rf.5d1e4d5a7f539b2e3c47ec2a8789bfad.jpg: 640x640 1 person, 43.6ms\n",
      "Speed: 0.7ms preprocess, 43.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-376_jpg.rf.c41c215d753588120c06cae7957ef83c.jpg: 640x640 1 person, 1 bus, 1 truck, 1 clock, 41.1ms\n",
      "Speed: 0.7ms preprocess, 41.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-628_jpg.rf.eacf6a98a4e100daf54a5ab254f0191b.jpg: 640x640 7 persons, 39.5ms\n",
      "Speed: 0.6ms preprocess, 39.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_1004_jpg.rf.70292dd6d2f3d96f832d44776dda9dab.jpg: 640x640 1 person, 1 tv, 39.4ms\n",
      "Speed: 0.6ms preprocess, 39.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-519_jpg.rf.ef7eac749be35c2cd30dcd8354de7a5d.jpg: 640x640 5 persons, 1 toothbrush, 41.6ms\n",
      "Speed: 0.6ms preprocess, 41.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-29_jpg.rf.0298ab1201345e2fe8afd06c0c7ca2c9.jpg: 640x640 4 persons, 1 airplane, 1 truck, 39.4ms\n",
      "Speed: 0.6ms preprocess, 39.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-813-_jpg.rf.b085952261fd98f2e76b8065de149b5f.jpg: 640x640 1 person, 1 motorcycle, 2 trucks, 39.7ms\n",
      "Speed: 0.7ms preprocess, 39.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-24_jpg.rf.f9e7803a7755260449de41f00a63c0a0.jpg: 640x640 3 persons, 45.3ms\n",
      "Speed: 0.6ms preprocess, 45.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-25_jpg.rf.3bbcfef23f20b2cf747256793dcfc615.jpg: 640x640 7 persons, 43.2ms\n",
      "Speed: 0.6ms preprocess, 43.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/p65621379_jpg.rf.5735572551e7f087e9ba38b09f0b3646.jpg: 640x640 1 person, 1 airplane, 1 toilet, 48.0ms\n",
      "Speed: 0.6ms preprocess, 48.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-94_jpg.rf.af104684c19a232f02c90552eaa84fbc.jpg: 640x640 1 person, 41.5ms\n",
      "Speed: 0.8ms preprocess, 41.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-1975-_png_jpg.rf.c2be4021c4d6452f7941be256160f957.jpg: 640x640 3 persons, 1 chair, 41.6ms\n",
      "Speed: 0.8ms preprocess, 41.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5024_mp4-2_jpg.rf.ef79470223ea72c2c2a7604795c2d3da.jpg: 640x640 1 car, 45.9ms\n",
      "Speed: 0.6ms preprocess, 45.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-18_jpg.rf.f881a0e8125381315c9391d4f03a13da.jpg: 640x640 (no detections), 39.2ms\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/006118_jpg.rf.68e3bf2321bb87ec786d9fd5d60cb2a5.jpg: 640x640 3 persons, 1 bicycle, 1 truck, 39.1ms\n",
      "Speed: 0.6ms preprocess, 39.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (29).jpeg: 480x640 1 person, 1 train, 29.3ms\n",
      "Speed: 0.8ms preprocess, 29.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-560_jpg.rf.bf09771b2e40ad774e1ccab9bb930919.jpg: 640x640 5 persons, 40.3ms\n",
      "Speed: 0.6ms preprocess, 40.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008629_jpg.rf.b1befa29d2154ce889608dac6a5a86b0.jpg: 640x640 2 bicycles, 1 car, 1 motorcycle, 2 buss, 2 trucks, 41.8ms\n",
      "Speed: 0.6ms preprocess, 41.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-295_jpg.rf.acc7e503322d516b86a0638f98f975b3.jpg: 640x640 1 car, 1 airplane, 1 truck, 38.9ms\n",
      "Speed: 0.6ms preprocess, 38.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-303_jpg.rf.9682cdf3e474e58bf4dd2d23cdf55d98.jpg: 640x640 1 person, 1 clock, 40.4ms\n",
      "Speed: 0.6ms preprocess, 40.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-682_jpg.rf.36e90cb60cd8dfe2db4f9442f5492264.jpg: 640x640 2 persons, 42.1ms\n",
      "Speed: 0.7ms preprocess, 42.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_31_jpg.rf.678c31291633a15b98915ef7cda5a516.jpg: 640x640 1 person, 1 umbrella, 43.4ms\n",
      "Speed: 0.6ms preprocess, 43.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-24_jpg.rf.e185f434f777196a7ee734b6cd6e3eee.jpg: 640x640 3 persons, 45.2ms\n",
      "Speed: 0.7ms preprocess, 45.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_181_jpg.rf.b618759936300d0504ae588b7177ee2d.jpg: 640x640 4 persons, 1 truck, 1 fire hydrant, 39.9ms\n",
      "Speed: 0.7ms preprocess, 39.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RTX7CD4D-e1580252893876_jpg.rf.566997198d6f8131f0a1b5447da17974.jpg: 640x640 8 persons, 1 suitcase, 42.5ms\n",
      "Speed: 0.7ms preprocess, 42.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-6_jpg.rf.dee1486806bef37ff0bc3ed372df81b3.jpg: 640x640 2 cars, 38.8ms\n",
      "Speed: 0.6ms preprocess, 38.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-242_jpg.rf.a071a5824b6c309c3360741639d653e8.jpg: 640x640 2 persons, 1 train, 1 truck, 43.0ms\n",
      "Speed: 0.6ms preprocess, 43.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5024_mp4-5_jpg.rf.3ff4b4132d97c95bc32540e903c5f440.jpg: 640x640 1 person, 2 cars, 4 trucks, 1 horse, 1 bed, 38.3ms\n",
      "Speed: 0.7ms preprocess, 38.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-212-_jpg.rf.78a7d836a9b79b59b0d51323619e63d9.jpg: 640x640 2 refrigerators, 10 books, 52.8ms\n",
      "Speed: 0.6ms preprocess, 52.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-305-_jpg.rf.d6bf62f198a43cec387208b956a3c8f7.jpg: 640x640 2 persons, 1 train, 1 truck, 1 boat, 43.0ms\n",
      "Speed: 0.6ms preprocess, 43.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/n457047_jpg.rf.a5f4e8326c8d7531216377815de4cf73.jpg: 640x640 2 persons, 1 handbag, 38.2ms\n",
      "Speed: 0.6ms preprocess, 38.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_9949-1-_mp4-6_jpg.rf.0bb75ac9a85641251373c96f54595fde.jpg: 640x640 1 car, 2 trucks, 1 traffic light, 43.3ms\n",
      "Speed: 0.6ms preprocess, 43.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_986_jpg.rf.2fd4acceeb217b24062956a847f7dc61.jpg: 640x640 3 persons, 1 chair, 45.1ms\n",
      "Speed: 0.7ms preprocess, 45.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-209_jpg.rf.45c339647db05b692016e826489f33f8.jpg: 640x640 (no detections), 41.1ms\n",
      "Speed: 0.6ms preprocess, 41.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008337_jpg.rf.5590da143ecce5f4a253645df18158c1.jpg: 640x640 7 persons, 1 bicycle, 1 horse, 39.3ms\n",
      "Speed: 0.7ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-115_jpg.rf.7afe87b728c11bfa2d6616ef75081e4c.jpg: 640x640 1 person, 2 umbrellas, 4 books, 39.0ms\n",
      "Speed: 0.7ms preprocess, 39.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-332_jpg.rf.bd2882f0188e4e96db55817563b57e2d.jpg: 640x640 1 person, 1 bus, 1 truck, 37.5ms\n",
      "Speed: 0.6ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5848_jpg.rf.f85d11dd4ca63822364c1c1ebb1c23db.jpg: 640x640 2 persons, 1 truck, 40.0ms\n",
      "Speed: 0.6ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/001425_jpg.rf.ee12b5cd77b14d4b6edbec28be0b9b28.jpg: 640x640 4 persons, 1 chair, 40.0ms\n",
      "Speed: 0.7ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-636_jpg.rf.964f510075988212d7b22be0cd7b80d8.jpg: 640x640 1 bottle, 1 vase, 39.1ms\n",
      "Speed: 0.6ms preprocess, 39.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-25_jpg.rf.30be35b92b01ff7ba8e43bd3b523dcbb.jpg: 640x640 2 persons, 1 bus, 40.5ms\n",
      "Speed: 0.6ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-24_jpg.rf.4534d237f8e29efbb855e646f6090edb.jpg: 640x640 6 persons, 39.7ms\n",
      "Speed: 0.6ms preprocess, 39.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-10_jpg.rf.f35004a03b5e89ec62256990ce533e87.jpg: 640x640 2 persons, 1 bench, 1 chair, 40.7ms\n",
      "Speed: 0.7ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-21_jpg.rf.f59f6ed232997892729b7bf27dbe0288.jpg: 640x640 3 persons, 43.8ms\n",
      "Speed: 0.8ms preprocess, 43.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-15_jpg.rf.a5fa6e719e0427f773a54c8d4cc19a1d.jpg: 640x640 4 persons, 42.6ms\n",
      "Speed: 0.8ms preprocess, 42.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-661_jpg.rf.b991a8491c63f29355527e6b436aeece.jpg: 640x640 3 trucks, 1 bottle, 1 refrigerator, 2 toothbrushs, 41.3ms\n",
      "Speed: 0.7ms preprocess, 41.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-3394-_png_jpg.rf.55aa7de8ec0bc72fd08ac6c23fd9e7a6.jpg: 640x640 1 truck, 1 tv, 44.7ms\n",
      "Speed: 0.7ms preprocess, 44.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-504_jpg.rf.8793f585bd8d7c256ee8bcef8b806dfd.jpg: 640x640 2 persons, 1 bicycle, 1 truck, 39.1ms\n",
      "Speed: 0.7ms preprocess, 39.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class1_253_jpg.rf.6f354ca9b3b40523fcd3c44e935ad835.jpg: 640x640 7 persons, 1 truck, 38.7ms\n",
      "Speed: 0.7ms preprocess, 38.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_120_jpg.rf.40fce375a47fcd49ce6150a3fb2aa2a9.jpg: 640x640 1 person, 1 car, 1 train, 2 trucks, 1 handbag, 40.9ms\n",
      "Speed: 0.6ms preprocess, 40.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-460_jpg.rf.29c7717ac21671bc4eb29482083484c7.jpg: 640x640 2 persons, 1 train, 41.9ms\n",
      "Speed: 0.7ms preprocess, 41.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-30_jpg.rf.7cf816e9a4e83c6d9a256ec0acdcb913.jpg: 640x640 1 person, 39.1ms\n",
      "Speed: 0.7ms preprocess, 39.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-148_jpg.rf.20ec335e8625ddb4da3d7d656718c1bd.jpg: 640x640 1 person, 39.9ms\n",
      "Speed: 0.7ms preprocess, 39.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-708-_jpg.rf.d7ef7ae688a4d558cb2f299e577775f9.jpg: 640x640 1 person, 1 truck, 1 toilet, 42.3ms\n",
      "Speed: 0.7ms preprocess, 42.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-135_jpg.rf.6999ef662dd514389ed19622a37a2a93.jpg: 640x640 2 persons, 1 train, 2 trucks, 51.1ms\n",
      "Speed: 0.6ms preprocess, 51.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1099-_jpg.rf.aadb8d817921f24038d2f6ecd0a78b75.jpg: 640x640 1 person, 44.8ms\n",
      "Speed: 0.7ms preprocess, 44.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-385-_jpg.rf.d59ccb2166c957d8483378da1a273bbd.jpg: 640x640 2 persons, 1 motorcycle, 1 truck, 1 fire hydrant, 40.3ms\n",
      "Speed: 0.8ms preprocess, 40.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-10_jpg.rf.eb5cded28302977870c452bf3b1df11e.jpg: 640x640 3 persons, 1 chair, 39.6ms\n",
      "Speed: 0.6ms preprocess, 39.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_721_jpg.rf.6a8f6d3cde1115ffb9a796d78ba2b4fe.jpg: 640x640 3 persons, 1 truck, 1 handbag, 39.3ms\n",
      "Speed: 0.8ms preprocess, 39.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005139_jpg.rf.df5b20b4373e6e301b010eda32f8ea3f.jpg: 640x640 5 persons, 1 truck, 39.0ms\n",
      "Speed: 0.7ms preprocess, 39.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_002711_jpg.rf.f0563c83394a79e936b0ecec2658ec97.jpg: 640x640 3 persons, 1 bottle, 40.5ms\n",
      "Speed: 0.6ms preprocess, 40.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-10_jpg.rf.810515f8a9482007ff07d4d5d5126252.jpg: 640x640 1 person, 42.5ms\n",
      "Speed: 0.6ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-741-_jpg.rf.38144cb2f377dbac8fedb2d4146fe527.jpg: 640x640 1 bus, 66.7ms\n",
      "Speed: 0.6ms preprocess, 66.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ins27_jpg.rf.3528045206c6b33291620e4638378ffd.jpg: 640x640 1 tv, 1 laptop, 52.4ms\n",
      "Speed: 0.6ms preprocess, 52.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-188_jpg.rf.222a8ed73f017be9b2c3fb6c9e250bca.jpg: 640x640 3 persons, 43.4ms\n",
      "Speed: 0.8ms preprocess, 43.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-385-_jpg.rf.ea84b7922f7cd0d24543b4692b698501.jpg: 640x640 7 persons, 1 bus, 1 truck, 2 ties, 45.5ms\n",
      "Speed: 0.7ms preprocess, 45.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-175_jpg.rf.ba471e0986c08a35632797168134f08b.jpg: 640x640 2 persons, 1 bus, 1 parking meter, 43.9ms\n",
      "Speed: 0.7ms preprocess, 43.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (8).jpeg: 480x640 2 boats, 37.6ms\n",
      "Speed: 0.8ms preprocess, 37.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/616_jpg.rf.440e1d2885969b920d1115e4dd9c95d3.jpg: 640x640 8 persons, 1 horse, 46.4ms\n",
      "Speed: 0.6ms preprocess, 46.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-1680-_png_jpg.rf.19e88a5022427045071da3f267825d67.jpg: 640x640 4 persons, 41.1ms\n",
      "Speed: 0.7ms preprocess, 41.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-615_jpg.rf.b0753ed0c5d860dca0ccfdaf074820bb.jpg: 640x640 2 persons, 4 bottles, 1 refrigerator, 41.7ms\n",
      "Speed: 0.6ms preprocess, 41.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-855-_jpg.rf.0867d4ce5a9cc9d8f87bd90a5214c7eb.jpg: 640x640 1 person, 2 motorcycles, 1 truck, 1 surfboard, 42.6ms\n",
      "Speed: 0.6ms preprocess, 42.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-118-_jpg.rf.7a2b5be851d660f3f995a625cfbede03.jpg: 640x640 1 person, 1 airplane, 39.9ms\n",
      "Speed: 0.6ms preprocess, 39.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-897-_jpg.rf.b1bd9732b4098eac183a82595f21199b.jpg: 640x640 1 person, 1 train, 1 truck, 38.9ms\n",
      "Speed: 0.6ms preprocess, 38.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-42_jpg.rf.3310ac1e447d6d4971d1237670eeabc0.jpg: 640x640 1 person, 1 bicycle, 1 motorcycle, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_757_jpg.rf.61abe73fc97e8ee6c23a1317c898234c.jpg: 640x640 1 person, 2 cars, 1 train, 1 truck, 40.0ms\n",
      "Speed: 0.6ms preprocess, 40.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-267-_jpg.rf.222246f7ce5e3109de00144c4f603292.jpg: 640x640 1 person, 1 car, 1 toilet, 41.7ms\n",
      "Speed: 0.7ms preprocess, 41.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-188_jpg.rf.751f7dc08b4a79d9c1fdc4b67fbbb4df.jpg: 640x640 (no detections), 42.9ms\n",
      "Speed: 0.7ms preprocess, 42.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-849_jpg.rf.accc9afdf3e1d7e90118b655646b6266.jpg: 640x640 1 person, 46.6ms\n",
      "Speed: 0.6ms preprocess, 46.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-10_jpg.rf.ab20fda596db2bee8ea7b28eca640c21.jpg: 640x640 1 person, 41.9ms\n",
      "Speed: 0.7ms preprocess, 41.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0550_jpg.rf.e4d7eb4a0f8870365fb2518f58e17459.jpg: 640x640 2 persons, 1 bench, 1 horse, 1 tv, 40.7ms\n",
      "Speed: 0.7ms preprocess, 40.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008618_jpg.rf.31e87a24eebedbd40bb9b22f0d0fe788.jpg: 640x640 1 train, 2 trucks, 43.6ms\n",
      "Speed: 0.6ms preprocess, 43.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-3_jpg.rf.b57a67cc9edcb3ac7ee87b2e14e56605.jpg: 640x640 1 person, 1 train, 40.6ms\n",
      "Speed: 0.7ms preprocess, 40.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-872-_jpg.rf.d28124ddcbb715b1005b49b71d8019da.jpg: 640x640 1 truck, 40.5ms\n",
      "Speed: 0.6ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008618_jpg.rf.11fe8e58330bb2d014dcd6c04cdc04af.jpg: 640x640 1 train, 1 truck, 1 chair, 42.3ms\n",
      "Speed: 0.6ms preprocess, 42.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-14_jpg.rf.d268b03dd1f2e079d15f38ceba312178.jpg: 640x640 1 person, 5 cars, 2 trucks, 39.4ms\n",
      "Speed: 0.7ms preprocess, 39.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/002654_jpg.rf.ff1deb021121bfef83e8a9152093596e.jpg: 640x640 2 persons, 1 motorcycle, 1 horse, 41.9ms\n",
      "Speed: 0.6ms preprocess, 41.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-187_jpg.rf.0aeddf391e62f89eb388ecc1dee1fdc2.jpg: 640x640 2 persons, 1 train, 1 truck, 1 elephant, 43.7ms\n",
      "Speed: 0.7ms preprocess, 43.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-986-_jpg.rf.abee995f420532ca7f4f0a1fa4b5ac7d.jpg: 640x640 2 persons, 1 bus, 3 trucks, 39.0ms\n",
      "Speed: 0.7ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Nhh_img_141_jpg.rf.b3b99b5e377f3992e933b2e200d6c05c.jpg: 640x640 3 persons, 1 train, 1 dog, 1 sheep, 1 chair, 1 refrigerator, 38.2ms\n",
      "Speed: 0.6ms preprocess, 38.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_678_jpg.rf.e1fd3af4360ff5291b3d6754a5e2ca98.jpg: 640x640 1 person, 2 bottles, 42.6ms\n",
      "Speed: 0.6ms preprocess, 42.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-234_jpg.rf.ac9a9ba63409a21e875187ccdb02a91b.jpg: 640x640 2 persons, 42.4ms\n",
      "Speed: 0.6ms preprocess, 42.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_622_jpg.rf.1b8c8b100526f72f09884c1cec3c43c5.jpg: 640x640 2 persons, 1 bicycle, 2 trucks, 51.0ms\n",
      "Speed: 1.0ms preprocess, 51.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_1037_jpg.rf.0fc0c99ae85a9af8a943b77ccd7c5c6c.jpg: 640x640 1 car, 1 truck, 1 traffic light, 1 fire hydrant, 40.9ms\n",
      "Speed: 0.7ms preprocess, 40.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-48_jpg.rf.4fdbba397c6dbde429373640d634e935.jpg: 640x640 1 person, 1 truck, 1 traffic light, 41.3ms\n",
      "Speed: 0.6ms preprocess, 41.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-166_jpg.rf.1ce1984044499b830a524061c57bfb7c.jpg: 640x640 1 person, 1 bicycle, 1 train, 2 trucks, 1 tv, 5 books, 38.5ms\n",
      "Speed: 0.6ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-165_jpg.rf.245a89fb6862ed44d8698e334777bc6d.jpg: 640x640 2 trucks, 1 boat, 40.2ms\n",
      "Speed: 0.6ms preprocess, 40.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-497_jpg.rf.15a2d595c0c22f68de5da8b27891c29d.jpg: 640x640 2 clocks, 42.3ms\n",
      "Speed: 0.6ms preprocess, 42.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-207_jpg.rf.9e0f85119e6ae22ff1c5fa5272606c5c.jpg: 640x640 3 persons, 1 truck, 39.0ms\n",
      "Speed: 0.6ms preprocess, 39.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/000415_jpg.rf.63b7e0293fb53612fdb4695fa0debfb7.jpg: 640x640 2 persons, 40.8ms\n",
      "Speed: 0.7ms preprocess, 40.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/002654_jpg.rf.f10456662b75b3d34e02a4db9cdf36a2.jpg: 640x640 1 person, 1 bird, 38.9ms\n",
      "Speed: 0.6ms preprocess, 38.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class5_012_jpg.rf.94da244a7179a22b22715a0a69a1086b.jpg: 640x640 2 persons, 43.2ms\n",
      "Speed: 0.7ms preprocess, 43.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-384_jpg.rf.0bcf89652762afb44edadfaf2690b3ac.jpg: 640x640 2 persons, 1 truck, 1 bottle, 42.8ms\n",
      "Speed: 0.7ms preprocess, 42.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/598_jpg.rf.18076700a0d087010905850e75759dd0.jpg: 640x640 1 person, 1 truck, 1 bottle, 42.5ms\n",
      "Speed: 0.7ms preprocess, 42.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-345_jpg.rf.acf10b19ca143688581071905c336f1d.jpg: 640x640 2 persons, 44.2ms\n",
      "Speed: 0.6ms preprocess, 44.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_18_jpg.rf.9be3756f23d3a5e6f69968bff1830bfa.jpg: 640x640 6 persons, 1 bird, 1 cat, 41.3ms\n",
      "Speed: 0.7ms preprocess, 41.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/istockphoto-879813818-612x612.jpg: 384x640 2 persons, 3 laptops, 26.5ms\n",
      "Speed: 0.8ms preprocess, 26.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_740_jpg.rf.49eabcd34fc8c43bde0320f3aebff84d.jpg: 640x640 1 car, 1 truck, 39.5ms\n",
      "Speed: 0.7ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-235_jpg.rf.186371c5383e0dbaaa3f71f3f3dab88c.jpg: 640x640 1 person, 1 truck, 41.7ms\n",
      "Speed: 0.6ms preprocess, 41.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-579_jpg.rf.db114ff0f07961521749739faca4fbcb.jpg: 640x640 1 person, 1 truck, 42.0ms\n",
      "Speed: 0.6ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-348_jpg.rf.f0c0935c79f1c2b59a63daa2b24ec45a.jpg: 640x640 1 truck, 1 clock, 40.4ms\n",
      "Speed: 0.7ms preprocess, 40.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_498_jpg.rf.635c6a6b76f2377a87be191023c9f3a9.jpg: 640x640 1 truck, 40.1ms\n",
      "Speed: 0.6ms preprocess, 40.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox6_mp4-80_jpg.rf.e170abed2946f1e3909ce9747becd353.jpg: 640x640 2 persons, 1 car, 65.4ms\n",
      "Speed: 0.6ms preprocess, 65.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2544-_png_jpg.rf.185d1d1c0cb4027d76f7e31cd409022e.jpg: 640x640 3 persons, 45.3ms\n",
      "Speed: 0.6ms preprocess, 45.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2270-_png_jpg.rf.fb11c18eea1ddb410b1b561de012a9f9.jpg: 640x640 2 persons, 1 truck, 41.9ms\n",
      "Speed: 0.7ms preprocess, 41.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/istockphoto-1406716242-612x612.jpg: 448x640 1 person, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/MariusConePic60_png_jpg.rf.e3c78bec7f9d53c0d0b9c7107c9d4dbd.jpg: 640x640 1 person, 1 toothbrush, 42.3ms\n",
      "Speed: 0.7ms preprocess, 42.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ezgif-frame-049_jpg.rf.c7ef5dafa9ce1349c1f59b7ccb2133f6.jpg: 640x640 3 persons, 1 carrot, 39.1ms\n",
      "Speed: 0.7ms preprocess, 39.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_39_jpg.rf.52fe6910795b92e2aac4d25c1ff72722.jpg: 640x640 (no detections), 40.6ms\n",
      "Speed: 0.6ms preprocess, 40.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_875_jpg.rf.0f5439432d802c7229752bf569e7abc6.jpg: 640x640 3 trucks, 42.1ms\n",
      "Speed: 0.6ms preprocess, 42.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-274_jpg.rf.068d680d7bafd5c0eddc15709b40c8ae.jpg: 640x640 2 persons, 1 cake, 41.6ms\n",
      "Speed: 0.7ms preprocess, 41.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005239_jpg.rf.b30f66b565561c64979bb7869ab4a970.jpg: 640x640 4 persons, 1 truck, 38.0ms\n",
      "Speed: 0.7ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-197_jpg.rf.7f0d9cdc6064fb94be0392bea9c984e7.jpg: 640x640 1 person, 2 chairs, 40.3ms\n",
      "Speed: 0.7ms preprocess, 40.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-855-_jpg.rf.cb8a1e10b97872d70496957076780658.jpg: 640x640 1 person, 1 truck, 1 clock, 53.6ms\n",
      "Speed: 0.7ms preprocess, 53.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5851_jpg.rf.c06261164b51386e1e8f6019cddd44dc.jpg: 640x640 7 persons, 1 toilet, 40.6ms\n",
      "Speed: 0.7ms preprocess, 40.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_255_jpg.rf.5037331638f2a0af78d018b8a719dfd9.jpg: 640x640 1 person, 2 trains, 45.1ms\n",
      "Speed: 0.7ms preprocess, 45.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_302_jpg.rf.4b76d28e9817d77daf35b3ba59dc4c4c.jpg: 640x640 2 persons, 3 trucks, 46.8ms\n",
      "Speed: 0.7ms preprocess, 46.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_093_jpg.rf.b48cd3eb2f144761b47c5bde4214a34f.jpg: 640x640 2 persons, 1 truck, 40.3ms\n",
      "Speed: 0.6ms preprocess, 40.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mo-justin-mask-NoMask_mov-34_jpg.rf.4e6773ec3cd044e328b6a0b1a7d08fca.jpg: 640x640 3 persons, 1 truck, 1 bird, 41.0ms\n",
      "Speed: 0.7ms preprocess, 41.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_191_jpg.rf.6696088664acbaad513226dc2962d19b.jpg: 640x640 1 person, 3 cars, 2 trucks, 1 dog, 1 tv, 2 books, 39.6ms\n",
      "Speed: 0.7ms preprocess, 39.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-207-_jpg.rf.d13e5186c072bfb87375bd06bfcf6414.jpg: 640x640 4 persons, 2 bicycles, 38.2ms\n",
      "Speed: 0.6ms preprocess, 38.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_9949-1-_mp4-24_jpg.rf.f1b40eef5d1dface15afbb3d296fb4c9.jpg: 640x640 5 persons, 40.2ms\n",
      "Speed: 0.7ms preprocess, 40.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-409_jpg.rf.131f18f30d7fe2bb76dd876d0e3f1941.jpg: 640x640 1 person, 1 truck, 39.2ms\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ins27_jpg.rf.89c98c782f6fc1aab397a1ca44a4af62.jpg: 640x640 (no detections), 46.2ms\n",
      "Speed: 0.8ms preprocess, 46.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-730_jpg.rf.dc8771c0575bb38ba15221310f1eb78b.jpg: 640x640 1 person, 2 motorcycles, 1 chair, 39.8ms\n",
      "Speed: 0.6ms preprocess, 39.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class1_199_jpg.rf.2250978db6c0152db7ef02b384754b37.jpg: 640x640 3 persons, 1 bicycle, 1 train, 44.5ms\n",
      "Speed: 0.7ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_880_jpg.rf.be962d8d02f0e9f8c7fb77cb53594529.jpg: 640x640 2 persons, 1 truck, 47.0ms\n",
      "Speed: 0.7ms preprocess, 47.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/bookstore_38_02_altavista_jpg.rf.79035ad5581fdab7e754f904debfb905.jpg: 640x640 1 motorcycle, 1 traffic light, 1 bottle, 42.3ms\n",
      "Speed: 0.7ms preprocess, 42.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_965_jpg.rf.8b7c66f34e00b05933f757a76493ad84.jpg: 640x640 2 persons, 2 trucks, 43.2ms\n",
      "Speed: 0.7ms preprocess, 43.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-242_jpg.rf.91b9d0cecaa2c686c4c49a7d21e5c02b.jpg: 640x640 2 persons, 1 truck, 41.7ms\n",
      "Speed: 0.7ms preprocess, 41.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-207-_jpg.rf.8a3fce7280ed193217b1b4e9bc472c32.jpg: 640x640 1 person, 39.0ms\n",
      "Speed: 0.7ms preprocess, 39.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-136_jpg.rf.4de970ffc60aa2cda3fb97f03350384a.jpg: 640x640 4 persons, 1 truck, 1 cat, 41.3ms\n",
      "Speed: 0.7ms preprocess, 41.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-731_jpg.rf.e4515115515cca8190fc1dca7f73256b.jpg: 640x640 2 persons, 1 truck, 42.0ms\n",
      "Speed: 0.7ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-161_jpg.rf.414bb7266d8b44f253dab7b65d7da37c.jpg: 640x640 1 person, 1 suitcase, 1 frisbee, 1 book, 45.7ms\n",
      "Speed: 0.7ms preprocess, 45.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ins27_jpg.rf.7f942b588422984e5543ddf5add7b2f0.jpg: 640x640 1 person, 2 trucks, 39.7ms\n",
      "Speed: 0.6ms preprocess, 39.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class1_075_jpg.rf.2a22da3708b1c7ba80a4da925984f48f.jpg: 640x640 2 persons, 1 cell phone, 40.6ms\n",
      "Speed: 0.7ms preprocess, 40.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-24_jpg.rf.b29ff2e9363136c15ab19cac4cda72b5.jpg: 640x640 1 person, 1 car, 41.0ms\n",
      "Speed: 0.6ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-806_jpg.rf.c0abadb1a80331958e9b2f0fcdc99469.jpg: 640x640 2 persons, 1 traffic light, 1 bench, 1 horse, 41.4ms\n",
      "Speed: 0.6ms preprocess, 41.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-219_jpg.rf.d00dcbb1681782b09b105dd0c54d5852.jpg: 640x640 2 persons, 1 truck, 5 bottles, 1 toilet, 1 refrigerator, 46.6ms\n",
      "Speed: 0.6ms preprocess, 46.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-295_jpg.rf.6e615d6498ce08c4a73bde83d5a55a89.jpg: 640x640 4 persons, 1 car, 1 tie, 43.4ms\n",
      "Speed: 0.6ms preprocess, 43.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/002458_jpg.rf.5920dd0b127455ba3892de5ce09611e2.jpg: 640x640 1 train, 43.6ms\n",
      "Speed: 0.7ms preprocess, 43.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/165_jpg.rf.8e28e2ec55d7ab727f8a5cd072024dd2.jpg: 640x640 2 persons, 1 refrigerator, 41.6ms\n",
      "Speed: 0.8ms preprocess, 41.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/additional_tests-Nomask-wearing_mp4-35_jpg.rf.577a53ee9e1896cee0ff0fcfddd4b937.jpg: 640x640 2 persons, 51.1ms\n",
      "Speed: 0.6ms preprocess, 51.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/helmet999863_jpg.rf.532399683d5b56a404e935b18b13b9c3.jpg: 640x640 4 persons, 1 train, 3 trucks, 39.7ms\n",
      "Speed: 0.6ms preprocess, 39.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-253-_jpg.rf.0590780a5e0f86c9f306c71d7c3a3c6b.jpg: 640x640 2 persons, 1 truck, 37.4ms\n",
      "Speed: 0.6ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-396_jpg.rf.b4ba18ab11ba9100d19819e75a887129.jpg: 640x640 2 persons, 1 car, 41.7ms\n",
      "Speed: 0.6ms preprocess, 41.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/bowling_0014_jpg.rf.fa3a779743c3d783023951b5bfc09916.jpg: 640x640 1 person, 1 train, 1 truck, 41.5ms\n",
      "Speed: 0.7ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-837_jpg.rf.1b09fa4284f78dbb865099f70462cfad.jpg: 640x640 9 persons, 39.6ms\n",
      "Speed: 0.6ms preprocess, 39.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-568_jpg.rf.49f1d5b90378ee7a8dbd85b799bfa32d.jpg: 640x640 2 persons, 1 cell phone, 66.2ms\n",
      "Speed: 0.6ms preprocess, 66.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-622_jpg.rf.c2168764d6c0902f3aeeda7ea0706c24.jpg: 640x640 5 persons, 1 motorcycle, 1 truck, 1 handbag, 42.7ms\n",
      "Speed: 0.8ms preprocess, 42.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/video_CDC-YOUTUBE_mp4-60_jpg.rf.85c79ff93408a87d693176464971b524.jpg: 640x640 2 persons, 1 airplane, 1 truck, 43.7ms\n",
      "Speed: 0.7ms preprocess, 43.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/video_CDC-YOUTUBE_mp4-60_jpg.rf.6f1bb05f4532d86f30b8df6f5936fdc7.jpg: 640x640 1 person, 41.5ms\n",
      "Speed: 0.7ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_743_jpg.rf.c95f7066332dd202339051309e82d4eb.jpg: 640x640 1 person, 41.6ms\n",
      "Speed: 0.7ms preprocess, 41.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-396_jpg.rf.caa896f1df9fbadcefce4fe79a8be683.jpg: 640x640 4 persons, 1 parking meter, 1 dog, 1 surfboard, 39.9ms\n",
      "Speed: 0.7ms preprocess, 39.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-435_jpg.rf.6aa12c0a2e7658ba820900145dbb7b2d.jpg: 640x640 1 cow, 39.8ms\n",
      "Speed: 0.6ms preprocess, 39.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-60_jpg.rf.30b09a8c2865e4922520e7d022dd9c61.jpg: 640x640 1 person, 41.8ms\n",
      "Speed: 0.6ms preprocess, 41.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-113_jpg.rf.377be4d7db46984bac62a282d7db22f4.jpg: 640x640 1 person, 2 cars, 2 airplanes, 1 truck, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-409_jpg.rf.6c7eb5bd2a8543b62192a69b7cdf6e22.jpg: 640x640 3 persons, 1 truck, 41.6ms\n",
      "Speed: 0.7ms preprocess, 41.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-266_jpg.rf.94c0d2c8c89f261c57fc1b1997e60f0a.jpg: 640x640 2 persons, 37.9ms\n",
      "Speed: 0.7ms preprocess, 37.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/60_jpg.rf.5827b492f3c06df6e2572f69866a3b49.jpg: 640x640 1 person, 1 train, 1 traffic light, 1 fire hydrant, 1 chair, 1 potted plant, 1 refrigerator, 40.9ms\n",
      "Speed: 0.6ms preprocess, 40.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/002682_jpg.rf.b5f6e4d4f429c574db5367b57dad17ff.jpg: 640x640 3 persons, 41.7ms\n",
      "Speed: 0.6ms preprocess, 41.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-547-_jpg.rf.06ac6a710305132de8e64a49e4ec05b8.jpg: 640x640 1 person, 40.4ms\n",
      "Speed: 0.6ms preprocess, 40.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_560_jpg.rf.cec604e4e8173d635fc4c4170df9d739.jpg: 640x640 4 persons, 1 train, 1 bed, 50.6ms\n",
      "Speed: 0.7ms preprocess, 50.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/129_jpg.rf.0cb07be3237753e24204a014ebee12a0.jpg: 640x640 1 truck, 1 suitcase, 1 bottle, 41.5ms\n",
      "Speed: 0.7ms preprocess, 41.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_829_jpg.rf.b2c6df2ec1d3dbe9e43ab5f86c21fad0.jpg: 640x640 6 persons, 1 bicycle, 1 dog, 1 tie, 42.8ms\n",
      "Speed: 0.7ms preprocess, 42.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_288_jpg.rf.f6f38c0bae911e5f24207dc97476307a.jpg: 640x640 1 train, 1 truck, 45.2ms\n",
      "Speed: 0.6ms preprocess, 45.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-178_jpg.rf.79f0a5b662d06a476cc9a5c9ff703edc.jpg: 640x640 1 person, 1 bus, 1 truck, 41.8ms\n",
      "Speed: 0.6ms preprocess, 41.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-0_jpg.rf.5eb18cc65358b70ee602eafa99f2ff54.jpg: 640x640 4 persons, 1 cat, 38.0ms\n",
      "Speed: 0.7ms preprocess, 38.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_991_jpg.rf.9966252c3fda2a50e25e9db82132e6a3.jpg: 640x640 1 person, 2 cars, 2 trucks, 1 suitcase, 40.8ms\n",
      "Speed: 0.6ms preprocess, 40.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/707_jpg.rf.db3baced2a7a966138cf88c7cb95f522.jpg: 640x640 2 persons, 1 potted plant, 1 book, 40.4ms\n",
      "Speed: 0.6ms preprocess, 40.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-710_jpg.rf.676309e8bb0b7465a6fc6ae233c91011.jpg: 640x640 3 persons, 1 dog, 54.6ms\n",
      "Speed: 0.7ms preprocess, 54.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-135_jpg.rf.f7409d777b9b29b4565546cde4ffa927.jpg: 640x640 1 person, 2 cars, 1 truck, 48.4ms\n",
      "Speed: 0.6ms preprocess, 48.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-127_jpg.rf.c8b5b8cd660a766336ecfcf953fe4305.jpg: 640x640 1 truck, 40.5ms\n",
      "Speed: 0.6ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0015_jpg.rf.1637e0c40555dc87aec1266445b69e23.jpg: 640x640 2 persons, 1 train, 43.5ms\n",
      "Speed: 0.8ms preprocess, 43.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-267-_jpg.rf.ec6899b2550e859e6ffc075cd1903202.jpg: 640x640 1 person, 2 cars, 1 truck, 1 tie, 46.4ms\n",
      "Speed: 0.7ms preprocess, 46.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-497_jpg.rf.e0f0250ef7939eb4813e9b2f57b1a5ff.jpg: 640x640 2 persons, 43.7ms\n",
      "Speed: 0.7ms preprocess, 43.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-224_jpg.rf.0e87e77b917fae082722bc8e324092f5.jpg: 640x640 2 persons, 1 truck, 1 toilet, 38.5ms\n",
      "Speed: 0.7ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-38_jpg.rf.b6b2776f594852b65c5a0a6e7c1fc9d2.jpg: 640x640 1 toilet, 39.2ms\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2252-_png_jpg.rf.a71a293e8fb2e65c9b851ee278fbc4c0.jpg: 640x640 2 persons, 1 car, 2 motorcycles, 38.5ms\n",
      "Speed: 0.6ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-5_jpg.rf.106b6680fc19438ef3401acccef4e428.jpg: 640x640 2 persons, 1 bus, 2 trucks, 1 refrigerator, 39.1ms\n",
      "Speed: 0.6ms preprocess, 39.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_662_jpg.rf.c01ed16d038c373ff7519aa09965201b.jpg: 640x640 2 persons, 1 truck, 42.6ms\n",
      "Speed: 0.6ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_781_jpg.rf.30fe7f898afdb328ed872a9add06817a.jpg: 640x640 1 person, 1 train, 4 trucks, 43.3ms\n",
      "Speed: 0.7ms preprocess, 43.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_002883_jpg.rf.14d86d27fb802b8d26403c723c3e4c33.jpg: 640x640 1 person, 1 horse, 40.0ms\n",
      "Speed: 0.6ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-230_jpg.rf.462aca78b71bedb66bce8aeef766a9af.jpg: 640x640 1 truck, 1 surfboard, 40.9ms\n",
      "Speed: 0.6ms preprocess, 40.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-142-_jpg.rf.c313f46a8dd97e812be46b56862ee0ed.jpg: 640x640 4 persons, 42.9ms\n",
      "Speed: 0.6ms preprocess, 42.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/amz_02354_png_jpg.rf.921443ff67fe49b2185683dd5bbca1f1.jpg: 640x640 4 persons, 43.4ms\n",
      "Speed: 0.6ms preprocess, 43.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-816-_jpg.rf.9bc25654e962c8a8070928911f5195ad.jpg: 640x640 3 persons, 1 train, 2 trucks, 1 backpack, 45.6ms\n",
      "Speed: 0.7ms preprocess, 45.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005376_jpg.rf.b5f5bae65dbd647030aa3a08c16f17f0.jpg: 640x640 10 persons, 41.5ms\n",
      "Speed: 0.7ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-457_jpg.rf.5af4fbc8b3cfa887a55b9d45a7f3e547.jpg: 640x640 2 persons, 1 car, 1 truck, 41.5ms\n",
      "Speed: 0.8ms preprocess, 41.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-122_jpg.rf.7bb280627f23963d8fc187e624716358.jpg: 640x640 1 person, 2 buss, 1 cell phone, 42.5ms\n",
      "Speed: 0.6ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-21_jpg.rf.08e29573ac2164df688205f58ad4f1a0.jpg: 640x640 2 persons, 1 boat, 38.7ms\n",
      "Speed: 0.6ms preprocess, 38.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-210_jpg.rf.543e9db42a9c233df4eeb6816dfcbe74.jpg: 640x640 1 airplane, 1 truck, 40.1ms\n",
      "Speed: 0.6ms preprocess, 40.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-661_jpg.rf.96b27bc1550d9c74255de3061c1d61cb.jpg: 640x640 1 car, 2 trucks, 40.6ms\n",
      "Speed: 0.6ms preprocess, 40.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0491_jpg.rf.f7d47380ac16da405eb34a6a83171afc.jpg: 640x640 2 persons, 2 bananas, 39.8ms\n",
      "Speed: 0.7ms preprocess, 39.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_841_jpg.rf.042e14097ac20b8e81bb76017ee79c1d.jpg: 640x640 (no detections), 55.0ms\n",
      "Speed: 0.6ms preprocess, 55.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/616_jpg.rf.e95fe500cd53ff0a1278f730331d00c4.jpg: 640x640 2 persons, 1 truck, 39.5ms\n",
      "Speed: 0.6ms preprocess, 39.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5847_jpg.rf.321a7891cd33cfd8e8ae930563660aac.jpg: 640x640 11 persons, 2 cars, 1 truck, 1 dining table, 72.2ms\n",
      "Speed: 0.6ms preprocess, 72.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/YouTube_FreeStockFootage_People-wearing-face-mask_Empty-Street_Covid19-D_DbgrvhlGs-720p_mp4-11_jpg.rf.1939c26f45d953e4a423d3cf9958dfca.jpg: 640x640 1 person, 1 train, 1 truck, 43.1ms\n",
      "Speed: 0.7ms preprocess, 43.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox6_mp4-80_jpg.rf.0cebdad4d9d8f205f998ceaad09ea576.jpg: 640x640 1 person, 1 train, 1 truck, 42.3ms\n",
      "Speed: 0.7ms preprocess, 42.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-23_jpg.rf.89d36ba8fa7060b226d63d08223458d9.jpg: 640x640 (no detections), 42.0ms\n",
      "Speed: 0.7ms preprocess, 42.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-182_jpg.rf.f72c3426b5e987bc41302d8309dcc192.jpg: 640x640 3 trucks, 1 traffic light, 40.9ms\n",
      "Speed: 0.7ms preprocess, 40.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-221_jpg.rf.5e18725fb664a2515efa4e98dd505891.jpg: 640x640 1 person, 1 truck, 1 banana, 40.2ms\n",
      "Speed: 0.6ms preprocess, 40.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-543-_jpg.rf.36a5fb92366cc6bc65b8b2c28f27bdab.jpg: 640x640 (no detections), 45.9ms\n",
      "Speed: 0.6ms preprocess, 45.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-618_jpg.rf.83e038d916e5333f0429bec1775be2e2.jpg: 640x640 1 person, 1 truck, 41.8ms\n",
      "Speed: 0.6ms preprocess, 41.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-554_jpg.rf.7c697c7deea9995a0145e96cb7a23797.jpg: 640x640 1 person, 2 trucks, 38.5ms\n",
      "Speed: 0.6ms preprocess, 38.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-15_jpg.rf.79e6d35cd4a465fd7ec0d4dd031673ff.jpg: 640x640 1 person, 39.9ms\n",
      "Speed: 0.6ms preprocess, 39.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_23_jpg.rf.4d595f95fa30ca00a4e0dac39d6d0447.jpg: 640x640 2 persons, 1 fire hydrant, 1 bench, 46.5ms\n",
      "Speed: 0.7ms preprocess, 46.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2297-_png_jpg.rf.c11b54951365d9db2ce38e43da5a2482.jpg: 640x640 2 persons, 1 bicycle, 1 suitcase, 44.5ms\n",
      "Speed: 0.7ms preprocess, 44.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-507-_jpg.rf.ff1f7ff6c3ee0a5495251801e04151c8.jpg: 640x640 1 person, 1 bus, 1 truck, 40.1ms\n",
      "Speed: 0.6ms preprocess, 40.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-480_jpg.rf.faf443d4d10cc97074f6a80225f0ac29.jpg: 640x640 6 persons, 1 car, 1 clock, 40.4ms\n",
      "Speed: 0.6ms preprocess, 40.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-0_jpg.rf.4d7f373a15931dfd2572e11460cdda90.jpg: 640x640 1 person, 43.9ms\n",
      "Speed: 0.7ms preprocess, 43.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Screenshot_20210830-123141_Instagram_jpg.rf.eee49b0c99613c4cd2db2490d7d58cc9.jpg: 640x640 2 persons, 2 airplanes, 1 toothbrush, 40.3ms\n",
      "Speed: 0.7ms preprocess, 40.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_1021_jpg.rf.1d7075dbfe7fcdb52a6bcf29c295f3c6.jpg: 640x640 4 persons, 1 car, 2 trucks, 43.5ms\n",
      "Speed: 0.7ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-2_jpg.rf.bde377ae23066dfe925f09789c2bbdef.jpg: 640x640 3 persons, 37.1ms\n",
      "Speed: 0.6ms preprocess, 37.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Inside-merge_mov-16_jpg.rf.064c243f380d31af030bd1b7508e472f.jpg: 640x640 3 persons, 41.9ms\n",
      "Speed: 0.6ms preprocess, 41.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-23_jpg.rf.a80a9fcc61dead23c59fd84753cd5452.jpg: 640x640 4 persons, 40.5ms\n",
      "Speed: 0.7ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-480_jpg.rf.a1f30706658bee44054e92dcb51a2192.jpg: 640x640 4 persons, 39.7ms\n",
      "Speed: 0.6ms preprocess, 39.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-10_jpg.rf.df7e36757e8f14d68d24814e81014f96.jpg: 640x640 1 person, 1 truck, 41.3ms\n",
      "Speed: 0.6ms preprocess, 41.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_796_jpg.rf.d4c6712e7edf4b1ea95b346b63a7022b.jpg: 640x640 4 persons, 1 truck, 44.5ms\n",
      "Speed: 0.7ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_MOV-30_jpg.rf.4d588016dab520bbafc27f87b95926dc.jpg: 640x640 3 persons, 4 motorcycles, 2 trucks, 46.5ms\n",
      "Speed: 0.6ms preprocess, 46.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Bookstore111_jpg.rf.ebe6cd0b7e77dc3cea423b7b3458f67f.jpg: 640x640 2 persons, 1 bicycle, 7 books, 78.3ms\n",
      "Speed: 1.1ms preprocess, 78.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_221_jpg.rf.2b878e437f185500f1226667532f06a9.jpg: 640x640 5 persons, 1 truck, 43.1ms\n",
      "Speed: 0.8ms preprocess, 43.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-391_jpg.rf.c61a67d5bceb5f24951ba13f67e75ee9.jpg: 640x640 1 person, 1 bus, 1 train, 1 truck, 38.0ms\n",
      "Speed: 0.6ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-165_jpg.rf.6b00efd09ed86e6969894d0bcc5aebb2.jpg: 640x640 2 persons, 1 car, 2 trucks, 41.1ms\n",
      "Speed: 0.6ms preprocess, 41.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_560_jpg.rf.6c6d505912c78a83a850fd0e05dd3002.jpg: 640x640 1 truck, 1 cell phone, 39.4ms\n",
      "Speed: 0.6ms preprocess, 39.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-651_jpg.rf.b2c4f5c904997039262f6aad836b864c.jpg: 640x640 7 persons, 2 handbags, 40.9ms\n",
      "Speed: 0.7ms preprocess, 40.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_93_jpg.rf.9ab670caa839d1b471864a68fc7f31bb.jpg: 640x640 1 person, 1 bed, 45.2ms\n",
      "Speed: 0.7ms preprocess, 45.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_673_jpg.rf.b735afb05956b1748764df1dfe11f0cb.jpg: 640x640 1 person, 1 train, 1 tie, 42.6ms\n",
      "Speed: 0.7ms preprocess, 42.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox4_mp4-111_jpg.rf.2292cbeef0a5da66dd9fe1040822d3e9.jpg: 640x640 6 persons, 2 trucks, 1 parking meter, 1 tie, 40.4ms\n",
      "Speed: 0.6ms preprocess, 40.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_50_jpg.rf.98159c6be48071b9ae87b456ef4a285e.jpg: 640x640 2 persons, 1 truck, 48.0ms\n",
      "Speed: 0.7ms preprocess, 48.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-266_jpg.rf.bcfe55fb70ab90bfe1bcc697aab51a27.jpg: 640x640 1 person, 1 truck, 1 baseball bat, 1 bed, 41.5ms\n",
      "Speed: 0.7ms preprocess, 41.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-24_jpg.rf.80e4e03da7a762652a41859d95f33734.jpg: 640x640 4 persons, 1 motorcycle, 1 bed, 41.3ms\n",
      "Speed: 0.8ms preprocess, 41.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_13_jpg.rf.2b8a935fb25cb33b55fa32f6906d63ad.jpg: 640x640 2 persons, 1 cell phone, 39.3ms\n",
      "Speed: 0.8ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/img_037_jpg.rf.7ac1fae45ffb804a605d797a9675b297.jpg: 640x640 9 persons, 1 tv, 38.5ms\n",
      "Speed: 0.7ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_796_jpg.rf.e8e096687e5a05e79328b6618b693676.jpg: 640x640 1 person, 2 trucks, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-507-_jpg.rf.f34e6dff28e95f62951544db53e7ce64.jpg: 640x640 1 person, 1 bottle, 1 dining table, 38.5ms\n",
      "Speed: 0.6ms preprocess, 38.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-270_jpg.rf.4d12d412d22aad7d403e5ffb7a1c0797.jpg: 640x640 1 person, 40.1ms\n",
      "Speed: 0.7ms preprocess, 40.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox6_mp4-20_jpg.rf.01fd6c988a63b016a2ba95b6030344ac.jpg: 640x640 1 person, 1 car, 39.9ms\n",
      "Speed: 0.6ms preprocess, 39.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_1004_jpg.rf.57bc4c7a8f1d5f7737d9c7dc5827d7f5.jpg: 640x640 2 persons, 43.0ms\n",
      "Speed: 0.6ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_000379_jpg.rf.8a537e55ba2654835278f344da61abfe.jpg: 640x640 2 persons, 1 tie, 40.0ms\n",
      "Speed: 0.6ms preprocess, 40.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-812_jpg.rf.375474621f788ea313458cf4a7ba6e6a.jpg: 640x640 3 persons, 5 bottles, 39.9ms\n",
      "Speed: 0.6ms preprocess, 39.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-29_jpg.rf.8a394954d5e6c7f7f6b659b06fdd4150.jpg: 640x640 4 persons, 1 motorcycle, 42.5ms\n",
      "Speed: 0.7ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/REVZGCBIJNQPMIIXOKDCQA3GJI_jpg.rf.7137c1768ca8bb678f8023804f2dc9d4.jpg: 640x640 6 persons, 44.5ms\n",
      "Speed: 0.6ms preprocess, 44.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-135-_jpg.rf.de989df51bba3fbfd485a65b285614a9.jpg: 640x640 1 person, 2 cars, 46.2ms\n",
      "Speed: 0.7ms preprocess, 46.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-651_jpg.rf.a200e7467cde04aa5c59d3fccc8c39fd.jpg: 640x640 1 person, 1 refrigerator, 41.9ms\n",
      "Speed: 0.7ms preprocess, 41.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/01094_jpg.rf.ada3cfdaa41584a1f44bc13caea976fc.jpg: 640x640 1 person, 52.9ms\n",
      "Speed: 0.7ms preprocess, 52.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-622_jpg.rf.a5440f236330dd579ed80c8154b4a1d0.jpg: 640x640 2 persons, 1 truck, 1 tie, 38.7ms\n",
      "Speed: 0.7ms preprocess, 38.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-253-_jpg.rf.3e850898ed55f86eced4486e4cb1840f.jpg: 640x640 1 person, 37.4ms\n",
      "Speed: 0.6ms preprocess, 37.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-75_jpg.rf.289034d906e0ff963e0ba2ba80fcdce9.jpg: 640x640 2 persons, 1 bus, 44.2ms\n",
      "Speed: 0.7ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_757_jpg.rf.97ce10366965d7ed2207c0636961408c.jpg: 640x640 1 person, 1 car, 1 truck, 1 suitcase, 42.3ms\n",
      "Speed: 0.7ms preprocess, 42.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-837_jpg.rf.cb9d104a7df8e2da5bc8e7e3645b3349.jpg: 640x640 2 persons, 2 trucks, 41.3ms\n",
      "Speed: 0.6ms preprocess, 41.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_170_jpg.rf.0f55b91722306f122699342ce6c057aa.jpg: 640x640 1 person, 1 motorcycle, 2 books, 42.6ms\n",
      "Speed: 0.7ms preprocess, 42.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-554_jpg.rf.b18de4169917a75781361b42dcfede78.jpg: 640x640 3 persons, 1 bench, 1 refrigerator, 39.8ms\n",
      "Speed: 0.6ms preprocess, 39.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-29_jpg.rf.a16477923a252af01de0a8700dfb5783.jpg: 640x640 1 motorcycle, 1 truck, 1 boat, 47.2ms\n",
      "Speed: 0.6ms preprocess, 47.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_716_jpg.rf.d20e2f34a0f4320dd0fa6d078967235c.jpg: 640x640 2 persons, 4 cars, 1 train, 1 truck, 1 cup, 1 bowl, 41.8ms\n",
      "Speed: 0.7ms preprocess, 41.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-709_jpg.rf.80681d4729a022bfc1bf6073aadc6f20.jpg: 640x640 3 persons, 1 chair, 1 cell phone, 47.7ms\n",
      "Speed: 0.7ms preprocess, 47.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_731_jpg.rf.73a783ca018f76b895cf5cd2355ac1aa.jpg: 640x640 3 persons, 1 bus, 1 train, 39.3ms\n",
      "Speed: 0.7ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2252-_png_jpg.rf.959ef543a1a8383d7ea395bec26b1030.jpg: 640x640 3 persons, 43.4ms\n",
      "Speed: 0.6ms preprocess, 43.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_16_jpg.rf.2a50dbc7c159879fb80f6c29905b69f3.jpg: 640x640 3 persons, 2 traffic lights, 42.7ms\n",
      "Speed: 0.7ms preprocess, 42.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-457_jpg.rf.68083426ed75d1e46ed28567e4245843.jpg: 640x640 1 person, 40.1ms\n",
      "Speed: 0.7ms preprocess, 40.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-61_jpg.rf.1b26ec9c12255c8a7d19cddda5850f5f.jpg: 640x640 3 persons, 42.5ms\n",
      "Speed: 0.7ms preprocess, 42.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-113_jpg.rf.657cf7274654eddca1d6c542cdee3dd0.jpg: 640x640 1 person, 1 bottle, 39.0ms\n",
      "Speed: 0.6ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_1212_jpg.rf.7bb612bc84ecb56f461512ddcb0cc5c9.jpg: 640x640 2 persons, 38.6ms\n",
      "Speed: 0.6ms preprocess, 38.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-628_jpg.rf.d4e735079e3403aeb4a3c610e664f1f2.jpg: 640x640 2 trucks, 1 tie, 1 banana, 69.5ms\n",
      "Speed: 0.6ms preprocess, 69.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-348_jpg.rf.1aabd2813662bd7b86584c03b43ea2bc.jpg: 640x640 2 persons, 1 skis, 45.0ms\n",
      "Speed: 0.9ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0015_jpg.rf.47f0a91d63f98e6f2c10b37f14dc237c.jpg: 640x640 2 persons, 41.4ms\n",
      "Speed: 0.7ms preprocess, 41.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-134_jpg.rf.c0cdd4265a0d7f7d83a7674ccd8830ba.jpg: 640x640 2 persons, 5 cars, 1 train, 1 truck, 43.9ms\n",
      "Speed: 0.7ms preprocess, 43.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-731-_jpg.rf.20e3d7c26bf8c63c65ae274555773e95.jpg: 640x640 1 airplane, 1 truck, 40.6ms\n",
      "Speed: 0.7ms preprocess, 40.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-12_jpg.rf.08cddb92471bc97a4bb37b6ce28b5655.jpg: 640x640 1 truck, 1 vase, 39.5ms\n",
      "Speed: 0.7ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_50_jpg.rf.2fd4f730ebf2e12ae454946a0927b5c8.jpg: 640x640 1 truck, 53.4ms\n",
      "Speed: 0.6ms preprocess, 53.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1116-_jpg.rf.da7f8f05689a5daf50a70fd109bb4a8f.jpg: 640x640 1 clock, 38.8ms\n",
      "Speed: 0.7ms preprocess, 38.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_527_jpg.rf.195d9418c90bc4368699ef7e3be727b4.jpg: 640x640 3 persons, 42.1ms\n",
      "Speed: 0.7ms preprocess, 42.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-384_jpg.rf.4112a46ab81f97f392849d7656bb47c0.jpg: 640x640 1 person, 42.9ms\n",
      "Speed: 0.6ms preprocess, 42.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_379_jpg.rf.76f16ba57fbf5e06f4a16739bf1b643c.jpg: 640x640 4 persons, 2 books, 43.6ms\n",
      "Speed: 0.7ms preprocess, 43.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-48_jpg.rf.fd5477e7199642ffa7a483b1b0ce6af2.jpg: 640x640 4 persons, 2 trains, 1 cat, 49.1ms\n",
      "Speed: 0.7ms preprocess, 49.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-5_jpg.rf.986a2bfc0bc4260332a8718fe6711684.jpg: 640x640 1 person, 1 truck, 45.5ms\n",
      "Speed: 0.7ms preprocess, 45.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-51_jpg.rf.aa7c8977184675aa773c6d399e1f224c.jpg: 640x640 1 person, 1 train, 1 truck, 1 surfboard, 39.1ms\n",
      "Speed: 0.6ms preprocess, 39.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-266_jpg.rf.170d1fe1b1ac1abe806b47f7a47c1211.jpg: 640x640 4 persons, 1 car, 2 trucks, 39.8ms\n",
      "Speed: 0.7ms preprocess, 39.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008652_jpg.rf.fdf7e303604d0fb6feb39b62d8469cf5.jpg: 640x640 1 person, 2 trucks, 42.5ms\n",
      "Speed: 0.6ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ezgif-frame-049_jpg.rf.51c4102f3880e82726034fd0582257a4.jpg: 640x640 1 person, 39.4ms\n",
      "Speed: 0.6ms preprocess, 39.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox2_mp4-74_jpg.rf.dc717b3f997effa8bcd6e23c5ce2a029.jpg: 640x640 5 persons, 1 horse, 41.5ms\n",
      "Speed: 0.6ms preprocess, 41.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-270_jpg.rf.62a75ad69c0902ce2734b232975c1884.jpg: 640x640 4 persons, 1 motorcycle, 1 airplane, 1 truck, 43.5ms\n",
      "Speed: 0.6ms preprocess, 43.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-2_jpg.rf.87e69eb0f5f24cbadcca3fbfe8ca029c.jpg: 640x640 2 persons, 1 bus, 1 train, 1 truck, 39.3ms\n",
      "Speed: 0.6ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1116-_jpg.rf.97f5e2cdb1ff760617a2ea53954b949c.jpg: 640x640 1 car, 1 train, 3 trucks, 39.1ms\n",
      "Speed: 0.6ms preprocess, 39.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0750_jpg.rf.59c05e6f5064e20add59ff074c518073.jpg: 640x640 3 persons, 42.1ms\n",
      "Speed: 0.6ms preprocess, 42.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/002458_jpg.rf.1b4000f1327c1a3d54d98bceebcde622.jpg: 640x640 5 persons, 1 umbrella, 46.6ms\n",
      "Speed: 0.6ms preprocess, 46.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_314_jpg.rf.d9709ed031d36dbf028ef0cfbcd78039.jpg: 640x640 2 persons, 4 cars, 2 trucks, 48.8ms\n",
      "Speed: 0.7ms preprocess, 48.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_1037_jpg.rf.5ff93f8ea02ad4f0c1a0fe898de80745.jpg: 640x640 2 persons, 1 bus, 2 chairs, 1 dining table, 41.6ms\n",
      "Speed: 0.6ms preprocess, 41.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-15_jpg.rf.2c28a52bbdfb4d269bade273922896c0.jpg: 640x640 5 persons, 1 bed, 43.5ms\n",
      "Speed: 0.7ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-246_jpg.rf.8809473eb178b062b48fb1ee9b8e5369.jpg: 640x640 2 persons, 41.7ms\n",
      "Speed: 0.6ms preprocess, 41.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-272_jpg.rf.bf7c90ad1b2d70c8a8cf63ec878b0aed.jpg: 640x640 1 person, 1 car, 1 train, 1 bench, 1 dog, 41.1ms\n",
      "Speed: 0.6ms preprocess, 41.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_074_jpg.rf.fcad9abb23e115e251789cae2020ab58.jpg: 640x640 3 persons, 1 bicycle, 1 car, 1 dog, 1 bear, 1 frisbee, 49.4ms\n",
      "Speed: 0.6ms preprocess, 49.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-17_jpg.rf.cac019c72f4cfdc7fb9a916792eeb20e.jpg: 640x640 3 persons, 1 train, 53.0ms\n",
      "Speed: 0.7ms preprocess, 53.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-260_jpg.rf.ebb38b7437d6b5d56951004d3c3a80ff.jpg: 640x640 1 person, 1 bus, 1 truck, 1 chair, 40.4ms\n",
      "Speed: 0.7ms preprocess, 40.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_002883_jpg.rf.d10587ac3861e970e5a2bec61ef90b26.jpg: 640x640 1 person, 1 truck, 1 horse, 1 potted plant, 1 mouse, 44.1ms\n",
      "Speed: 0.6ms preprocess, 44.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/n190039_jpg.rf.e81596a1eda409a3f441c38bd7da6d2a.jpg: 640x640 7 persons, 1 truck, 1 handbag, 2 potted plants, 68.5ms\n",
      "Speed: 0.6ms preprocess, 68.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/video_CDC-YOUTUBE_mp4-50_jpg.rf.4912d4cb665e1ab8243c28d9c3039ae8.jpg: 640x640 3 persons, 41.9ms\n",
      "Speed: 0.8ms preprocess, 41.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_575_jpg.rf.37dc5c2b4e64116800d0be65673bd13f.jpg: 640x640 1 person, 2 trucks, 43.9ms\n",
      "Speed: 0.7ms preprocess, 43.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1115-_jpg.rf.f4e84bf10d14c55df148f2f8ea589760.jpg: 640x640 1 person, 2 trains, 40.5ms\n",
      "Speed: 0.6ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-148_jpg.rf.b7b07362ee93800883c6d31ba0b7ade1.jpg: 640x640 1 bottle, 41.7ms\n",
      "Speed: 1.0ms preprocess, 41.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/smartmi-3pcs-filter-mask-pm25-haze-dustproof-mask-with-vent_jpg.rf.ed44be4620775ca11a7d635b03667b97.jpg: 640x640 4 persons, 1 train, 1 backpack, 44.2ms\n",
      "Speed: 0.6ms preprocess, 44.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-6_jpg.rf.bde255ddc63a02225feab284b6c6c5c3.jpg: 640x640 2 persons, 39.5ms\n",
      "Speed: 0.7ms preprocess, 39.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1116-_jpg.rf.d86e88d4a8ced388b86abff05c5aeefe.jpg: 640x640 1 train, 40.2ms\n",
      "Speed: 0.6ms preprocess, 40.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-I1-MS09uaqsLdGTFkgnS0Rcg1mmPyAj95ySg_eckoM_jpeg_jpg.rf.b6fe400473371645e17e76a323691b4b.jpg: 640x640 2 persons, 1 motorcycle, 2 trucks, 1 bench, 43.1ms\n",
      "Speed: 0.7ms preprocess, 43.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_673_jpg.rf.b44d04f9697b9117551c2f180474eda3.jpg: 640x640 1 person, 1 car, 1 train, 1 truck, 43.3ms\n",
      "Speed: 0.7ms preprocess, 43.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-303_jpg.rf.cdf28e1cc8d4407f46e083963ec5560a.jpg: 640x640 2 persons, 1 truck, 46.4ms\n",
      "Speed: 0.6ms preprocess, 46.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_575_jpg.rf.dc2951b0cc83d450252fd1a231cd0cf1.jpg: 640x640 6 persons, 1 truck, 1 umbrella, 1 tie, 1 banana, 43.7ms\n",
      "Speed: 0.6ms preprocess, 43.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_435_jpg.rf.b7353391129378f1de81fe5ac436d72f.jpg: 640x640 4 persons, 41.9ms\n",
      "Speed: 0.6ms preprocess, 41.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-272_jpg.rf.f3cd5235245d06df97bf23b4b9d4546b.jpg: 640x640 2 persons, 37.3ms\n",
      "Speed: 0.7ms preprocess, 37.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-872-_jpg.rf.d5a3857b1b2073061ba4ddd0aeb5fe84.jpg: 640x640 1 person, 1 train, 2 trucks, 42.2ms\n",
      "Speed: 0.7ms preprocess, 42.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-464_jpg.rf.3806bb90d6e44e83c13c4b61058d08d3.jpg: 640x640 1 person, 2 trucks, 38.6ms\n",
      "Speed: 0.7ms preprocess, 38.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/n457047_jpg.rf.a714b0b010973b624497d7a67f4c8816.jpg: 640x640 1 refrigerator, 39.0ms\n",
      "Speed: 0.7ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-12_jpg.rf.a7130b65bcfb458bd586a07b24ecf2ae.jpg: 640x640 2 cars, 1 truck, 40.2ms\n",
      "Speed: 0.6ms preprocess, 40.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-21_jpg.rf.024bd8e9d752e4b0e2c647cd9bea94ad.jpg: 640x640 3 persons, 1 refrigerator, 47.7ms\n",
      "Speed: 0.6ms preprocess, 47.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-12_jpg.rf.0f1cfcc2d1a6b29de5100c53d1ffc4b8.jpg: 640x640 1 person, 3 trucks, 50.6ms\n",
      "Speed: 1.2ms preprocess, 50.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_941_jpg.rf.36c3b66812c73b361669e47bc055cc40.jpg: 640x640 6 persons, 1 train, 1 tie, 44.5ms\n",
      "Speed: 0.6ms preprocess, 44.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005376_jpg.rf.0c1077624516cc048e465b4a675ce5e2.jpg: 640x640 4 persons, 1 bus, 42.5ms\n",
      "Speed: 0.7ms preprocess, 42.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_841_jpg.rf.ed1f5c0186f06cf6cf8434322ea8031f.jpg: 640x640 2 persons, 1 bed, 49.1ms\n",
      "Speed: 0.6ms preprocess, 49.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-57_jpg.rf.c5900b5314a0bf5fbccd6e43998898bc.jpg: 640x640 3 trucks, 40.7ms\n",
      "Speed: 0.7ms preprocess, 40.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0460_jpg.rf.6d6fd5be775da125c62929b9f90628b4.jpg: 640x640 2 persons, 2 cell phones, 1 clock, 41.8ms\n",
      "Speed: 0.6ms preprocess, 41.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/329_jpg.rf.545ddf049ed04f83620fd7ddb5bf6f87.jpg: 640x640 7 persons, 1 umbrella, 1 tie, 44.2ms\n",
      "Speed: 0.6ms preprocess, 44.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-855_jpg.rf.346f539ebe7317c5c7202185ddd56af5.jpg: 640x640 1 truck, 2 traffic lights, 40.3ms\n",
      "Speed: 0.6ms preprocess, 40.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_880_jpg.rf.d5521e4b5d741375f99709ba6483f190.jpg: 640x640 2 persons, 42.9ms\n",
      "Speed: 0.7ms preprocess, 42.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ka_00884_png_jpg.rf.32f17b2c4943e345a32765b1ce0ac3e9.jpg: 640x640 1 person, 1 tv, 42.1ms\n",
      "Speed: 0.6ms preprocess, 42.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-21_jpg.rf.19c9998d5c8e6029af7f5e5e34d14413.jpg: 640x640 4 persons, 41.1ms\n",
      "Speed: 0.6ms preprocess, 41.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_120_jpg.rf.93e81df9716279092b12417715ee944f.jpg: 640x640 1 person, 4 bottles, 46.0ms\n",
      "Speed: 0.7ms preprocess, 46.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-376_jpg.rf.ae2fc4ffb957f714075a0c97ce35e8a1.jpg: 640x640 3 persons, 2 motorcycles, 2 trucks, 72.4ms\n",
      "Speed: 0.7ms preprocess, 72.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/135e-huxwryw6451820_jpg.rf.ee9ca43c493a451ed87dcea9c7b3e0c6.jpg: 640x640 2 persons, 1 truck, 1 boat, 1 laptop, 3 books, 43.0ms\n",
      "Speed: 0.7ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-572-_jpg.rf.de16cf7d2e458d8a7d30bcac89a4f924.jpg: 640x640 1 person, 1 truck, 1 horse, 1 chair, 1 toilet, 41.4ms\n",
      "Speed: 0.7ms preprocess, 41.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-457_jpg.rf.05c5ec44a5f1cd8b304671f56b1bc7be.jpg: 640x640 2 persons, 1 car, 43.5ms\n",
      "Speed: 0.6ms preprocess, 43.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-242_jpg.rf.ecfb577d7a9e7a35dcc60b16ec4d47f4.jpg: 640x640 4 persons, 38.9ms\n",
      "Speed: 0.6ms preprocess, 38.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-303_jpg.rf.a516811dbe3ba18ff8c6e196490c1789.jpg: 640x640 1 person, 1 truck, 2 birds, 1 refrigerator, 43.7ms\n",
      "Speed: 0.7ms preprocess, 43.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-221_jpg.rf.ebbeb87d2c85b473ffe09c3e3b6d88e3.jpg: 640x640 1 person, 41.2ms\n",
      "Speed: 0.6ms preprocess, 41.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-528-_jpg.rf.cf2c53e133b7c53f3374d4bb2e6c6b89.jpg: 640x640 1 bowl, 1 cake, 39.7ms\n",
      "Speed: 0.6ms preprocess, 39.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_93_jpg.rf.ac1d4cd997f4c63871d6412021e10126.jpg: 640x640 2 trucks, 1 boat, 38.7ms\n",
      "Speed: 0.6ms preprocess, 38.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-38_jpg.rf.60ef8acdb20ee1db1643bdc4e0ed9838.jpg: 640x640 1 person, 41.5ms\n",
      "Speed: 0.6ms preprocess, 41.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5024_mp4-5_jpg.rf.9098e69dc2ea3056f2691059d073ac89.jpg: 640x640 2 trucks, 1 cat, 60.0ms\n",
      "Speed: 0.6ms preprocess, 60.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_18_jpg.rf.a7f18f0fb9fb1c0bebd2baf096afa9f9.jpg: 640x640 1 person, 1 bench, 45.2ms\n",
      "Speed: 0.7ms preprocess, 45.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_95_jpg.rf.5f7867b6006b00d85362aa37c436f967.jpg: 640x640 1 person, 1 train, 1 truck, 41.7ms\n",
      "Speed: 0.7ms preprocess, 41.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/000415_jpg.rf.8b898a9652182d324999f62f39119cfb.jpg: 640x640 1 person, 1 bottle, 1 tv, 40.9ms\n",
      "Speed: 0.8ms preprocess, 40.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-710_jpg.rf.17c00a6edf7e16fa7527b1fd376ff98b.jpg: 640x640 1 person, 1 traffic light, 1 surfboard, 1 cup, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-459_jpg.rf.7197e47830c027d29c81a960ce19d7c7.jpg: 640x640 1 airplane, 2 trucks, 40.3ms\n",
      "Speed: 0.7ms preprocess, 40.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0750_jpg.rf.3c6c7e7f41b061e2116d8ca06c781cfd.jpg: 640x640 6 persons, 1 snowboard, 38.8ms\n",
      "Speed: 0.7ms preprocess, 38.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-435-_jpg.rf.f7b9fb78990ed6dcecd2899d7643adaa.jpg: 640x640 1 person, 1 bus, 1 sink, 1 clock, 38.5ms\n",
      "Speed: 0.6ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-0_jpg.rf.c2682797779148fe3b487b59938676a4.jpg: 640x640 5 persons, 1 cat, 1 keyboard, 41.8ms\n",
      "Speed: 0.6ms preprocess, 41.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-492_jpg.rf.f22a252f10919a0b3bea48d912d5075d.jpg: 640x640 2 persons, 1 dog, 1 baseball bat, 43.8ms\n",
      "Speed: 0.6ms preprocess, 43.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class5_012_jpg.rf.75ad7a3fa454c7d20bacf9e322ef64ac.jpg: 640x640 1 person, 45.2ms\n",
      "Speed: 0.7ms preprocess, 45.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0029_jpg.rf.130a5bd882eaf7314cd82254f06f1a96.jpg: 640x640 1 person, 1 truck, 40.4ms\n",
      "Speed: 0.6ms preprocess, 40.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-268-_jpg.rf.a5a9c565f737e454d2146d1fd2cab5f5.jpg: 640x640 1 person, 2 trucks, 1 skateboard, 73.0ms\n",
      "Speed: 0.6ms preprocess, 73.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_740_jpg.rf.bb45115dd9add31efda4687b92a2f78f.jpg: 640x640 1 person, 2 trucks, 40.6ms\n",
      "Speed: 0.7ms preprocess, 40.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/616_jpg.rf.cf72efbe3dbc4a777ba5bf192ad4bc33.jpg: 640x640 2 persons, 40.9ms\n",
      "Speed: 0.8ms preprocess, 40.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-207_jpg.rf.7b6ef224e27e0bd01c3e5cce56f62384.jpg: 640x640 3 persons, 44.2ms\n",
      "Speed: 0.6ms preprocess, 44.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-554_jpg.rf.1bbece061ee56eaa0b32cb0a392b42c8.jpg: 640x640 7 persons, 1 truck, 2 boats, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox6_mp4-80_jpg.rf.44eee52828ea57aaaac102dfbcc55e45.jpg: 640x640 1 person, 2 trains, 40.2ms\n",
      "Speed: 0.6ms preprocess, 40.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-567_jpg.rf.f0d363edf6b7832ec61698ecfc457e48.jpg: 640x640 2 persons, 1 surfboard, 42.3ms\n",
      "Speed: 0.7ms preprocess, 42.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-219_jpg.rf.dae32347bb4fed1d2078263a64f58a70.jpg: 640x640 3 persons, 1 truck, 1 cell phone, 42.0ms\n",
      "Speed: 0.7ms preprocess, 42.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-391_jpg.rf.726b7971a07ba0e39e77b112cb999a6a.jpg: 640x640 4 persons, 1 tie, 38.2ms\n",
      "Speed: 0.7ms preprocess, 38.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-1975-_png_jpg.rf.b5622016579bca7e2e993de3470405e0.jpg: 640x640 5 persons, 1 truck, 39.1ms\n",
      "Speed: 0.7ms preprocess, 39.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox6_mp4-80_jpg.rf.370352a9ceca1d6bdb8828be017271ae.jpg: 640x640 4 persons, 1 car, 1 bottle, 58.6ms\n",
      "Speed: 0.8ms preprocess, 58.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008753_jpg.rf.d4c5f043915bded8b5a1909134766f54.jpg: 640x640 1 stop sign, 47.6ms\n",
      "Speed: 0.7ms preprocess, 47.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-502_jpg.rf.a12c146909c4f2cc577710149c449ecd.jpg: 640x640 2 persons, 1 motorcycle, 45.5ms\n",
      "Speed: 0.7ms preprocess, 45.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_002711_jpg.rf.2432192dc727d132f2eb4e85daf069de.jpg: 640x640 3 cars, 1 airplane, 1 truck, 40.5ms\n",
      "Speed: 0.6ms preprocess, 40.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_255_jpg.rf.422e26c6191794cbd77a3a8cc6d496c9.jpg: 640x640 1 person, 1 car, 2 trains, 41.3ms\n",
      "Speed: 0.6ms preprocess, 41.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-254_jpg.rf.1939cc2235cb0e0fa9498e877a191892.jpg: 640x640 5 persons, 1 bicycle, 1 truck, 38.8ms\n",
      "Speed: 0.7ms preprocess, 38.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_39_jpg.rf.b606c22a8844817f93703d9220a79a26.jpg: 640x640 1 person, 1 chair, 37.6ms\n",
      "Speed: 0.6ms preprocess, 37.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-15_jpg.rf.ef479286773454db7f4260a06eec8836.jpg: 640x640 (no detections), 42.0ms\n",
      "Speed: 0.7ms preprocess, 42.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_13_jpg.rf.051365a51cf994673c641432a3edee86.jpg: 640x640 1 person, 1 train, 1 truck, 43.0ms\n",
      "Speed: 0.6ms preprocess, 43.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-137_jpg.rf.f3c12d70881b7bcf0004d76431db4870.jpg: 640x640 1 person, 1 truck, 38.5ms\n",
      "Speed: 0.6ms preprocess, 38.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_296_jpg.rf.73761155f1b463dff7eb2bdedad471e8.jpg: 640x640 1 truck, 42.2ms\n",
      "Speed: 0.7ms preprocess, 42.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_379_jpg.rf.77d7bc1ae0d32bf5a2ca4bc2db0b8f56.jpg: 640x640 3 persons, 39.8ms\n",
      "Speed: 0.6ms preprocess, 39.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_575_jpg.rf.c0a0279908ff59e2af4c1724cb945620.jpg: 640x640 2 persons, 1 boat, 1 giraffe, 57.8ms\n",
      "Speed: 0.8ms preprocess, 57.8ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-708-_jpg.rf.b1132dae9e707cb3cff82d42c3ace26e.jpg: 640x640 2 persons, 1 truck, 1 couch, 44.7ms\n",
      "Speed: 1.0ms preprocess, 44.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/REVZGCBIJNQPMIIXOKDCQA3GJI_jpg.rf.b16c101282ee19137c82a92271433fd9.jpg: 640x640 5 persons, 45.4ms\n",
      "Speed: 0.7ms preprocess, 45.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-699_jpg.rf.ced94dd4765a8ff9fe60e7648179fb6d.jpg: 640x640 2 persons, 1 airplane, 2 trucks, 44.5ms\n",
      "Speed: 0.7ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-13_jpg.rf.01f41c3465981dfb5c5894f36dbe7405.jpg: 640x640 1 person, 1 truck, 1 bird, 2 cows, 44.2ms\n",
      "Speed: 0.7ms preprocess, 44.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_55_jpg.rf.88ca3048372d91f49c80084e75cc41de.jpg: 640x640 1 vase, 39.3ms\n",
      "Speed: 0.7ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-48_jpg.rf.72bf6dca6741d8c2f2c96b9f9177b3e4.jpg: 640x640 1 bus, 1 train, 1 truck, 1 suitcase, 41.0ms\n",
      "Speed: 0.6ms preprocess, 41.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_1021_jpg.rf.c0569909c0a161ddae0bbf3446b84642.jpg: 640x640 1 person, 2 cars, 1 truck, 45.1ms\n",
      "Speed: 0.7ms preprocess, 45.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_176_jpg.rf.bba93125abaf13dc2267c1b71ab20e33.jpg: 640x640 1 refrigerator, 40.0ms\n",
      "Speed: 0.7ms preprocess, 40.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-67_jpg.rf.f1110ee47dca5c33c0afdb8f21f4283d.jpg: 640x640 1 truck, 54.7ms\n",
      "Speed: 0.6ms preprocess, 54.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0015_jpg.rf.e9459752d7ff76c1d47841348f62b534.jpg: 640x640 3 persons, 1 bird, 42.3ms\n",
      "Speed: 0.6ms preprocess, 42.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-64_jpg.rf.58cdc2645314e54e9a12912914ad79a5.jpg: 640x640 4 persons, 1 backpack, 2 bottles, 47.2ms\n",
      "Speed: 0.6ms preprocess, 47.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005376_jpg.rf.2a20e5687918f570b05628736b28e9b4.jpg: 640x640 3 persons, 1 truck, 44.2ms\n",
      "Speed: 0.7ms preprocess, 44.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_31_jpg.rf.e73e43acd927e29c86e1295201f71aef.jpg: 640x640 4 persons, 1 car, 1 cake, 44.2ms\n",
      "Speed: 0.7ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-51_jpg.rf.3145d6b80394273089e6b3dbd86d3a2b.jpg: 640x640 2 persons, 38.4ms\n",
      "Speed: 0.7ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-19_jpg.rf.0e0c0646c5203de125745b30b9a352c8.jpg: 640x640 2 persons, 1 train, 1 boat, 1 bottle, 41.0ms\n",
      "Speed: 0.7ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_875_jpg.rf.3d674469d92b9dc298a57c5468b95e1f.jpg: 640x640 1 truck, 1 bed, 39.1ms\n",
      "Speed: 0.8ms preprocess, 39.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-55_jpg.rf.da354e2f06ef5c7db51ad85a8dc50e57.jpg: 640x640 1 car, 43.6ms\n",
      "Speed: 0.7ms preprocess, 43.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class1_075_jpg.rf.f7bb65e5958e262cf9b3ab5ea58eb1c3.jpg: 640x640 3 persons, 1 car, 44.5ms\n",
      "Speed: 0.7ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-645_jpg.rf.ad2e663924cfcee098cd2d2f72dcf238.jpg: 640x640 2 persons, 1 motorcycle, 39.2ms\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_153_jpg.rf.513389c7049c5ff59a3cbef8c20decf3.jpg: 640x640 2 persons, 2 trucks, 1 handbag, 1 toothbrush, 51.6ms\n",
      "Speed: 0.7ms preprocess, 51.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_153_jpg.rf.f86a092614e123c322194a8bd8eccca6.jpg: 640x640 2 persons, 1 truck, 154.0ms\n",
      "Speed: 13.3ms preprocess, 154.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-571_jpg.rf.9754f45af694d7838cef0e816190018d.jpg: 640x640 1 traffic light, 1 surfboard, 42.8ms\n",
      "Speed: 0.7ms preprocess, 42.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-5_jpg.rf.ce4fac119218ae0c5d586d7f338c1c0e.jpg: 640x640 2 trucks, 50.1ms\n",
      "Speed: 0.7ms preprocess, 50.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/YouTube_FreeStockFootage_People-wearing-face-mask_Empty-Street_Covid19-D_DbgrvhlGs-720p_mp4-11_jpg.rf.aef8e3cdccf0305e2c8237fb6734dc69.jpg: 640x640 2 persons, 1 truck, 44.7ms\n",
      "Speed: 0.7ms preprocess, 44.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-618-_jpg.rf.eef05f234b24341cde01eb8ca476781e.jpg: 640x640 1 person, 1 bicycle, 45.0ms\n",
      "Speed: 1.6ms preprocess, 45.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-824_jpg.rf.c3657af2cfe0258c9c311523f03a2917.jpg: 640x640 1 person, 1 truck, 36.8ms\n",
      "Speed: 0.7ms preprocess, 36.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_294_jpg.rf.3fb7868468c81bc16637ea012898a6a3.jpg: 640x640 1 person, 1 car, 1 bus, 3 trucks, 48.6ms\n",
      "Speed: 0.7ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_18_jpg.rf.335e252ed8e6e0e4c83d801d98deaed3.jpg: 640x640 1 person, 1 bed, 42.0ms\n",
      "Speed: 0.7ms preprocess, 42.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-435-_jpg.rf.0d50ada8fdca82a1c6912db00230fd40.jpg: 640x640 5 persons, 1 train, 1 truck, 50.7ms\n",
      "Speed: 0.7ms preprocess, 50.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class1_075_jpg.rf.e3831cb374ca34da6761df50b874cbc9.jpg: 640x640 1 train, 1 bench, 54.9ms\n",
      "Speed: 0.6ms preprocess, 54.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-178_jpg.rf.0b86b7829e2da46f66cbf5dddb677a82.jpg: 640x640 1 person, 2 trucks, 52.9ms\n",
      "Speed: 0.6ms preprocess, 52.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_337_jpg.rf.961796940b13502ddc37ed2a2e063cee.jpg: 640x640 2 persons, 1 train, 1 boat, 1 backpack, 48.3ms\n",
      "Speed: 0.7ms preprocess, 48.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-331-_jpg.rf.ea29c106612a81b5265ea538ee457638.jpg: 640x640 1 person, 1 truck, 62.3ms\n",
      "Speed: 5.1ms preprocess, 62.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox6_mp4-157_jpg.rf.6691e2b4c1959679de0f67afd80747fe.jpg: 640x640 1 person, 1 bicycle, 1 motorcycle, 1 bus, 1 truck, 1 bench, 49.7ms\n",
      "Speed: 1.0ms preprocess, 49.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_MOV-30_jpg.rf.52a36c88b3ce2ba545fd2c44e79a45c3.jpg: 640x640 8 persons, 1 car, 1 train, 1 truck, 42.4ms\n",
      "Speed: 0.9ms preprocess, 42.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/235_jpg.rf.b3db12fa2baf556ce9956e8c4312cd61.jpg: 640x640 1 person, 1 surfboard, 48.8ms\n",
      "Speed: 0.7ms preprocess, 48.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-571_jpg.rf.98dcc380e8a5e5ad1dc66bf5f2376f18.jpg: 640x640 1 car, 1 bus, 1 truck, 46.9ms\n",
      "Speed: 0.7ms preprocess, 46.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-11_jpg.rf.605a9a63de885d697157fad2a64d426f.jpg: 640x640 2 persons, 1 frisbee, 1 remote, 54.7ms\n",
      "Speed: 0.7ms preprocess, 54.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005139_jpg.rf.e8403525bf33f19710d4adb5344256a9.jpg: 640x640 7 persons, 1 skateboard, 52.0ms\n",
      "Speed: 0.6ms preprocess, 52.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-24_jpg.rf.4b65b1bcb5f9753bbb16956181f44659.jpg: 640x640 2 persons, 1 chair, 48.2ms\n",
      "Speed: 0.7ms preprocess, 48.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-564_jpg.rf.4d53a205cd034c39472c8ceebf3af69d.jpg: 640x640 1 person, 2 trucks, 1 toothbrush, 44.9ms\n",
      "Speed: 0.7ms preprocess, 44.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-829_jpg.rf.3c5cf4e90ad5bc6817cd55a98c84e8b5.jpg: 640x640 3 bottles, 43.9ms\n",
      "Speed: 1.0ms preprocess, 43.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2544-_png_jpg.rf.dcf58552354021e725e2535105969f5a.jpg: 640x640 1 person, 2 tvs, 55.2ms\n",
      "Speed: 0.7ms preprocess, 55.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_39_jpg.rf.ae457b40ef2ab2b4b0e24718388019ea.jpg: 640x640 3 persons, 1 train, 1 truck, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-178_jpg.rf.fa1b55734f91780c56954103f0e94ed5.jpg: 640x640 1 person, 1 truck, 41.5ms\n",
      "Speed: 0.7ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_170_jpg.rf.2be45261d9b8c9e3ad48f1d5992a81e0.jpg: 640x640 1 person, 44.0ms\n",
      "Speed: 0.8ms preprocess, 44.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-51_jpg.rf.7e1f61fc8aea97dd1ffa5ee9a64e8299.jpg: 640x640 6 persons, 47.6ms\n",
      "Speed: 0.7ms preprocess, 47.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-568_jpg.rf.b8066e857c2560d855270853a5afbea3.jpg: 640x640 1 person, 1 car, 1 train, 1 truck, 39.0ms\n",
      "Speed: 0.7ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-13_jpg.rf.45050c60edb973136cb5d3f59ba29883.jpg: 640x640 3 persons, 40.2ms\n",
      "Speed: 0.6ms preprocess, 40.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-260_jpg.rf.cecb7cbad4d0e82722464d408d2073c9.jpg: 640x640 1 toilet, 1 toothbrush, 54.7ms\n",
      "Speed: 0.6ms preprocess, 54.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-60_jpg.rf.96ec79cd34674cef3b35219b90d9f753.jpg: 640x640 2 persons, 1 truck, 1 bed, 50.2ms\n",
      "Speed: 1.0ms preprocess, 50.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mask-wearing-1632933572733_png_jpg.rf.9ed180761e32fbbc11dbe2220445c632.jpg: 640x640 1 person, 1 car, 1 bus, 3 trucks, 1 traffic light, 2 chairs, 79.5ms\n",
      "Speed: 1.6ms preprocess, 79.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-64_jpg.rf.e8ae1f94e6832d22568206d85471cbd9.jpg: 640x640 3 persons, 2 motorcycles, 1 airplane, 44.8ms\n",
      "Speed: 0.7ms preprocess, 44.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005577_jpg.rf.f153278ef72ca14b0fee9d9c16331fa2.jpg: 640x640 4 persons, 49.5ms\n",
      "Speed: 0.6ms preprocess, 49.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (37).jpeg: 320x640 3 persons, 30.4ms\n",
      "Speed: 0.6ms preprocess, 30.4ms inference, 0.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008526_jpg.rf.73bbaeff54aafabd9a49d2fdbedb4453.jpg: 640x640 3 persons, 1 umbrella, 46.5ms\n",
      "Speed: 0.7ms preprocess, 46.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008600_jpg.rf.8ce5b36f0111be922eb20834bfedffcd.jpg: 640x640 9 persons, 1 toilet, 38.1ms\n",
      "Speed: 0.6ms preprocess, 38.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-753-_jpg.rf.c51bed05b86b7114bf8279c77899da6e.jpg: 640x640 3 bicycles, 2 trucks, 1 book, 52.7ms\n",
      "Speed: 0.7ms preprocess, 52.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/4c43875bc97cdaece84ac6ce555235f1_jpg.rf.f7fa31a18ba1d08f8e9d322265241f8c.jpg: 640x640 2 persons, 2 bicycles, 1 truck, 1 refrigerator, 49.9ms\n",
      "Speed: 0.6ms preprocess, 49.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-60_jpg.rf.73ba97ab2f23c2ef4776160a27424f5a.jpg: 640x640 1 tie, 49.3ms\n",
      "Speed: 0.6ms preprocess, 49.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_093_jpg.rf.32f5a4ec255bd410a88b1d428d36b978.jpg: 640x640 1 person, 42.8ms\n",
      "Speed: 0.6ms preprocess, 42.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1015-_jpg.rf.7952ff5ef6a051ccadee219cdcc74a86.jpg: 640x640 2 persons, 1 truck, 1 sports ball, 44.7ms\n",
      "Speed: 0.8ms preprocess, 44.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_296_jpg.rf.f15597161ae5df59ecb09ae9e1202399.jpg: 640x640 2 persons, 50.7ms\n",
      "Speed: 0.6ms preprocess, 50.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1015-_jpg.rf.b72ccaf38436e2085a4b0556d337da38.jpg: 640x640 1 person, 1 motorcycle, 2 trucks, 1 vase, 57.1ms\n",
      "Speed: 0.7ms preprocess, 57.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ezgif-frame-049_jpg.rf.b48bcc3d61ced355cb30ff2df96a6925.jpg: 640x640 1 person, 49.4ms\n",
      "Speed: 0.7ms preprocess, 49.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2406-_png_jpg.rf.e4afdc64224be4738b1cdacd09d1c483.jpg: 640x640 2 persons, 1 toilet, 1 cell phone, 46.9ms\n",
      "Speed: 1.9ms preprocess, 46.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_314_jpg.rf.24f21706a57450ecfe9b6a99428c5371.jpg: 640x640 6 persons, 1 bus, 1 train, 1 book, 47.9ms\n",
      "Speed: 0.6ms preprocess, 47.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/01261_jpg.rf.ee044d42291843f1358960c4d8c1d466.jpg: 640x640 4 persons, 52.7ms\n",
      "Speed: 1.3ms preprocess, 52.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3094_mp4-45_jpg.rf.aa91d0d906646ecc9f16df6a94a68d12.jpg: 640x640 2 persons, 1 truck, 1 suitcase, 40.9ms\n",
      "Speed: 0.7ms preprocess, 40.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-741-_jpg.rf.41c3f830c4dfdc4f555898a2864672f1.jpg: 640x640 1 truck, 1 vase, 68.9ms\n",
      "Speed: 0.9ms preprocess, 68.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ezgif-frame-049_jpg.rf.f3de004784deeeac18a38814323b3355.jpg: 640x640 1 person, 1 bottle, 43.5ms\n",
      "Speed: 0.6ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-589_jpg.rf.66e1e48a171f0813592728de2a1d44b1.jpg: 640x640 (no detections), 45.9ms\n",
      "Speed: 0.6ms preprocess, 45.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-812_jpg.rf.a5f34a08b407b48f43169f49917906a2.jpg: 640x640 1 person, 1 dog, 2 bottles, 1 tv, 1 refrigerator, 45.1ms\n",
      "Speed: 0.7ms preprocess, 45.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5024_mp4-2_jpg.rf.f14476eee4096607def4cd1f1883ca5d.jpg: 640x640 3 persons, 1 train, 1 baseball bat, 41.6ms\n",
      "Speed: 0.7ms preprocess, 41.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008364_jpg.rf.6c09ae7ec7500b18c2f9175f7ae996c9.jpg: 640x640 1 person, 1 train, 1 elephant, 1 potted plant, 41.9ms\n",
      "Speed: 0.6ms preprocess, 41.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1062-_jpg.rf.86db01e6cdf1325ed46f34fb10e1a6c9.jpg: 640x640 2 persons, 1 bus, 1 truck, 38.8ms\n",
      "Speed: 0.7ms preprocess, 38.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2406-_png_jpg.rf.bc179b858971b0a65740383c849c429e.jpg: 640x640 2 persons, 1 clock, 44.2ms\n",
      "Speed: 0.6ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-753-_jpg.rf.849b0aba5bde9a36732a6f9a7839eac9.jpg: 640x640 1 train, 2 trucks, 38.5ms\n",
      "Speed: 1.9ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-435-_jpg.rf.3c115485f2e5d31dabe17b006f656489.jpg: 640x640 1 person, 1 bus, 37.4ms\n",
      "Speed: 0.6ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-519_jpg.rf.79bce9674838d4bbfdeb3bcd9eef040e.jpg: 640x640 1 person, 46.9ms\n",
      "Speed: 0.6ms preprocess, 46.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-10_jpg.rf.316b943fdf8f56161e0005bb9c4ec0b2.jpg: 640x640 1 person, 42.9ms\n",
      "Speed: 0.6ms preprocess, 42.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/01094_jpg.rf.5f3dda8b6f1f7908983da80afb575e4e.jpg: 640x640 1 person, 2 trucks, 43.6ms\n",
      "Speed: 0.7ms preprocess, 43.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-162_jpg.rf.52db765af29c85fdf701e0d4a7624fb4.jpg: 640x640 2 persons, 1 truck, 1 toilet, 79.0ms\n",
      "Speed: 0.6ms preprocess, 79.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-253-_jpg.rf.d5829d56d58b707680c115aa1695b7c9.jpg: 640x640 1 person, 2 trucks, 1 cat, 46.2ms\n",
      "Speed: 0.6ms preprocess, 46.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-849_jpg.rf.5d8edd60e5719fa55ed85fc67d814a89.jpg: 640x640 1 truck, 1 traffic light, 1 cell phone, 41.6ms\n",
      "Speed: 0.7ms preprocess, 41.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-75_jpg.rf.0a5bbd753cfb38da9a58c21168decc50.jpg: 640x640 2 persons, 2 toilets, 42.8ms\n",
      "Speed: 0.7ms preprocess, 42.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class1_235_jpg.rf.fd08fc930ee03765015b1177903d0b4f.jpg: 640x640 1 person, 7 cars, 3 trucks, 1 bench, 59.7ms\n",
      "Speed: 0.7ms preprocess, 59.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/01261_jpg.rf.965dff8087002c174bf37951f02806a1.jpg: 640x640 2 persons, 1 train, 38.7ms\n",
      "Speed: 0.6ms preprocess, 38.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_50_jpg.rf.20d6911819d7f972d6606a4636ab1b40.jpg: 640x640 4 persons, 1 truck, 1 boat, 40.3ms\n",
      "Speed: 0.6ms preprocess, 40.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_9949-1-_mp4-63_jpg.rf.0d50a1b1eeb76ddeda4adb7d0713ad40.jpg: 640x640 1 person, 1 truck, 1 toilet, 47.7ms\n",
      "Speed: 0.6ms preprocess, 47.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1116-_jpg.rf.293365d3885eed0bcae63201c5ca15f6.jpg: 640x640 1 truck, 39.3ms\n",
      "Speed: 0.6ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-178_jpg.rf.b8c85b8264b4c4ac5f63983ea0ca05cf.jpg: 640x640 (no detections), 42.9ms\n",
      "Speed: 0.6ms preprocess, 42.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-134_jpg.rf.840e0f602e0c938e439221ddfe6dfd04.jpg: 640x640 1 bus, 1 truck, 42.2ms\n",
      "Speed: 0.7ms preprocess, 42.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-51_jpg.rf.8bba7b3f3b5111e581d7d5a0bdb07604.jpg: 640x640 1 truck, 43.8ms\n",
      "Speed: 0.7ms preprocess, 43.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-49_jpg.rf.eecc0008cd5c3a038f1981f09494321c.jpg: 640x640 2 persons, 1 bus, 1 truck, 1 chair, 55.4ms\n",
      "Speed: 0.8ms preprocess, 55.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-506_jpg.rf.65ef5b727b126d184a659049ddc959c0.jpg: 640x640 1 person, 42.0ms\n",
      "Speed: 0.7ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-27_jpg.rf.bde361a7760285a4b0274f6bb349aacd.jpg: 640x640 1 person, 2 trucks, 39.2ms\n",
      "Speed: 0.7ms preprocess, 39.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008526_jpg.rf.206536056ad018be846c10c1aa29e111.jpg: 640x640 5 persons, 1 bus, 1 bed, 48.8ms\n",
      "Speed: 0.6ms preprocess, 48.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-506_jpg.rf.a80afde96da589684d5c9b15c7b669df.jpg: 640x640 1 backpack, 1 handbag, 41.3ms\n",
      "Speed: 0.7ms preprocess, 41.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-162_jpg.rf.d5b9deac1a1c1205d223e3d604afdd09.jpg: 640x640 4 persons, 1 train, 40.6ms\n",
      "Speed: 0.6ms preprocess, 40.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/002458_jpg.rf.2a5e959314f62660e27f9ab53cf21952.jpg: 640x640 1 person, 1 chair, 38.6ms\n",
      "Speed: 0.6ms preprocess, 38.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-345_jpg.rf.6f2b47989785f4e8d360fb535189ad86.jpg: 640x640 1 person, 1 truck, 46.1ms\n",
      "Speed: 0.7ms preprocess, 46.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_662_jpg.rf.21199937bc568e202a04c5c4e3867511.jpg: 640x640 1 train, 43.6ms\n",
      "Speed: 0.7ms preprocess, 43.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-646_jpg.rf.71fb2940683f013ce350fd3ed47b0ca0.jpg: 640x640 2 persons, 1 chair, 1 refrigerator, 65.9ms\n",
      "Speed: 0.6ms preprocess, 65.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-855-_jpg.rf.2c9f8208d07994d0cca23ba7d0a3f16b.jpg: 640x640 2 trucks, 54.4ms\n",
      "Speed: 0.8ms preprocess, 54.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-39_jpg.rf.e828d532dce99528cc3afc47a75b6c29.jpg: 640x640 1 person, 2 trains, 42.0ms\n",
      "Speed: 0.7ms preprocess, 42.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-1_jpg.rf.ad3568fd357eca826288b3a5988b1bc1.jpg: 640x640 4 persons, 41.4ms\n",
      "Speed: 0.8ms preprocess, 41.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/006118_jpg.rf.52041b1d83e4a812028b6ead912c00e5.jpg: 640x640 3 persons, 40.8ms\n",
      "Speed: 0.7ms preprocess, 40.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005100_jpg.rf.d4b1f7a747d0ebfd6f25d164a3cbb10b.jpg: 640x640 2 persons, 1 chair, 47.5ms\n",
      "Speed: 0.7ms preprocess, 47.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (19).jpeg: 544x640 4 persons, 36.3ms\n",
      "Speed: 1.0ms preprocess, 36.3ms inference, 0.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/hqdefault_jpg.rf.c372926225dba8658d9a64186b850eed.jpg: 640x640 1 bench, 1 horse, 42.3ms\n",
      "Speed: 0.7ms preprocess, 42.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_31_jpg.rf.df389b809c126343ee86d041142c8935.jpg: 640x640 4 persons, 2 cars, 1 cell phone, 38.9ms\n",
      "Speed: 0.6ms preprocess, 38.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-142-_jpg.rf.c9fa15249bd2798628a92f5fecba86d2.jpg: 640x640 2 persons, 1 truck, 49.8ms\n",
      "Speed: 0.6ms preprocess, 49.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-395_jpg.rf.569e142fec0c8439b9954ca2ec2b0d7c.jpg: 640x640 4 persons, 1 boat, 39.8ms\n",
      "Speed: 0.6ms preprocess, 39.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_46_jpg.rf.fca0eb9eb04c5c3fc20e3783f18f56f2.jpg: 640x640 3 persons, 1 truck, 40.1ms\n",
      "Speed: 0.6ms preprocess, 40.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-196_jpg.rf.f867c0e95ef00e76e642e924d22d717f.jpg: 640x640 4 persons, 62.2ms\n",
      "Speed: 0.7ms preprocess, 62.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (32).jpeg: 448x640 3 persons, 31.9ms\n",
      "Speed: 5.8ms preprocess, 31.9ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0750_jpg.rf.6a25fb7ef7bba0bbadeaa81926f2500c.jpg: 640x640 3 persons, 2 cars, 3 trucks, 1 tie, 45.5ms\n",
      "Speed: 0.7ms preprocess, 45.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/01094_jpg.rf.15d2452cfbd2f25016ddb1bb90f0e19a.jpg: 640x640 2 persons, 43.4ms\n",
      "Speed: 0.7ms preprocess, 43.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-23_jpg.rf.4f6c342990c036513c4bf9befc409c7b.jpg: 640x640 2 persons, 2 ties, 1 chair, 50.3ms\n",
      "Speed: 0.6ms preprocess, 50.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/YouTube-FreeStockFootage_Child-playing-with-parents-JoyLaughterHD-RQ_qqCZOkZk-720p_mp4-42_jpg.rf.25f28feb71c8eb2365ddef7281c16786.jpg: 640x640 3 persons, 1 bird, 39.0ms\n",
      "Speed: 0.6ms preprocess, 39.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-824_jpg.rf.f823acb225df022187a49a848be78f54.jpg: 640x640 1 person, 1 chair, 1 refrigerator, 51.9ms\n",
      "Speed: 0.9ms preprocess, 51.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-13_jpg.rf.7f6ecc3e5497f54e3146fa73d8936ade.jpg: 640x640 5 persons, 2 traffic lights, 41.0ms\n",
      "Speed: 0.7ms preprocess, 41.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/001425_jpg.rf.8d9766a13f37413d9a9b509766897167.jpg: 640x640 3 persons, 1 car, 3 trucks, 52.7ms\n",
      "Speed: 0.7ms preprocess, 52.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-23_jpg.rf.7042315ee68e17ead44f4637c6e7fdab.jpg: 640x640 1 person, 1 car, 1 truck, 1 cell phone, 40.8ms\n",
      "Speed: 0.6ms preprocess, 40.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_153_jpg.rf.da2dfd3346476f74fa1ddc0690c5defc.jpg: 640x640 2 persons, 1 motorcycle, 1 cell phone, 40.0ms\n",
      "Speed: 0.7ms preprocess, 40.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-815_jpg.rf.efcb04fd1022521a86e34b4fde943808.jpg: 640x640 1 person, 1 bus, 3 trucks, 5 bottles, 1 bed, 1 refrigerator, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-821-_jpg.rf.f3d6f50ef917d0bf1a77282663f1e7a0.jpg: 640x640 2 persons, 1 truck, 70.8ms\n",
      "Speed: 0.6ms preprocess, 70.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-137_jpg.rf.aafab9fa046d884e1426603f80ea53d4.jpg: 640x640 1 person, 1 motorcycle, 42.6ms\n",
      "Speed: 0.6ms preprocess, 42.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_704_jpg.rf.a5b43ef2288512fbe06fe5863393da06.jpg: 640x640 1 person, 49.5ms\n",
      "Speed: 0.6ms preprocess, 49.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-709_jpg.rf.25b93351042304554ba1fc60eb8ce451.jpg: 640x640 3 persons, 51.9ms\n",
      "Speed: 0.6ms preprocess, 51.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-434-_jpg.rf.3bc7d72cfb1fd34c037931a5fc361028.jpg: 640x640 2 trucks, 1 boat, 41.1ms\n",
      "Speed: 0.7ms preprocess, 41.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-13_jpg.rf.f99e4eb123997cf1a94823e7091657df.jpg: 640x640 1 person, 1 train, 1 truck, 43.4ms\n",
      "Speed: 0.7ms preprocess, 43.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-127_jpg.rf.369dffc6c0812c73e687686e68e9bde3.jpg: 640x640 2 persons, 40.9ms\n",
      "Speed: 0.6ms preprocess, 40.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0985_jpg.rf.0f64a0473bdc767099a74d9b34f1725f.jpg: 640x640 3 persons, 1 truck, 51.5ms\n",
      "Speed: 0.8ms preprocess, 51.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class1_253_jpg.rf.1929d248256fadf2751deed3207a4326.jpg: 640x640 11 persons, 1 car, 1 train, 1 umbrella, 38.9ms\n",
      "Speed: 0.6ms preprocess, 38.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5024_mp4-5_jpg.rf.29486c821e09b032fafdda06d7c86434.jpg: 640x640 4 persons, 1 truck, 1 clock, 42.1ms\n",
      "Speed: 0.7ms preprocess, 42.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-230_jpg.rf.1892d9772f890c9e7a3533235a85887e.jpg: 640x640 1 person, 1 truck, 2 surfboards, 51.2ms\n",
      "Speed: 0.6ms preprocess, 51.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/front_crawling_00088_jpg.rf.7f5ce5d70f21af8e25741e12f0bfbae7.jpg: 640x640 2 persons, 1 car, 2 umbrellas, 39.5ms\n",
      "Speed: 0.6ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-459_jpg.rf.0cb0664d323d2c5610c34fcfcb706be5.jpg: 640x640 5 persons, 1 truck, 53.7ms\n",
      "Speed: 0.7ms preprocess, 53.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-17_jpg.rf.12d9b740632bc47db175529b4c6acfec.jpg: 640x640 8 persons, 1 refrigerator, 39.0ms\n",
      "Speed: 0.6ms preprocess, 39.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008600_jpg.rf.1e30fdd484a479256bd540cc92dc375b.jpg: 640x640 1 person, 1 couch, 72.8ms\n",
      "Speed: 0.6ms preprocess, 72.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-210_jpg.rf.12b470e1de5ec9374cafd5d827da6fa6.jpg: 640x640 4 persons, 1 parking meter, 1 suitcase, 49.0ms\n",
      "Speed: 0.7ms preprocess, 49.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005139_jpg.rf.d3163480876e9f5a621e25e44ece6db4.jpg: 640x640 2 persons, 1 bus, 2 trucks, 2 traffic lights, 41.4ms\n",
      "Speed: 0.7ms preprocess, 41.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/amz_04178_png_jpg.rf.4313b414c237d190af0ad60830b5bd4c.jpg: 640x640 2 persons, 1 bottle, 44.2ms\n",
      "Speed: 0.8ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (36).jpeg: 640x448 1 person, 31.1ms\n",
      "Speed: 0.8ms preprocess, 31.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008382_jpg.rf.051446bdb7b3da2d378bef843e2db409.jpg: 640x640 5 persons, 2 bicycles, 1 train, 40.8ms\n",
      "Speed: 0.7ms preprocess, 40.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-741-_jpg.rf.49657de04621c1d8f3e6dbc94ecea094.jpg: 640x640 2 persons, 1 car, 1 train, 37.8ms\n",
      "Speed: 1.0ms preprocess, 37.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_MOV-39_jpg.rf.cad305edda519e95291dd63518835f82.jpg: 640x640 2 persons, 1 truck, 42.7ms\n",
      "Speed: 0.6ms preprocess, 42.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0345_jpg.rf.81733cc3cc37d665aabb9d11122ab053.jpg: 640x640 1 person, 1 train, 1 dining table, 38.2ms\n",
      "Speed: 0.7ms preprocess, 38.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mask-wearing-1632933572733_png_jpg.rf.d1dfda64eb6981fe3fdad9f598ab047a.jpg: 640x640 1 person, 49.7ms\n",
      "Speed: 0.7ms preprocess, 49.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox5_mp4-34_jpg.rf.9355e6d129f90d4f5be17f3f93259086.jpg: 640x640 1 person, 1 bicycle, 1 potted plant, 38.6ms\n",
      "Speed: 0.6ms preprocess, 38.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-19_jpg.rf.9bd721934889a9f63923ffb5285f4d3c.jpg: 640x640 1 person, 1 laptop, 47.4ms\n",
      "Speed: 0.7ms preprocess, 47.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-376_jpg.rf.46021b529c258b26fdaef182a608a53e.jpg: 640x640 1 boat, 48.4ms\n",
      "Speed: 0.6ms preprocess, 48.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_326_jpg.rf.ea420584500c363c0851769a46b1ea3e.jpg: 640x640 1 person, 1 car, 1 horse, 44.3ms\n",
      "Speed: 0.7ms preprocess, 44.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0214_jpg.rf.15a384374cf39042cbdd00d9a0973b36.jpg: 640x640 3 persons, 1 motorcycle, 1 truck, 1 umbrella, 41.9ms\n",
      "Speed: 0.7ms preprocess, 41.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0449_jpg.rf.22ef0328c4e2f82d4914c26b9402595d.jpg: 640x640 1 person, 52.9ms\n",
      "Speed: 0.6ms preprocess, 52.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-30_jpg.rf.5c8e550b1e5053b550bdc04845a56783.jpg: 640x640 2 persons, 2 trucks, 56.1ms\n",
      "Speed: 0.6ms preprocess, 56.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_704_jpg.rf.4c741a4ebadf03219d0d8d3b230b09a4.jpg: 640x640 1 person, 1 airplane, 1 truck, 39.2ms\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-135-_jpg.rf.91c126ddc875b52d91504259fec10f83.jpg: 640x640 3 persons, 46.1ms\n",
      "Speed: 0.6ms preprocess, 46.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RTX7CD4D-e1580252893876_jpg.rf.440e3fa953f740b0f78757c7bfa93d11.jpg: 640x640 1 person, 39.9ms\n",
      "Speed: 0.7ms preprocess, 39.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_475_jpg.rf.a9769a70f9c33b6092d6cf9be6d3ebf3.jpg: 640x640 1 truck, 1 bottle, 1 cell phone, 67.6ms\n",
      "Speed: 0.6ms preprocess, 67.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-300_jpg.rf.f9854531d289c54ada6069fb0b68d2b4.jpg: 640x640 1 person, 44.4ms\n",
      "Speed: 0.7ms preprocess, 44.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-649-_jpg.rf.d57527f5b80000d1931bdb5d407e3a44.jpg: 640x640 3 persons, 1 bus, 1 train, 2 trucks, 1 wine glass, 51.8ms\n",
      "Speed: 0.7ms preprocess, 51.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-645_jpg.rf.8a5e2742de2430f50d2641fa3e7151cf.jpg: 640x640 1 person, 1 fire hydrant, 41.3ms\n",
      "Speed: 0.7ms preprocess, 41.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-10_jpg.rf.2afaba4c97c2c1d857f56a414abe9d7f.jpg: 640x640 1 person, 1 bicycle, 2 chairs, 43.0ms\n",
      "Speed: 0.7ms preprocess, 43.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-435_jpg.rf.b2cdb9d22be30935907246df6a8ea86d.jpg: 640x640 2 persons, 1 cow, 44.2ms\n",
      "Speed: 0.6ms preprocess, 44.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-574_jpg.rf.4f2d383a6755c89da14c19c04f482a11.jpg: 640x640 2 persons, 1 truck, 1 bench, 1 giraffe, 1 surfboard, 1 refrigerator, 48.4ms\n",
      "Speed: 0.7ms preprocess, 48.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-137_jpg.rf.655f978410609149efe49e2f10031d2f.jpg: 640x640 2 persons, 1 tie, 39.2ms\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-270_jpg.rf.9ae5283f885f67c55f351ac2d03e2053.jpg: 640x640 2 cars, 1 train, 1 truck, 1 kite, 40.2ms\n",
      "Speed: 0.6ms preprocess, 40.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-572-_jpg.rf.68ee8e58fe38f98c89b0341be036d5cd.jpg: 640x640 4 persons, 3 trucks, 41.4ms\n",
      "Speed: 0.6ms preprocess, 41.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-67_jpg.rf.a10d621dac22f2888b49e1abe9bb5296.jpg: 640x640 1 person, 1 airplane, 1 bus, 38.5ms\n",
      "Speed: 0.7ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/n190039_jpg.rf.8d25d64c2c6cc1fd56cafbe151d2d32a.jpg: 640x640 4 persons, 1 potted plant, 1 cell phone, 41.2ms\n",
      "Speed: 0.7ms preprocess, 41.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/hqdefault_jpg.rf.4706073e06174142f831b93adb16f07d.jpg: 640x640 4 persons, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0460_jpg.rf.08bdc9d5bdd94eda87888c1082b3871f.jpg: 640x640 3 persons, 74.9ms\n",
      "Speed: 0.6ms preprocess, 74.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RTX7CD4D-e1580252893876_jpg.rf.79dfa1562749048955b91d007f2ca5b7.jpg: 640x640 5 persons, 2 bottles, 1 chair, 60.0ms\n",
      "Speed: 0.6ms preprocess, 60.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/YouTube-FreeStockFootage_Child-playing-with-parents-JoyLaughterHD-RQ_qqCZOkZk-720p_mp4-42_jpg.rf.3d9c8da9d6790fd2f6e0bec895ca1a81.jpg: 640x640 1 person, 43.1ms\n",
      "Speed: 0.7ms preprocess, 43.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_7211_PNG_jpg.rf.4cc6e82cb3e26474fe674ea343197438.jpg: 640x640 2 persons, 1 clock, 43.0ms\n",
      "Speed: 0.7ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-360_jpg.rf.16fc1037fb64a35c8c2acad6f366915d.jpg: 640x640 3 trucks, 41.7ms\n",
      "Speed: 0.8ms preprocess, 41.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-622_jpg.rf.05aa5b08154e5b2ae45002d5a742b1da.jpg: 640x640 2 persons, 1 motorcycle, 39.5ms\n",
      "Speed: 0.6ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_833_jpg.rf.550df56bda117a625df46ce9c44e457c.jpg: 640x640 2 trucks, 37.4ms\n",
      "Speed: 0.7ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_4921-2_mp4-40_jpg.rf.4c12e2beca4e02b9674e6e64aa58c693.jpg: 640x640 2 persons, 1 motorcycle, 2 trucks, 1 suitcase, 38.8ms\n",
      "Speed: 0.7ms preprocess, 38.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-645_jpg.rf.0cae206994074c96880eee9f8b4f6fa0.jpg: 640x640 2 persons, 35.3ms\n",
      "Speed: 15.8ms preprocess, 35.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-246-_jpg.rf.bded1f9cc77f185a6281e371634a4759.jpg: 640x640 2 persons, 1 car, 37.8ms\n",
      "Speed: 0.6ms preprocess, 37.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-210_jpg.rf.3f1db97359eab99f4c5034600951928d.jpg: 640x640 2 persons, 40.1ms\n",
      "Speed: 0.7ms preprocess, 40.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008382_jpg.rf.17d1f80e4513c2e3b16de5fbc649828d.jpg: 640x640 2 persons, 1 car, 1 train, 1 truck, 1 traffic light, 42.6ms\n",
      "Speed: 0.7ms preprocess, 42.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_55_jpg.rf.687fe5037e332ac02eb6cc93310845be.jpg: 640x640 2 persons, 1 truck, 54.8ms\n",
      "Speed: 2.6ms preprocess, 54.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-502_jpg.rf.c3320c43830b6fc9bbcb449d42c5a810.jpg: 640x640 4 persons, 1 remote, 1 book, 40.7ms\n",
      "Speed: 0.7ms preprocess, 40.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-305-_jpg.rf.a695e0f5685a2f573642f4bffe29d357.jpg: 640x640 1 person, 1 truck, 1 cell phone, 40.8ms\n",
      "Speed: 0.6ms preprocess, 40.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-641_jpg.rf.9bb57cfffa7710f279d94e83dc8911ea.jpg: 640x640 1 truck, 48.7ms\n",
      "Speed: 0.7ms preprocess, 48.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0449_jpg.rf.96ce7258cff66f91dc199992535159d2.jpg: 640x640 1 person, 2 cars, 3 trucks, 37.7ms\n",
      "Speed: 0.6ms preprocess, 37.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005310_jpg.rf.31b8beb7dd8e338e4818d2e1a648656f.jpg: 640x640 5 persons, 36.1ms\n",
      "Speed: 0.6ms preprocess, 36.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_321_jpg.rf.7637c30937425c6bdbc08729f2061840.jpg: 640x640 3 cars, 2 trucks, 1 boat, 48.9ms\n",
      "Speed: 0.7ms preprocess, 48.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_1021_jpg.rf.a634f371a9b4f20d220232a0a199e146.jpg: 640x640 2 persons, 1 bicycle, 2 trucks, 1 refrigerator, 41.9ms\n",
      "Speed: 0.8ms preprocess, 41.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Inside-merge_mov-16_jpg.rf.6c01f603e4e10decc54abf1947db7fae.jpg: 640x640 1 person, 1 truck, 37.9ms\n",
      "Speed: 0.7ms preprocess, 37.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/588_jpg.rf.f4b4ae3e5ee90c957a0b8a62cbd88954.jpg: 640x640 1 person, 1 car, 1 parking meter, 1 clock, 38.3ms\n",
      "Speed: 0.7ms preprocess, 38.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_1021_jpg.rf.794cab9898f50fcb8d8ff3251f69b035.jpg: 640x640 1 person, 2 trucks, 43.7ms\n",
      "Speed: 0.6ms preprocess, 43.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/235_jpg.rf.fc43ddf1f7b8872bae6b2d1f1495f634.jpg: 640x640 4 persons, 1 truck, 1 backpack, 1 tie, 47.9ms\n",
      "Speed: 0.9ms preprocess, 47.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-23_jpg.rf.d607fb0a64fc766fd1af875a5b159789.jpg: 640x640 1 person, 2 trucks, 39.7ms\n",
      "Speed: 0.6ms preprocess, 39.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-832_jpg.rf.fd422fc645f0412c547da78aea7f856f.jpg: 640x640 10 persons, 38.2ms\n",
      "Speed: 0.7ms preprocess, 38.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-18_jpg.rf.e9a52e771b256c2e73a344a78e56bc3d.jpg: 640x640 2 persons, 1 truck, 2 traffic lights, 1 chair, 40.5ms\n",
      "Speed: 0.7ms preprocess, 40.5ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-135-_jpg.rf.20b41fe526103f184c02d97a303fa695.jpg: 640x640 7 persons, 1 car, 1 surfboard, 38.4ms\n",
      "Speed: 0.6ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-693_jpg.rf.52fec3a45fb4c747d62c2b581d831c89.jpg: 640x640 1 person, 1 truck, 2 boats, 1 refrigerator, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-230_jpg.rf.8c88cdcc6732cbf4431747bef40863c4.jpg: 640x640 1 person, 2 motorcycles, 36.9ms\n",
      "Speed: 0.6ms preprocess, 36.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_731_jpg.rf.448630cbbbb702e4ba5710dc31384d0a.jpg: 640x640 1 chair, 39.6ms\n",
      "Speed: 0.6ms preprocess, 39.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-360_jpg.rf.7919b4215e055f4ac79add205695891d.jpg: 640x640 4 persons, 1 wine glass, 1 potted plant, 46.6ms\n",
      "Speed: 0.6ms preprocess, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0460_jpg.rf.aae905a80f304e8b4a3e3c738887490b.jpg: 640x640 3 persons, 1 car, 37.6ms\n",
      "Speed: 0.6ms preprocess, 37.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/smartmi-3pcs-filter-mask-pm25-haze-dustproof-mask-with-vent_jpg.rf.79f2ac44db8c468f5e8f2605b25ef935.jpg: 640x640 6 persons, 1 chair, 1 dining table, 66.1ms\n",
      "Speed: 0.6ms preprocess, 66.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/bowling_0014_jpg.rf.192dc02b9aca65ed8c0200d86ff873e5.jpg: 640x640 2 persons, 1 banana, 47.5ms\n",
      "Speed: 0.7ms preprocess, 47.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-628_jpg.rf.d427d0722bf65a27b71bb4ef33451f84.jpg: 640x640 (no detections), 52.9ms\n",
      "Speed: 0.7ms preprocess, 52.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-897-_jpg.rf.030a41f60cc0ce2a5aba9dcdf212890f.jpg: 640x640 1 person, 1 airplane, 40.3ms\n",
      "Speed: 0.7ms preprocess, 40.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5024_mp4-2_jpg.rf.c5b2608e4802e3b71e2e51862b3e1542.jpg: 640x640 4 persons, 1 clock, 40.7ms\n",
      "Speed: 0.7ms preprocess, 40.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-115_jpg.rf.4dccb4f6ffaaa020f6b83ad8f7f8554f.jpg: 640x640 5 persons, 1 truck, 38.7ms\n",
      "Speed: 0.6ms preprocess, 38.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1062-_jpg.rf.1c92fda4bd441d59c70cb857fe1283c0.jpg: 640x640 1 bus, 1 bottle, 37.1ms\n",
      "Speed: 0.6ms preprocess, 37.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-27_jpg.rf.f10be4f4f70251914ecd0a0c1de06aca.jpg: 640x640 2 persons, 2 trucks, 1 baseball glove, 46.6ms\n",
      "Speed: 0.7ms preprocess, 46.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_995_jpg.rf.3b80546909b3559f8b16499a38571d88.jpg: 640x640 2 trucks, 39.5ms\n",
      "Speed: 0.6ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2544-_png_jpg.rf.cbcb183dbec853ee769df1327119472b.jpg: 640x640 1 person, 1 car, 1 truck, 1 tie, 44.6ms\n",
      "Speed: 0.6ms preprocess, 44.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-55_jpg.rf.a4b3b31384a7f232413a5a84ca3136d7.jpg: 640x640 1 person, 1 train, 1 truck, 37.2ms\n",
      "Speed: 0.7ms preprocess, 37.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-212-_jpg.rf.c2e946e66af55cde7a9039b41eab1fdb.jpg: 640x640 (no detections), 38.3ms\n",
      "Speed: 0.6ms preprocess, 38.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-24_jpg.rf.f251793e25ddd374d88a3d05b2ba10ce.jpg: 640x640 1 cat, 68.2ms\n",
      "Speed: 0.6ms preprocess, 68.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-334_jpg.rf.f33a2325e096dc60c0118bcb6c706c72.jpg: 640x640 2 persons, 39.3ms\n",
      "Speed: 0.8ms preprocess, 39.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-131_jpg.rf.c61a789bdcc60c1185c62073f8d24b24.jpg: 640x640 3 persons, 1 truck, 40.3ms\n",
      "Speed: 0.6ms preprocess, 40.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-832_jpg.rf.8d9fc0352bb230129a4485a2f0aec4eb.jpg: 640x640 (no detections), 41.5ms\n",
      "Speed: 0.6ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-137_jpg.rf.c21fdd6ea91c01d8f9f37d3f8cc7e474.jpg: 640x640 1 person, 1 bicycle, 41.9ms\n",
      "Speed: 0.8ms preprocess, 41.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/move_in_corridor_jpg.rf.6ab9a86dad87653d6f45f5a8e51a0efa.jpg: 640x640 3 persons, 1 truck, 48.8ms\n",
      "Speed: 0.8ms preprocess, 48.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-252_jpg.rf.00af025f2854a4f79fbd9a657ca0f335.jpg: 640x640 1 person, 1 truck, 1 bird, 39.6ms\n",
      "Speed: 0.7ms preprocess, 39.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-18_jpg.rf.0e8406438fb943d30b283fd375756634.jpg: 640x640 1 person, 1 bus, 2 trucks, 36.9ms\n",
      "Speed: 0.7ms preprocess, 36.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-872-_jpg.rf.64b854dc31c9900921840c3652d3c449.jpg: 640x640 1 bus, 2 trucks, 1 traffic light, 1 clock, 40.2ms\n",
      "Speed: 0.6ms preprocess, 40.2ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-384_jpg.rf.b68e01bd9465f42161d0ef3c0b378b94.jpg: 640x640 3 persons, 1 car, 2 trucks, 1 bottle, 36.7ms\n",
      "Speed: 0.7ms preprocess, 36.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-94_jpg.rf.faa54990813350bf15eebdb3d1ace03d.jpg: 640x640 9 persons, 1 car, 1 traffic light, 1 skis, 36.2ms\n",
      "Speed: 0.6ms preprocess, 36.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-331-_jpg.rf.a81eec9d26ee319d3d0cc6692ad1018c.jpg: 640x640 1 bottle, 37.2ms\n",
      "Speed: 0.6ms preprocess, 37.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (1).jpeg: 448x640 4 persons, 27.2ms\n",
      "Speed: 0.8ms preprocess, 27.2ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-844-_jpg.rf.cfda77282f185f7885d3bce88583dbe7.jpg: 640x640 1 truck, 1 snowboard, 1 surfboard, 68.4ms\n",
      "Speed: 0.6ms preprocess, 68.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/707_jpg.rf.8457eeaff99b07ff4e8ccb2317a7092a.jpg: 640x640 1 refrigerator, 36.9ms\n",
      "Speed: 0.7ms preprocess, 36.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_560_jpg.rf.c9db5d5571253f2e6bd8b8559e0cc313.jpg: 640x640 1 truck, 1 cell phone, 41.7ms\n",
      "Speed: 0.7ms preprocess, 41.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/588_jpg.rf.0fa1d16e756d16422a39783c8f4926c1.jpg: 640x640 2 persons, 41.6ms\n",
      "Speed: 0.7ms preprocess, 41.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-197_jpg.rf.85f809ae1a9cbc6d2d95bd7d28bc461d.jpg: 640x640 (no detections), 47.4ms\n",
      "Speed: 0.7ms preprocess, 47.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-295_jpg.rf.6a93d92523b87b45efa10c3ce16c4c48.jpg: 640x640 4 persons, 1 clock, 41.6ms\n",
      "Speed: 0.7ms preprocess, 41.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_1025_jpg.rf.d305cc24e2ade948caab2bb624791bb4.jpg: 640x640 3 trucks, 1 dog, 36.9ms\n",
      "Speed: 0.6ms preprocess, 36.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-1_jpg.rf.7f7885aea560be0f8179588784380905.jpg: 640x640 3 persons, 1 car, 1 bus, 1 chair, 1 bed, 37.0ms\n",
      "Speed: 0.6ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005376_jpg.rf.f9d2282335b826a6baedffbb64cde582.jpg: 640x640 4 persons, 1 tie, 53.3ms\n",
      "Speed: 0.8ms preprocess, 53.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-668_jpg.rf.ce3804ef6c8f28490efeb8d2b5d52090.jpg: 640x640 1 car, 36.9ms\n",
      "Speed: 0.7ms preprocess, 36.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_818_jpg.rf.e6cd4aff34d752d2094d6c52cecaa239.jpg: 640x640 1 person, 2 trucks, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_833_jpg.rf.66e2de7c05f5df0dd6c1a0657d60f994.jpg: 640x640 4 persons, 70.2ms\n",
      "Speed: 0.6ms preprocess, 70.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-96_jpg.rf.fa2cc7cf3b5931a8ec0dfa59b68f5902.jpg: 640x640 1 person, 1 airplane, 42.2ms\n",
      "Speed: 0.6ms preprocess, 42.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-94_jpg.rf.2b9ba76d627d94a28cf92437d21569cc.jpg: 640x640 2 persons, 1 truck, 1 banana, 39.9ms\n",
      "Speed: 0.6ms preprocess, 39.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-188_jpg.rf.577e87be1f729e28f67a8dbf7734d643.jpg: 640x640 1 person, 1 car, 1 train, 1 truck, 1 bottle, 40.5ms\n",
      "Speed: 0.7ms preprocess, 40.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_991_jpg.rf.bedcfa2a8c7af22e5cf13c894e51bcf5.jpg: 640x640 (no detections), 46.3ms\n",
      "Speed: 0.7ms preprocess, 46.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/img_038_jpg.rf.c9387fae49bc708d612f2ea1f6af8005.jpg: 640x640 8 persons, 1 snowboard, 1 clock, 37.3ms\n",
      "Speed: 0.6ms preprocess, 37.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-407_jpg.rf.dda53fd876a4038b177e007c5948a3f5.jpg: 640x640 1 train, 37.5ms\n",
      "Speed: 0.7ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-15_jpg.rf.c31067570072a0839fd1ab6cd0b7a5a7.jpg: 640x640 9 persons, 37.0ms\n",
      "Speed: 0.6ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-219_jpg.rf.1498e9d4c6c28b283f27aad0187aed96.jpg: 640x640 5 persons, 2 dining tables, 42.2ms\n",
      "Speed: 0.7ms preprocess, 42.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_418_jpg.rf.cf249e5eac03db2a9bb969ee2acec825.jpg: 640x640 4 persons, 1 car, 1 chair, 40.0ms\n",
      "Speed: 0.7ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-2_jpg.rf.c28f7521c16c937d5b308d185151f610.jpg: 640x640 2 persons, 1 car, 1 truck, 1 cat, 1 bottle, 38.0ms\n",
      "Speed: 0.7ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_784_jpg.rf.d2c68db9d95f69548f5424ecfebca1ad.jpg: 640x640 1 car, 1 book, 67.8ms\n",
      "Speed: 0.7ms preprocess, 67.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-731_jpg.rf.75f1bb8c05e0e1ba3667e6b1fbce8250.jpg: 640x640 2 persons, 1 motorcycle, 51.5ms\n",
      "Speed: 0.7ms preprocess, 51.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-860-_jpg.rf.798a96cd719c190547f83bbdd331555e.jpg: 640x640 4 persons, 51.6ms\n",
      "Speed: 0.7ms preprocess, 51.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-502_jpg.rf.05c0bca95928741d8ec0f5cebae1f23c.jpg: 640x640 2 persons, 3 trucks, 42.0ms\n",
      "Speed: 0.7ms preprocess, 42.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_9949-1-_mp4-63_jpg.rf.23b3f6343eb2c857c3fddd2fd0b9307e.jpg: 640x640 4 cars, 2 trucks, 41.9ms\n",
      "Speed: 0.6ms preprocess, 41.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/277_jpg.rf.e533863ccfdd0dba4c8d7089ef7b965d.jpg: 640x640 1 person, 1 vase, 38.2ms\n",
      "Speed: 0.7ms preprocess, 38.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-260_jpg.rf.bf204cb73ecb38d4c88045354ba687d1.jpg: 640x640 3 persons, 1 truck, 1 horse, 38.6ms\n",
      "Speed: 0.6ms preprocess, 38.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_176_jpg.rf.1716b2e67aed8cdf829114b18ad9a099.jpg: 640x640 4 trucks, 36.2ms\n",
      "Speed: 0.6ms preprocess, 36.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/istockphoto-1469127968-612x612.jpg: 448x640 1 person, 1 backpack, 3 suitcases, 29.2ms\n",
      "Speed: 1.0ms preprocess, 29.2ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_861_jpg.rf.200a7afabef8d142040c9a6bb1d6b2f9.jpg: 640x640 4 persons, 45.5ms\n",
      "Speed: 0.6ms preprocess, 45.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/img_038_jpg.rf.e152b3af6aa26c6ffd65ade299de5771.jpg: 640x640 6 persons, 38.3ms\n",
      "Speed: 0.6ms preprocess, 38.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mask-wearing-1632932085584_png_jpg.rf.a2d2e5702d2eec45420a4e9b1aa215d4.jpg: 640x640 3 persons, 1 chair, 2 laptops, 37.7ms\n",
      "Speed: 0.6ms preprocess, 37.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-695_jpg.rf.4c25a8537275a63e5c32e0f48e03ad7c.jpg: 640x640 4 persons, 2 ties, 95.2ms\n",
      "Speed: 0.6ms preprocess, 95.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_1025_jpg.rf.61268a2f144c707d1190c9370721cb9e.jpg: 640x640 (no detections), 44.8ms\n",
      "Speed: 0.7ms preprocess, 44.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008600_jpg.rf.d8f5f9cf688bbe34999c4fdea17bc8bf.jpg: 640x640 1 person, 1 bed, 40.9ms\n",
      "Speed: 0.7ms preprocess, 40.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mms_00692_jpg.rf.172c70de90c7f0170272abdf699d97b1.jpg: 640x640 2 persons, 1 tie, 41.9ms\n",
      "Speed: 0.6ms preprocess, 41.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-14_jpg.rf.68a9069434b346382290a1134d3b52fd.jpg: 640x640 2 persons, 41.6ms\n",
      "Speed: 0.8ms preprocess, 41.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/60_jpg.rf.7605faf52324ab72b148018c8ed93813.jpg: 640x640 2 persons, 1 train, 1 potted plant, 39.3ms\n",
      "Speed: 0.6ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0738_jpg.rf.8bdd2b07822885389235a1076d2f9da4.jpg: 640x640 1 person, 51.7ms\n",
      "Speed: 0.7ms preprocess, 51.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0015_jpg.rf.371607a3e9a7ecac36a75f2f9877ee94.jpg: 640x640 10 persons, 1 train, 1 truck, 39.3ms\n",
      "Speed: 0.7ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-15_jpg.rf.32f738570f4a7f171454c1623720ea61.jpg: 640x640 2 persons, 2 books, 38.9ms\n",
      "Speed: 0.9ms preprocess, 38.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox5_mp4-34_jpg.rf.cc87f9ec9778844aea62a27a0ad2130f.jpg: 640x640 1 person, 1 car, 1 truck, 1 surfboard, 39.4ms\n",
      "Speed: 0.6ms preprocess, 39.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_000280_jpg.rf.14ea05d770d7a1cdd2ee28b6d7901c86.jpg: 640x640 2 cars, 1 bus, 2 trucks, 63.6ms\n",
      "Speed: 0.6ms preprocess, 63.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_61_jpg.rf.06b130702a18cbe9775cfef7e58ff369.jpg: 640x640 3 persons, 51.9ms\n",
      "Speed: 0.6ms preprocess, 51.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5848_jpg.rf.2dc727dbdae4d8ec162b98b6ca5370b9.jpg: 640x640 3 persons, 40.0ms\n",
      "Speed: 0.7ms preprocess, 40.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox3_mp4-49_jpg.rf.6121fb64e33a8b42f4492a6a9740edc2.jpg: 640x640 3 persons, 1 car, 39.4ms\n",
      "Speed: 0.7ms preprocess, 39.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-763-_jpg.rf.22c7434345e36046b5c018f024f4811a.jpg: 640x640 1 person, 3 trains, 38.4ms\n",
      "Speed: 0.8ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-3_jpg.rf.3eccf410a77d6c12ed9fd789a3b8867b.jpg: 640x640 2 persons, 1 truck, 1 vase, 45.3ms\n",
      "Speed: 0.7ms preprocess, 45.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Libreria_09_20_altavista_jpg.rf.37034555ce000a9156534c8ffb6736d0.jpg: 640x640 3 persons, 39.2ms\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/598_jpg.rf.a7412d17da518abc68373b0c0e9edb08.jpg: 640x640 2 persons, 1 boat, 36.7ms\n",
      "Speed: 0.7ms preprocess, 36.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-806_jpg.rf.c8952e265f0c4af327b56f43b365537a.jpg: 640x640 1 bus, 1 train, 2 trucks, 39.4ms\n",
      "Speed: 0.6ms preprocess, 39.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-661_jpg.rf.b0ae3ac48fdc989a2fc886f789d6b951.jpg: 640x640 5 persons, 1 car, 1 skateboard, 45.4ms\n",
      "Speed: 0.7ms preprocess, 45.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/01094_jpg.rf.a353aa741bea05e999eed430fbca7d6b.jpg: 640x640 4 persons, 1 bottle, 1 bed, 38.7ms\n",
      "Speed: 0.6ms preprocess, 38.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-682-_jpg.rf.4f5711298668cec5cf63e8c7f8d7541d.jpg: 640x640 2 persons, 62.6ms\n",
      "Speed: 0.6ms preprocess, 62.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/02629_jpg.rf.b9355827a29589ddae4528281e89a885.jpg: 640x640 5 persons, 50.6ms\n",
      "Speed: 0.7ms preprocess, 50.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/MariusConePic60_png_jpg.rf.b0a75275cc2fdadceedf0e6452a04678.jpg: 640x640 1 person, 1 train, 1 cell phone, 42.6ms\n",
      "Speed: 10.9ms preprocess, 42.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_176_jpg.rf.d8619d7aa3fd3c89fecb3bd21942cfee.jpg: 640x640 4 suitcases, 39.4ms\n",
      "Speed: 0.6ms preprocess, 39.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2_jpg.rf.81cecacca0143515726201efb42fe5b6.jpg: 640x640 2 cars, 1 airplane, 1 train, 40.6ms\n",
      "Speed: 0.7ms preprocess, 40.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_46_jpg.rf.48f9b930b56324dd2a055f249d7e247c.jpg: 640x640 2 persons, 1 banana, 45.7ms\n",
      "Speed: 0.7ms preprocess, 45.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-21_jpg.rf.ffab92c4b5d4e9d14d4de9a8fef566fe.jpg: 640x640 2 persons, 1 train, 1 bench, 36.5ms\n",
      "Speed: 0.6ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-122_jpg.rf.0cd1654e69130f2f2b2b5adb08c879f0.jpg: 640x640 1 person, 1 car, 2 trains, 37.0ms\n",
      "Speed: 0.6ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox3_mp4-49_jpg.rf.8ddb4986f36cc784dbfbd9be67369d29.jpg: 640x640 3 persons, 37.8ms\n",
      "Speed: 0.6ms preprocess, 37.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox6_mp4-20_jpg.rf.b5d35cc6e8a707c658604de70b53b465.jpg: 640x640 2 persons, 1 car, 1 traffic light, 1 bed, 38.7ms\n",
      "Speed: 0.6ms preprocess, 38.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/129_jpg.rf.3ddb7831c49cc812f103617cf0da07fa.jpg: 640x640 3 persons, 39.3ms\n",
      "Speed: 1.0ms preprocess, 39.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0073_jpg.rf.7eb910b916105f83ea3102533826401f.jpg: 640x640 2 persons, 1 motorcycle, 1 parking meter, 37.1ms\n",
      "Speed: 0.6ms preprocess, 37.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_176_jpg.rf.b8a919c25f0cc5d1caf0e4db3f2f77d0.jpg: 640x640 1 person, 1 bus, 38.1ms\n",
      "Speed: 0.7ms preprocess, 38.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-361_jpg.rf.3f7aa8802b2b37a2720fc4a5bd1fe05d.jpg: 640x640 1 person, 44.9ms\n",
      "Speed: 0.8ms preprocess, 44.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-331-_jpg.rf.52581f5e20bb001a25462041667c51e6.jpg: 640x640 1 person, 57.9ms\n",
      "Speed: 0.7ms preprocess, 57.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/download (2).jpeg: 448x640 1 person, 31.5ms\n",
      "Speed: 0.8ms preprocess, 31.5ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/download (4).jpeg: 448x640 16 persons, 27.7ms\n",
      "Speed: 0.8ms preprocess, 27.7ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-649-_jpg.rf.684e6f30445a032c9fdfa9cfe9d9a752.jpg: 640x640 1 truck, 1 surfboard, 47.1ms\n",
      "Speed: 1.2ms preprocess, 47.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-646_jpg.rf.e65c657ffa1ac398dc1dcebcb42b1e52.jpg: 640x640 1 bus, 46.0ms\n",
      "Speed: 0.6ms preprocess, 46.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_1009_jpg.rf.42a85f154507fc3c69facf93bbb1d22b.jpg: 640x640 2 persons, 1 motorcycle, 1 bench, 38.3ms\n",
      "Speed: 0.7ms preprocess, 38.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_721_jpg.rf.24fc8a861c4a80e9312d55453bcfd926.jpg: 640x640 3 persons, 1 truck, 1 suitcase, 64.3ms\n",
      "Speed: 0.6ms preprocess, 64.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-986-_jpg.rf.431a1941ab76f67268f7681f47f402d3.jpg: 640x640 2 trucks, 43.5ms\n",
      "Speed: 0.6ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_257_jpg.rf.6b5b531a478ca8052f1c7d3eb63055bf.jpg: 640x640 2 persons, 38.1ms\n",
      "Speed: 0.6ms preprocess, 38.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/img_037_jpg.rf.3172ab1c0bf89864c11461334e9c7f8c.jpg: 640x640 8 persons, 39.2ms\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-423_jpg.rf.95b39994b1b2c6e4e40cbfbbc149d6b1.jpg: 640x640 1 truck, 37.7ms\n",
      "Speed: 0.6ms preprocess, 37.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-435_jpg.rf.e1f595de41eb39a1e878759770aeaa9a.jpg: 640x640 2 persons, 1 truck, 2 books, 47.1ms\n",
      "Speed: 0.6ms preprocess, 47.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-161_jpg.rf.631bd222a82425dbe1dc30b8fe42dc39.jpg: 640x640 1 book, 40.6ms\n",
      "Speed: 0.7ms preprocess, 40.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-448_jpg.rf.a9f2d6af79f45605b867ec6fac63d53c.jpg: 640x640 1 person, 1 bicycle, 1 car, 1 boat, 1 bed, 39.5ms\n",
      "Speed: 0.6ms preprocess, 39.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-571_jpg.rf.2ba401a7dbbdb20ed5cb34d063311ffa.jpg: 640x640 5 persons, 42.2ms\n",
      "Speed: 0.7ms preprocess, 42.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_95_jpg.rf.d7f474ed656cfafee7bf4a8ce79f2fcc.jpg: 640x640 1 truck, 40.9ms\n",
      "Speed: 0.7ms preprocess, 40.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/006118_jpg.rf.f747f08bf972bd350b70c282e547a71c.jpg: 640x640 1 person, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-486_jpg.rf.fad016b7440556a65ee408cf4d938f62.jpg: 640x640 2 persons, 1 truck, 37.9ms\n",
      "Speed: 0.6ms preprocess, 37.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-23_jpg.rf.d2ec775d08f151313efa1364ccbd6d7f.jpg: 640x640 2 persons, 48.7ms\n",
      "Speed: 0.7ms preprocess, 48.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_004148_jpg.rf.20ee0ed182f1410ef10f130001b67a14.jpg: 640x640 2 persons, 44.6ms\n",
      "Speed: 0.7ms preprocess, 44.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (31).jpeg: 640x384 1 person, 25.0ms\n",
      "Speed: 0.8ms preprocess, 25.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3094_mp4-45_jpg.rf.9acc24b88ff1809064a0f6506e2fbfd6.jpg: 640x640 2 persons, 1 chair, 1 toothbrush, 41.4ms\n",
      "Speed: 0.6ms preprocess, 41.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-815_jpg.rf.db67913f887fa4d91d6720efe21bbf81.jpg: 640x640 2 bottles, 1 chair, 1 refrigerator, 38.1ms\n",
      "Speed: 0.8ms preprocess, 38.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-253-_jpg.rf.c67e3fcf3be1e96d7fec63a327b585f7.jpg: 640x640 1 person, 1 truck, 1 boat, 64.1ms\n",
      "Speed: 0.6ms preprocess, 64.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-49_jpg.rf.5a44fe43dd47987a1b67b83e743ea9ce.jpg: 640x640 1 person, 2 trucks, 1 bottle, 41.9ms\n",
      "Speed: 0.8ms preprocess, 41.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-98_jpg.rf.f30eaa2acd13890a1ec29645af90bab9.jpg: 640x640 3 persons, 41.0ms\n",
      "Speed: 0.6ms preprocess, 41.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/003184_jpg.rf.028bc555473f5424473dac253d2e6de4.jpg: 640x640 2 persons, 41.1ms\n",
      "Speed: 0.7ms preprocess, 41.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/006012_jpg.rf.58b1f82029fec52d5d718ec7baa7d2c9.jpg: 640x640 2 persons, 1 dog, 1 surfboard, 44.5ms\n",
      "Speed: 0.7ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mms_00691_jpg.rf.4a761e77f8d5c433d7a2844e18433b7f.jpg: 640x640 1 person, 1 car, 1 truck, 1 surfboard, 39.5ms\n",
      "Speed: 0.6ms preprocess, 39.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-I1-MS09uaqsLdGTFkgnS0Rcg1mmPyAj95ySg_eckoM_jpeg_jpg.rf.8691072d7687a7a3251efdf544326795.jpg: 640x640 4 persons, 1 car, 38.1ms\n",
      "Speed: 0.6ms preprocess, 38.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ins30_jpg.rf.e30d92fec606131c43538afd2c08efbd.jpg: 640x640 1 person, 1 truck, 1 bed, 37.4ms\n",
      "Speed: 0.6ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008444_jpg.rf.9c5a03ccac6c0c594459f9cd336d8114.jpg: 640x640 3 persons, 2 chairs, 1 dining table, 46.7ms\n",
      "Speed: 0.7ms preprocess, 46.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_9949-1-_mp4-6_jpg.rf.a5dcdd2976abcef414d4d4ce0c1f537f.jpg: 640x640 2 persons, 37.2ms\n",
      "Speed: 0.6ms preprocess, 37.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (23).jpeg: 384x640 6 persons, 2 cars, 32.6ms\n",
      "Speed: 0.6ms preprocess, 32.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox4_mp4-112_jpg.rf.7cc302ad3018179e980d430dacb22f9d.jpg: 640x640 2 persons, 2 trucks, 1 couch, 46.0ms\n",
      "Speed: 3.5ms preprocess, 46.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-499_jpg.rf.108e4f13fd0e76422d399dea68b7b744.jpg: 640x640 1 person, 51.3ms\n",
      "Speed: 0.7ms preprocess, 51.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_880_jpg.rf.9fc48cdadc429034a5868be1d6ca6f5a.jpg: 640x640 (no detections), 42.6ms\n",
      "Speed: 0.6ms preprocess, 42.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_074_jpg.rf.4a5533574b5d308ea1c6672f25bd030b.jpg: 640x640 1 person, 42.0ms\n",
      "Speed: 0.7ms preprocess, 42.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-207-_jpg.rf.2d637019ba12c4961982789fedfd3c12.jpg: 640x640 1 train, 1 truck, 1 frisbee, 39.3ms\n",
      "Speed: 0.7ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0029_jpg.rf.68d73a92947e699429310cfc21709e56.jpg: 640x640 2 persons, 2 trucks, 1 bird, 47.9ms\n",
      "Speed: 0.7ms preprocess, 47.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (27).jpeg: 448x640 11 persons, 26.9ms\n",
      "Speed: 1.0ms preprocess, 26.9ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-61_jpg.rf.0b22869fe6da04a763f3e1f2a216c55b.jpg: 640x640 1 chair, 38.2ms\n",
      "Speed: 0.7ms preprocess, 38.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5024_mp4-2_jpg.rf.d79771c23f9e7097b751911545c4953f.jpg: 640x640 3 persons, 1 car, 40.0ms\n",
      "Speed: 0.6ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-18_jpg.rf.d2817da497a7109e0388ea1550d9901a.jpg: 640x640 1 person, 46.3ms\n",
      "Speed: 0.6ms preprocess, 46.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008600_jpg.rf.fbcb0255367052070ef10f94875ec8e6.jpg: 640x640 2 persons, 38.0ms\n",
      "Speed: 0.6ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/129_jpg.rf.a68b454b70b3db44e61475f360275f39.jpg: 640x640 3 persons, 1 clock, 38.5ms\n",
      "Speed: 0.6ms preprocess, 38.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_191_jpg.rf.3a356d66e9df96dc47b0c2f0d20ebba7.jpg: 640x640 1 person, 2 trucks, 2 wine glasss, 37.7ms\n",
      "Speed: 0.7ms preprocess, 37.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-543-_jpg.rf.649ab011cb782b350dff83fdb605e65a.jpg: 640x640 2 persons, 78.8ms\n",
      "Speed: 0.7ms preprocess, 78.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2544-_png_jpg.rf.1224ec786928243a0076833c5ddb34f4.jpg: 640x640 7 persons, 1 truck, 55.8ms\n",
      "Speed: 0.7ms preprocess, 55.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-499_jpg.rf.422cea5362e8675e93b7769d6a605011.jpg: 640x640 1 person, 2 bottles, 1 refrigerator, 1 toothbrush, 41.9ms\n",
      "Speed: 0.7ms preprocess, 41.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-274_jpg.rf.ed75407538cec1770e72d1c0d034a380.jpg: 640x640 2 persons, 1 truck, 1 potted plant, 45.9ms\n",
      "Speed: 0.7ms preprocess, 45.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005180_jpg.rf.07f95f7d40be1642632bca5a25661ec5.jpg: 640x640 3 persons, 1 truck, 1 tie, 37.2ms\n",
      "Speed: 0.7ms preprocess, 37.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-272_jpg.rf.7dd66440ef8aa37bd17d50705dd38ccf.jpg: 640x640 1 person, 1 bus, 38.4ms\n",
      "Speed: 0.6ms preprocess, 38.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2_jpg.rf.9ea7125de2c58de7327b2b061398d7f4.jpg: 640x640 11 persons, 2 suitcases, 36.0ms\n",
      "Speed: 0.7ms preprocess, 36.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-270_jpg.rf.f37b036f2e57b71cba2781aacd44447f.jpg: 640x640 5 persons, 1 tie, 1 suitcase, 46.1ms\n",
      "Speed: 0.6ms preprocess, 46.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_158_jpg.rf.0ac72e367ada032364e70632897c268e.jpg: 640x640 4 persons, 1 chair, 36.2ms\n",
      "Speed: 0.6ms preprocess, 36.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_624_jpg.rf.6606bdfe781b8863d9823eb7bb867a28.jpg: 640x640 3 persons, 2 cars, 1 truck, 37.3ms\n",
      "Speed: 0.7ms preprocess, 37.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/405_jpg.rf.d32a5c5e31bf063c660923d082f43e83.jpg: 640x640 5 persons, 1 motorcycle, 1 bottle, 38.8ms\n",
      "Speed: 0.6ms preprocess, 38.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-1680-_png_jpg.rf.56da4925f9967baa3e9deae422aac04f.jpg: 640x640 5 persons, 1 truck, 1 tie, 53.0ms\n",
      "Speed: 0.6ms preprocess, 53.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-554_jpg.rf.12abc545630972a6e272892494a59dcc.jpg: 640x640 5 persons, 41.4ms\n",
      "Speed: 0.7ms preprocess, 41.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_151_jpg.rf.bd3a6afc6980ba1938fc0791be100536.jpg: 640x640 (no detections), 40.6ms\n",
      "Speed: 0.7ms preprocess, 40.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox5_mp4-34_jpg.rf.3c78d4783f9d8451aa12e1a2177ec740.jpg: 640x640 1 person, 39.2ms\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005180_jpg.rf.07de45ecea6050e4afec7f8a3632ea11.jpg: 640x640 2 persons, 1 motorcycle, 1 tie, 44.9ms\n",
      "Speed: 0.6ms preprocess, 44.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-423_jpg.rf.d0ec989fcfb1d783c32081989ef7c39c.jpg: 640x640 1 person, 2 bicycles, 1 car, 51.3ms\n",
      "Speed: 0.6ms preprocess, 51.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox6_mp4-157_jpg.rf.0bb6fec008de80af30afd18d1a6c676f.jpg: 640x640 3 persons, 1 train, 39.9ms\n",
      "Speed: 0.7ms preprocess, 39.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/helmet999595_jpg.rf.dee6180028ca0d9f7a4c9e3988bff5e7.jpg: 640x640 1 person, 1 truck, 1 cake, 38.3ms\n",
      "Speed: 0.7ms preprocess, 38.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_527_jpg.rf.735b4a3234ed22f8d2d14d7d7bcae26c.jpg: 640x640 1 person, 1 tv, 50.4ms\n",
      "Speed: 0.7ms preprocess, 50.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1115-_jpg.rf.a5f28dfa40323a63fb7141203e921cff.jpg: 640x640 1 truck, 37.7ms\n",
      "Speed: 0.7ms preprocess, 37.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-699_jpg.rf.08d0890d9ffd3c79f94e48db68c2ea6c.jpg: 640x640 1 person, 1 truck, 1 bottle, 39.7ms\n",
      "Speed: 0.6ms preprocess, 39.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-460_jpg.rf.faf17ea4f6f46a51cc51629c29946240.jpg: 640x640 1 person, 1 truck, 2 suitcases, 1 surfboard, 39.7ms\n",
      "Speed: 0.6ms preprocess, 39.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0491_jpg.rf.bd8c7a68df79fb79b2cdc0a6d4632a6e.jpg: 640x640 2 persons, 74.7ms\n",
      "Speed: 0.7ms preprocess, 74.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-460_jpg.rf.186e39e79bdf1e04380ba03079331a2b.jpg: 640x640 1 person, 39.1ms\n",
      "Speed: 0.7ms preprocess, 39.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-260-_jpg.rf.339601ad6502461bf6ffcd18d61629a2.jpg: 640x640 2 persons, 1 truck, 39.9ms\n",
      "Speed: 0.6ms preprocess, 39.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-182_jpg.rf.de6b154c40fe604072fbd94399a9328a.jpg: 640x640 2 persons, 1 truck, 47.2ms\n",
      "Speed: 0.6ms preprocess, 47.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_575_jpg.rf.77757c5bfd7587c1b437d75122250302.jpg: 640x640 8 persons, 2 trucks, 39.6ms\n",
      "Speed: 0.6ms preprocess, 39.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-254_jpg.rf.e4f247b7a5566b9a03d834127b9c2683.jpg: 640x640 (no detections), 36.8ms\n",
      "Speed: 0.7ms preprocess, 36.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-560_jpg.rf.95875f8d875c1a43c1b4e6f39f77780d.jpg: 640x640 1 person, 1 train, 1 truck, 37.1ms\n",
      "Speed: 0.7ms preprocess, 37.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_004148_jpg.rf.323afb7ac28a89fe20723187498dc297.jpg: 640x640 3 persons, 2 trucks, 44.3ms\n",
      "Speed: 0.6ms preprocess, 44.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-142-_jpg.rf.53227c120a3027506c31c03c65563d0b.jpg: 640x640 3 persons, 2 trucks, 1 laptop, 51.9ms\n",
      "Speed: 0.6ms preprocess, 51.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_294_jpg.rf.fdf2e9830d2c9f9648463a48508cb539.jpg: 640x640 7 persons, 38.1ms\n",
      "Speed: 0.6ms preprocess, 38.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008753_jpg.rf.186c87c81cd6acbc5dbd5a24cdc48033.jpg: 640x640 3 persons, 1 motorcycle, 38.0ms\n",
      "Speed: 0.6ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_000280_jpg.rf.ec836370fef6cf224c1c349c5814fce5.jpg: 640x640 1 person, 1 bicycle, 1 motorcycle, 1 truck, 67.9ms\n",
      "Speed: 0.7ms preprocess, 67.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_740_jpg.rf.a609426b253105a9150695c8988a5cc5.jpg: 640x640 2 persons, 40.5ms\n",
      "Speed: 0.7ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/img17_jpg.rf.ae8adc31923d27a04747ccd334b12e7f.jpg: 640x640 3 persons, 41.7ms\n",
      "Speed: 0.7ms preprocess, 41.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-9_jpg.rf.4f9f4bd5d2f73c4ae0b875be6c783250.jpg: 640x640 2 persons, 1 fire hydrant, 46.2ms\n",
      "Speed: 0.7ms preprocess, 46.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Screenshot_20210830-123141_Instagram_jpg.rf.cf87553f734ba5173fd4f575167ade7d.jpg: 640x640 4 persons, 36.6ms\n",
      "Speed: 0.7ms preprocess, 36.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/616_jpg.rf.05c63c91f6ce5efe80d1f6b70d757dc8.jpg: 640x640 2 persons, 1 bottle, 38.8ms\n",
      "Speed: 0.6ms preprocess, 38.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-197_jpg.rf.de7698fa188d148fa8c31e572450db8a.jpg: 640x640 2 persons, 1 car, 37.3ms\n",
      "Speed: 0.6ms preprocess, 37.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_23_jpg.rf.f140ebb7ae3740e5f867a899ec44e5e2.jpg: 640x640 2 persons, 1 motorcycle, 1 bus, 1 traffic light, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-572-_jpg.rf.13199ba6523ff369244d3cab111637e4.jpg: 640x640 1 person, 1 truck, 36.5ms\n",
      "Speed: 0.7ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/additional_tests-Nomask-wearing_mp4-35_jpg.rf.133f003b3b52925570bda04ec243b96d.jpg: 640x640 2 persons, 1 motorcycle, 38.0ms\n",
      "Speed: 0.7ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-235_jpg.rf.4b25a9ac4d779e264f91b96f950f61e1.jpg: 640x640 2 persons, 1 truck, 37.8ms\n",
      "Speed: 0.6ms preprocess, 37.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-434-_jpg.rf.d5ba4f33db856f8fe617d0283dbba3bb.jpg: 640x640 3 persons, 2 trucks, 75.8ms\n",
      "Speed: 0.7ms preprocess, 75.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_191_jpg.rf.a5bbd2d86e5d05079cbebf54436c0ace.jpg: 640x640 6 persons, 1 truck, 1 tie, 1 cup, 50.4ms\n",
      "Speed: 3.9ms preprocess, 50.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-14_jpg.rf.e5d60da96c5096a3c35f0c58b1abb112.jpg: 640x640 2 persons, 2 cars, 1 truck, 1 potted plant, 39.5ms\n",
      "Speed: 0.7ms preprocess, 39.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-209_jpg.rf.b5ad704cb8a44e82ab6697bb3c275fd9.jpg: 640x640 1 person, 42.4ms\n",
      "Speed: 0.7ms preprocess, 42.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/p65621379_jpg.rf.00d56f3bb60d7b74546bd950b530247c.jpg: 640x640 1 person, 1 surfboard, 2 chairs, 1 refrigerator, 45.9ms\n",
      "Speed: 0.9ms preprocess, 45.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ins27_jpg.rf.ec02ee8f42e71099e661712f90d013eb.jpg: 640x640 1 person, 1 truck, 36.7ms\n",
      "Speed: 0.7ms preprocess, 36.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/MariusConePic60_png_jpg.rf.2113312268bdc5cb2ae311e1a713af16.jpg: 640x640 2 persons, 1 kite, 39.2ms\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (26).jpeg: 448x640 1 person, 1 bench, 29.5ms\n",
      "Speed: 0.8ms preprocess, 29.5ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-661_jpg.rf.fa385cb41313359cf19b3a20a78d944f.jpg: 640x640 1 person, 3 trucks, 46.1ms\n",
      "Speed: 0.7ms preprocess, 46.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/129_jpg.rf.ffd6c2f950c552a16727f9bf145f7454.jpg: 640x640 2 persons, 1 bottle, 38.2ms\n",
      "Speed: 0.6ms preprocess, 38.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_622_jpg.rf.eb67018944ac0f71031e3e94a0500667.jpg: 640x640 2 persons, 1 umbrella, 37.7ms\n",
      "Speed: 0.6ms preprocess, 37.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (22).jpeg: 640x448 1 person, 53.2ms\n",
      "Speed: 0.8ms preprocess, 53.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5024_mp4-4_jpg.rf.02dc33f0f0ffc6b8eab4a796f01b3e79.jpg: 640x640 1 parking meter, 41.0ms\n",
      "Speed: 0.7ms preprocess, 41.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005239_jpg.rf.205d328d802b9bbcdb0b1a55cb86756f.jpg: 640x640 (no detections), 37.9ms\n",
      "Speed: 0.6ms preprocess, 37.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-14_jpg.rf.f3027b7117e0f1c6cf0d007ca62c2d30.jpg: 640x640 2 persons, 1 truck, 1 boat, 44.0ms\n",
      "Speed: 0.7ms preprocess, 44.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-276_jpg.rf.4db3522d66a80bfdd0afd4e92b7416b6.jpg: 640x640 2 persons, 45.9ms\n",
      "Speed: 0.8ms preprocess, 45.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/727_jpg.rf.b004fb5a9642d2bc9bad47c5fd69cfe8.jpg: 640x640 1 train, 47.2ms\n",
      "Speed: 0.7ms preprocess, 47.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_158_jpg.rf.8ca0f8054053f5210eedc8c62687fe98.jpg: 640x640 1 truck, 38.7ms\n",
      "Speed: 0.6ms preprocess, 38.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/istockphoto-639796472-612x612.jpg: 448x640 1 person, 26.4ms\n",
      "Speed: 0.9ms preprocess, 26.4ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-370_jpg.rf.530e18112042793011dbdb674c18d822.jpg: 640x640 2 persons, 1 truck, 7 surfboards, 37.9ms\n",
      "Speed: 0.6ms preprocess, 37.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mask-wearing-1632932085584_png_jpg.rf.fc6a1e9ce29ec295230ed2ea10adaebd.jpg: 640x640 4 persons, 1 chair, 1 laptop, 45.0ms\n",
      "Speed: 0.7ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/front_crawling_00088_jpg.rf.af7fe16deed2aa3cdd189eee2a70c605.jpg: 640x640 1 person, 35.6ms\n",
      "Speed: 0.6ms preprocess, 35.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-209_jpg.rf.7481790dcb493c4fb30559657779a131.jpg: 640x640 (no detections), 40.2ms\n",
      "Speed: 0.7ms preprocess, 40.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-849_jpg.rf.f8fbaed0c296cd84d30e1dde5a082b04.jpg: 640x640 1 person, 1 truck, 1 tie, 3 toothbrushs, 66.7ms\n",
      "Speed: 0.7ms preprocess, 66.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0363_jpg.rf.b84ed2a27c7787c847a869219c2fdaa2.jpg: 640x640 2 trucks, 40.8ms\n",
      "Speed: 11.3ms preprocess, 40.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-207-_jpg.rf.b05aecc4f46dcd4bacc33a92067c51a7.jpg: 640x640 3 trucks, 41.5ms\n",
      "Speed: 0.7ms preprocess, 41.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-547-_jpg.rf.5a75e2e90f7e6e23620b4311cb7bf65e.jpg: 640x640 1 motorcycle, 1 truck, 1 giraffe, 39.4ms\n",
      "Speed: 0.6ms preprocess, 39.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-5_jpg.rf.9154c57141bf7eb34f5fcce5b2dcef6e.jpg: 640x640 3 persons, 1 truck, 47.1ms\n",
      "Speed: 0.6ms preprocess, 47.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_9949-1-_mp4-24_jpg.rf.dce341f63f0481f31c3357bfba3f976c.jpg: 640x640 1 person, 1 truck, 1 bottle, 1 clock, 49.3ms\n",
      "Speed: 0.6ms preprocess, 49.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-560-_jpg.rf.77991e7505048da45e44fa988ce9ee0a.jpg: 640x640 1 person, 1 airplane, 2 buss, 1 train, 2 trucks, 38.5ms\n",
      "Speed: 0.6ms preprocess, 38.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/588_jpg.rf.7e978c634b992f3b3fc9332329e20c67.jpg: 640x640 (no detections), 36.3ms\n",
      "Speed: 0.7ms preprocess, 36.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-376_jpg.rf.3718c769c7b35997d6ce58fecc01d438.jpg: 640x640 5 persons, 45.3ms\n",
      "Speed: 0.7ms preprocess, 45.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-224_jpg.rf.828282763610b13afaab1adc61cda0e8.jpg: 640x640 3 persons, 64.3ms\n",
      "Speed: 0.6ms preprocess, 64.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008618_jpg.rf.83d27bf2a3b03d840da408f29f6d5864.jpg: 640x640 4 persons, 3 trains, 37.2ms\n",
      "Speed: 0.7ms preprocess, 37.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/w1240-p16x9-fa978043deff83fed485af12d16e39c61398fc30_jpg.rf.4fe7ae591a404f8654a9f5cff48dc81e.jpg: 640x640 1 person, 1 bus, 1 truck, 40.4ms\n",
      "Speed: 0.6ms preprocess, 40.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-75_jpg.rf.0844c3312299abbdca62c47534d96bca.jpg: 640x640 1 person, 1 car, 1 chair, 51.4ms\n",
      "Speed: 0.7ms preprocess, 51.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/001425_jpg.rf.970cbc9921e627d49bab629e2bc7dd6c.jpg: 640x640 4 persons, 2 trucks, 43.5ms\n",
      "Speed: 0.7ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/001425_jpg.rf.85bc2e1d337adb66e78e393c2aecff1c.jpg: 640x640 7 persons, 1 cell phone, 43.3ms\n",
      "Speed: 0.7ms preprocess, 43.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_861_jpg.rf.dfe1552c7796b53e288441abfa5e9316.jpg: 640x640 1 bench, 1 chair, 46.2ms\n",
      "Speed: 0.6ms preprocess, 46.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005773_jpg.rf.6fd082a2f449bb3d41d8c0180cb6f6df.jpg: 640x640 2 persons, 1 boat, 1 frisbee, 1 couch, 1 book, 37.9ms\n",
      "Speed: 0.7ms preprocess, 37.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-705-_jpg.rf.2c95558ac85804170ead0976dee79e93.jpg: 640x640 1 person, 37.0ms\n",
      "Speed: 0.6ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/01094_jpg.rf.a95df02db342161eb0d886290b8f28b7.jpg: 640x640 4 persons, 1 bus, 37.7ms\n",
      "Speed: 0.6ms preprocess, 37.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008753_jpg.rf.bb84d47d973f36b81330f3f44c0731f2.jpg: 640x640 2 persons, 1 truck, 51.7ms\n",
      "Speed: 0.6ms preprocess, 51.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-705-_jpg.rf.0e2bd9143ae68c7407a69b26ac17232c.jpg: 640x640 3 persons, 1 car, 1 truck, 1 boat, 1 bottle, 36.6ms\n",
      "Speed: 1.6ms preprocess, 36.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_1009_jpg.rf.70bc8d863b6a6ee361a435519a7fe2de.jpg: 640x640 5 persons, 2 trains, 1 truck, 37.8ms\n",
      "Speed: 0.7ms preprocess, 37.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/02629_jpg.rf.a7248eecf328be2e0b9794d850bf379a.jpg: 640x640 6 persons, 1 truck, 1 refrigerator, 37.1ms\n",
      "Speed: 0.6ms preprocess, 37.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1115-_jpg.rf.eedbec3ffbfd397bfcc8274956c249f0.jpg: 640x640 3 persons, 44.6ms\n",
      "Speed: 0.6ms preprocess, 44.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-708-_jpg.rf.8412869d37074b8796769c0d431af32e.jpg: 640x640 2 persons, 68.3ms\n",
      "Speed: 0.7ms preprocess, 68.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Screenshot_20210830-123141_Instagram_jpg.rf.b67fad686e2627a75caef191e13072e4.jpg: 640x640 5 persons, 1 dining table, 41.2ms\n",
      "Speed: 1.1ms preprocess, 41.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-348_jpg.rf.3623f117ae64ebd0dc1625ea14fade72.jpg: 640x640 3 persons, 39.7ms\n",
      "Speed: 0.6ms preprocess, 39.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-572-_jpg.rf.5c5fb0a8084cb050b133d0dec66f360e.jpg: 640x640 2 trucks, 48.2ms\n",
      "Speed: 0.7ms preprocess, 48.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-999-_jpg.rf.23daf4cedd16091ba4334c1fd6e8b271.jpg: 640x640 1 person, 1 car, 1 handbag, 39.6ms\n",
      "Speed: 0.7ms preprocess, 39.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-571_jpg.rf.16636d62c99271b2ae6a35563a84caac.jpg: 640x640 4 persons, 1 truck, 1 surfboard, 42.0ms\n",
      "Speed: 0.6ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Inside-merge_mov-16_jpg.rf.509243c79928e5eb4f9e9c448fd01aea.jpg: 640x640 1 person, 1 train, 39.2ms\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/01235_jpg.rf.309f857849c1804ab1f2f1f168902f50.jpg: 640x640 4 persons, 1 boat, 1 tie, 43.4ms\n",
      "Speed: 0.7ms preprocess, 43.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-646_jpg.rf.26b91c9dd7980bda27b42271533e4734.jpg: 640x640 1 person, 1 tv, 37.6ms\n",
      "Speed: 0.7ms preprocess, 37.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-178_jpg.rf.7cea31ac9f8ab023bd65a904607a3d06.jpg: 640x640 3 persons, 2 bicycles, 1 truck, 1 dining table, 1 book, 49.7ms\n",
      "Speed: 0.6ms preprocess, 49.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/235_jpg.rf.ecd6121b665ab2bbdac1899ab058d2d3.jpg: 640x640 2 persons, 1 refrigerator, 46.7ms\n",
      "Speed: 0.6ms preprocess, 46.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-641_jpg.rf.40acd498e1dbac24565dacedd4cc7dbb.jpg: 640x640 2 persons, 1 bed, 64.0ms\n",
      "Speed: 0.7ms preprocess, 64.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008364_jpg.rf.8b5c0174f04094705ab872fc100939a5.jpg: 640x640 2 persons, 1 train, 45.8ms\n",
      "Speed: 0.7ms preprocess, 45.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-636_jpg.rf.623eb323389f62bea29c28bd49793022.jpg: 640x640 3 persons, 41.3ms\n",
      "Speed: 0.7ms preprocess, 41.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-528-_jpg.rf.f7aabc7792418cbc51f767e40325dfb4.jpg: 640x640 3 trucks, 50.5ms\n",
      "Speed: 0.7ms preprocess, 50.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (39).jpeg: 384x640 1 person, 1 umbrella, 26.1ms\n",
      "Speed: 0.6ms preprocess, 26.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0214_jpg.rf.5d8c6637d7185213fa66cfa76f1750ec.jpg: 640x640 2 persons, 39.5ms\n",
      "Speed: 0.6ms preprocess, 39.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-17_jpg.rf.624a189394a4c43b80b03a34211d0c2a.jpg: 640x640 1 person, 1 truck, 1 toilet, 37.4ms\n",
      "Speed: 0.6ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0873_MOV-10_jpg.rf.1ac5cdcd2d574d5619df3c42326276cb.jpg: 640x640 1 person, 1 car, 1 motorcycle, 1 train, 1 truck, 45.2ms\n",
      "Speed: 0.7ms preprocess, 45.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-196_jpg.rf.d91d071c343fb52c4e572d74079b21a4.jpg: 640x640 1 train, 1 truck, 37.5ms\n",
      "Speed: 0.6ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_221_jpg.rf.1ad6ad58d2f06450b700f8e0c56bc859.jpg: 640x640 4 persons, 1 traffic light, 36.8ms\n",
      "Speed: 0.6ms preprocess, 36.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/fnacc_corridor_jpg.rf.005249dddbd7c5b872dbd60275319f1d.jpg: 640x640 2 cars, 1 truck, 40.1ms\n",
      "Speed: 0.6ms preprocess, 40.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-0_jpg.rf.43171cee09f9560ebeded58e2d5832e9.jpg: 640x640 2 persons, 2 trains, 65.4ms\n",
      "Speed: 0.7ms preprocess, 65.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/02629_jpg.rf.1c71d128f3dca9b80504e5e7163508bc.jpg: 640x640 4 persons, 1 truck, 1 bottle, 55.7ms\n",
      "Speed: 0.7ms preprocess, 55.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_241_jpg.rf.ae5c13350042cce95f3e4cbc5b629b6d.jpg: 640x640 3 cars, 2 trains, 40.9ms\n",
      "Speed: 0.7ms preprocess, 40.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class5_012_jpg.rf.b9584b5d299a1a27b65bea64b58c37ff.jpg: 640x640 1 person, 1 bench, 1 refrigerator, 41.4ms\n",
      "Speed: 0.7ms preprocess, 41.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/006012_jpg.rf.57e2757e014f88ed990284daa18faed6.jpg: 640x640 1 train, 1 truck, 40.4ms\n",
      "Speed: 0.7ms preprocess, 40.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-96_jpg.rf.b34b00ccea66baa05cf4aa1db72c338b.jpg: 640x640 (no detections), 34.9ms\n",
      "Speed: 0.6ms preprocess, 34.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-51_jpg.rf.f7430f8f526701eb1a93b124ae3e7c8c.jpg: 640x640 1 person, 1 cup, 1 bed, 37.8ms\n",
      "Speed: 0.6ms preprocess, 37.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-568_jpg.rf.40b08efe635c831ccfeaff4494c412e1.jpg: 640x640 1 person, 37.7ms\n",
      "Speed: 0.6ms preprocess, 37.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-568_jpg.rf.264eb80c8dbae12b3e517cc70feffa31.jpg: 640x640 1 person, 1 train, 3 bottles, 43.8ms\n",
      "Speed: 0.6ms preprocess, 43.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-860-_jpg.rf.77b38f4a23ba38bebc990ab42f9a10e9.jpg: 640x640 3 persons, 39.9ms\n",
      "Speed: 0.7ms preprocess, 39.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-391_jpg.rf.f2fc01601297041149e8653fe4093f0e.jpg: 640x640 2 persons, 62.2ms\n",
      "Speed: 0.7ms preprocess, 62.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-554_jpg.rf.c76c721a1d0b10af68a4c02ff5886ea3.jpg: 640x640 1 person, 46.9ms\n",
      "Speed: 2.0ms preprocess, 46.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-571_jpg.rf.5fc130ee5e1be7e125feda702b069de8.jpg: 640x640 6 persons, 41.0ms\n",
      "Speed: 0.7ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (2).jpeg: 352x640 2 persons, 1 truck, 24.3ms\n",
      "Speed: 0.9ms preprocess, 24.3ms inference, 0.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_678_jpg.rf.32fc8ac69b0d4313b96b3713a5cd1745.jpg: 640x640 7 persons, 1 traffic light, 42.4ms\n",
      "Speed: 0.6ms preprocess, 42.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/329_jpg.rf.3a8533cdbd7c8755432f89c212d22719.jpg: 640x640 1 person, 1 bus, 1 train, 2 trucks, 50.2ms\n",
      "Speed: 0.7ms preprocess, 50.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/006118_jpg.rf.3a398e4f8ef5bf8cd84c4fc4a6f36ac6.jpg: 640x640 3 persons, 39.3ms\n",
      "Speed: 0.8ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-815_jpg.rf.0d31438a2c4b4e1ae240b81614469ba4.jpg: 640x640 1 person, 1 suitcase, 1 bottle, 1 refrigerator, 37.7ms\n",
      "Speed: 0.7ms preprocess, 37.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_MOV-30_jpg.rf.469d54b5cfd60a22d3b797c243043c82.jpg: 640x640 1 person, 1 bus, 1 truck, 37.5ms\n",
      "Speed: 0.6ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/588_jpg.rf.54ec47216c5574b0f185e8e3d2104441.jpg: 640x640 2 persons, 1 bottle, 46.6ms\n",
      "Speed: 0.6ms preprocess, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-29_jpg.rf.3aa8761e72a2a70eaae36cc6215f9618.jpg: 640x640 (no detections), 64.6ms\n",
      "Speed: 0.7ms preprocess, 64.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-492_jpg.rf.c4f35445e16b54f933dc7f2cd5d0804c.jpg: 640x640 1 person, 1 bus, 1 truck, 39.1ms\n",
      "Speed: 0.7ms preprocess, 39.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0985_jpg.rf.ec086e050c5b5d07c89dd2a1aff563e5.jpg: 640x640 3 persons, 39.2ms\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0491_jpg.rf.b46601406f2ad4a9e1181ed6e53c4392.jpg: 640x640 3 persons, 1 dog, 51.4ms\n",
      "Speed: 0.8ms preprocess, 51.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-813-_jpg.rf.29c60838739153b1f092dbfaffc8d8a2.jpg: 640x640 3 persons, 1 truck, 1 tie, 42.0ms\n",
      "Speed: 0.6ms preprocess, 42.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_4921-2_mp4-40_jpg.rf.b4e6373d7be3e64e60435387d8b8d701.jpg: 640x640 1 person, 1 laptop, 38.3ms\n",
      "Speed: 0.7ms preprocess, 38.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-506_jpg.rf.f6eb407abb8cd008124e1178d332a64b.jpg: 640x640 6 persons, 1 baseball glove, 38.6ms\n",
      "Speed: 0.6ms preprocess, 38.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_937_jpg.rf.1b2ad33f8d4c5ec04341d2f6d1a13e70.jpg: 640x640 1 person, 1 truck, 1 boat, 50.8ms\n",
      "Speed: 0.6ms preprocess, 50.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_MOV-39_jpg.rf.914e1002113e41ada32a1a90a66aab9a.jpg: 640x640 8 persons, 1 car, 48.1ms\n",
      "Speed: 0.7ms preprocess, 48.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/405_jpg.rf.ae2d82d70c03beca862cf4d2a3f604cf.jpg: 640x640 2 persons, 1 truck, 1 sandwich, 39.9ms\n",
      "Speed: 0.6ms preprocess, 39.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_337_jpg.rf.a1e56acd1e4cb3c5ccf547785cc41677.jpg: 640x640 4 persons, 1 bus, 3 ties, 1 surfboard, 67.8ms\n",
      "Speed: 0.6ms preprocess, 67.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_158_jpg.rf.303db217aab234aba913434a71b8d55d.jpg: 640x640 2 persons, 38.0ms\n",
      "Speed: 0.6ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_986_jpg.rf.109f5a671b9dc6f2f574773b9adc4f7d.jpg: 640x640 4 persons, 37.8ms\n",
      "Speed: 0.6ms preprocess, 37.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-369-_jpg.rf.98c9543f7396a23f7b5699baaba4c0df.jpg: 640x640 1 truck, 1 toilet, 42.8ms\n",
      "Speed: 0.7ms preprocess, 42.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-409_jpg.rf.bf0ce5249d8b18dd283cf404632d1125.jpg: 640x640 3 persons, 1 bicycle, 1 car, 1 truck, 1 traffic light, 55.1ms\n",
      "Speed: 0.7ms preprocess, 55.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_9949-1-_mp4-24_jpg.rf.4e70dafee713880ae7bef777adaf7f09.jpg: 640x640 2 bottles, 40.4ms\n",
      "Speed: 0.6ms preprocess, 40.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_003000_jpg.rf.6c5dc02b545928f15ee53c3ecbbe5fb4.jpg: 640x640 3 persons, 1 cat, 39.9ms\n",
      "Speed: 0.6ms preprocess, 39.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_187_jpg.rf.255a27589e0942a9a2a13f5062d00182.jpg: 640x640 1 person, 39.8ms\n",
      "Speed: 0.6ms preprocess, 39.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-196_jpg.rf.d9d5913fb05f3dfcc17d19e54e9ecbf6.jpg: 640x640 1 tv, 48.5ms\n",
      "Speed: 0.7ms preprocess, 48.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-162_jpg.rf.fcc17856f133926e2b49c657efcd48be.jpg: 640x640 1 person, 1 motorcycle, 1 truck, 1 toilet, 38.7ms\n",
      "Speed: 0.6ms preprocess, 38.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-242_jpg.rf.02b0e198e3325d86975e9d88e0713486.jpg: 640x640 4 persons, 2 cars, 1 truck, 38.4ms\n",
      "Speed: 0.7ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0363_jpg.rf.0c8e1d8f49a8f7f8fa0fd1be8019db94.jpg: 640x640 2 persons, 49.7ms\n",
      "Speed: 0.6ms preprocess, 49.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-303_jpg.rf.7469c1585f0d7a16acde5814ca5950db.jpg: 640x640 2 persons, 41.6ms\n",
      "Speed: 0.7ms preprocess, 41.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/277_jpg.rf.004c580eed497695eabbf509a273bb9e.jpg: 640x640 1 person, 1 tie, 1 oven, 50.9ms\n",
      "Speed: 0.6ms preprocess, 50.9ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-11_jpg.rf.0fb9f7898eb8b6542d6089c1deecb273.jpg: 640x640 1 person, 2 trucks, 35.0ms\n",
      "Speed: 0.7ms preprocess, 35.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class1_253_jpg.rf.3040280fef7ae5e6c2d1b9baf627d44f.jpg: 640x640 3 persons, 1 car, 1 truck, 49.2ms\n",
      "Speed: 0.6ms preprocess, 49.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/REVZGCBIJNQPMIIXOKDCQA3GJI_jpg.rf.84eab5aab0a00caca84f2c1bf3318f25.jpg: 640x640 2 persons, 1 umbrella, 41.6ms\n",
      "Speed: 0.7ms preprocess, 41.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-464_jpg.rf.8784a32dc660e889975cf6d6065c469a.jpg: 640x640 1 person, 1 truck, 40.4ms\n",
      "Speed: 0.7ms preprocess, 40.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-46_jpg.rf.01a41b1832bcad9c82d2c68ac77d8b38.jpg: 640x640 1 person, 1 bottle, 44.5ms\n",
      "Speed: 0.7ms preprocess, 44.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-649-_jpg.rf.fdc92ef7b8a44c1d32ddb0165cc8f4cf.jpg: 640x640 1 car, 2 trucks, 44.7ms\n",
      "Speed: 0.7ms preprocess, 44.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-28_jpg.rf.f08180b63e0129412eef90ad9f1ac293.jpg: 640x640 1 person, 1 bicycle, 2 books, 37.0ms\n",
      "Speed: 0.7ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-809_jpg.rf.6fb92c2982d1c552da9c5ba10ff72d5e.jpg: 640x640 1 truck, 2 bottles, 1 refrigerator, 36.7ms\n",
      "Speed: 0.6ms preprocess, 36.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-49_jpg.rf.bd9ddefd0f16a43403ec2cc1808b2baf.jpg: 640x640 2 trucks, 1 bed, 36.9ms\n",
      "Speed: 0.6ms preprocess, 36.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-396_jpg.rf.7501d10509b2c151d5eae679f8e5e5de.jpg: 640x640 1 person, 3 cars, 48.4ms\n",
      "Speed: 0.7ms preprocess, 48.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-523-_jpg.rf.32a3982052d2961d530c1b49d3fe9a0f.jpg: 640x640 4 persons, 1 bus, 1 truck, 48.3ms\n",
      "Speed: 0.6ms preprocess, 48.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-11_jpg.rf.68475305e60c164a081b563977e04db8.jpg: 640x640 2 persons, 37.9ms\n",
      "Speed: 0.8ms preprocess, 37.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_995_jpg.rf.7e67df0cbfe5d9ddd12ebd8d7a8a481c.jpg: 640x640 1 person, 3 trucks, 1 refrigerator, 50.3ms\n",
      "Speed: 0.6ms preprocess, 50.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-122_jpg.rf.00a97bfc32df3222f4b9a59692a64cc8.jpg: 640x640 1 bus, 1 bird, 43.8ms\n",
      "Speed: 0.6ms preprocess, 43.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (24).jpeg: 352x640 3 persons, 26.3ms\n",
      "Speed: 0.6ms preprocess, 26.3ms inference, 0.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-407_jpg.rf.eae2e6f24c92ca184c3bb29e091d8216.jpg: 640x640 1 person, 1 train, 1 truck, 39.9ms\n",
      "Speed: 0.7ms preprocess, 39.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-305-_jpg.rf.0ca723c56ea7de2d5d2482750837c6e2.jpg: 640x640 2 persons, 1 bus, 40.2ms\n",
      "Speed: 0.6ms preprocess, 40.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/bowling_0014_jpg.rf.3a4e573cb2c7f888fec2b6a710c60be9.jpg: 640x640 1 person, 1 truck, 39.6ms\n",
      "Speed: 0.6ms preprocess, 39.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-57_jpg.rf.41958971dfc7999e339ba42825f6f12d.jpg: 640x640 1 person, 2 trucks, 38.9ms\n",
      "Speed: 0.6ms preprocess, 38.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_1025_jpg.rf.c07c37849002f2eeadac6e7229413f44.jpg: 640x640 3 persons, 1 bicycle, 1 truck, 40.2ms\n",
      "Speed: 2.1ms preprocess, 40.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-615_jpg.rf.c3ec7544a5b9e33128ebdf2b934b5f39.jpg: 640x640 3 persons, 1 truck, 1 bird, 1 handbag, 38.8ms\n",
      "Speed: 0.6ms preprocess, 38.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-407_jpg.rf.c0adbc07fc3666a7ccd6aecfb62e7c9b.jpg: 640x640 1 person, 1 truck, 1 tie, 81.7ms\n",
      "Speed: 0.8ms preprocess, 81.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1015-_jpg.rf.9e94d76133793a7dfe1aeb00e6ecd373.jpg: 640x640 1 person, 1 car, 1 motorcycle, 2 trucks, 37.9ms\n",
      "Speed: 0.7ms preprocess, 37.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-837_jpg.rf.1c9fe1c871e46ff877c1f2b443576319.jpg: 640x640 2 persons, 1 bus, 1 truck, 44.5ms\n",
      "Speed: 0.7ms preprocess, 44.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-166_jpg.rf.3785bac9c8d14230444b9d7b9e669987.jpg: 640x640 1 person, 2 trains, 2 trucks, 47.6ms\n",
      "Speed: 0.9ms preprocess, 47.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0985_jpg.rf.d354c1af8965080e1b86cf4a97d4d762.jpg: 640x640 4 persons, 2 trucks, 39.6ms\n",
      "Speed: 0.6ms preprocess, 39.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-23_jpg.rf.061fdff3061f58b2c5712ddb616d642c.jpg: 640x640 6 persons, 1 motorcycle, 1 truck, 41.8ms\n",
      "Speed: 0.7ms preprocess, 41.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_1006_jpg.rf.13f80aa18a4be93fe186e58af82339dd.jpg: 640x640 2 persons, 1 parking meter, 37.9ms\n",
      "Speed: 0.7ms preprocess, 37.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/maksssksksss710_png_jpg.rf.c3c3d6e4c3e35d2fb1bb19311ba73056.jpg: 640x640 1 person, 1 bus, 46.4ms\n",
      "Speed: 0.7ms preprocess, 46.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-507_jpg.rf.9dd5d0a2881420c1b72fa4749c1d8830.jpg: 640x640 1 person, 1 surfboard, 37.7ms\n",
      "Speed: 0.6ms preprocess, 37.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5024_mp4-4_jpg.rf.08799e35cf749effcd52a5df4ec02d04.jpg: 640x640 1 person, 1 bottle, 40.9ms\n",
      "Speed: 0.6ms preprocess, 40.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/amz_02354_png_jpg.rf.05804b93377b6f8d38b6e61553c4c129.jpg: 640x640 3 persons, 37.0ms\n",
      "Speed: 0.6ms preprocess, 37.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-474_jpg.rf.31405beb62e0abdee684b44bbb69b242.jpg: 640x640 1 truck, 45.9ms\n",
      "Speed: 0.7ms preprocess, 45.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-189_jpg.rf.638a50850f41c580bc4cb85684025a84.jpg: 640x640 2 persons, 1 truck, 37.5ms\n",
      "Speed: 0.6ms preprocess, 37.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class1_235_jpg.rf.eb1beffcf8dccdc39a20bf88e0440788.jpg: 640x640 6 persons, 77.4ms\n",
      "Speed: 0.7ms preprocess, 77.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_002711_jpg.rf.9014fa0e9a77a787d9a8e3d03b984081.jpg: 640x640 3 persons, 1 chair, 47.7ms\n",
      "Speed: 0.7ms preprocess, 47.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0073_jpg.rf.22bc836b34109ced850c762d4213727d.jpg: 640x640 1 person, 42.9ms\n",
      "Speed: 0.7ms preprocess, 42.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Libreria_09_20_altavista_jpg.rf.dfbc78a201642a167875690ce8b7edb3.jpg: 640x640 1 bus, 5 trucks, 11 books, 40.7ms\n",
      "Speed: 0.7ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-986-_jpg.rf.3e843a82fab27d66c13283ea6e0cb2f6.jpg: 640x640 1 person, 1 horse, 40.8ms\n",
      "Speed: 0.6ms preprocess, 40.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-855_jpg.rf.016160b803b33611610bba867ebb078c.jpg: 640x640 3 persons, 2 trucks, 38.5ms\n",
      "Speed: 0.6ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-409_jpg.rf.c726b395a9167bfb3f5379155f6a43c9.jpg: 640x640 1 person, 1 car, 1 bus, 1 truck, 1 traffic light, 37.9ms\n",
      "Speed: 0.6ms preprocess, 37.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-170_jpg.rf.9d3b38f91d03a6107fdcb9b684060252.jpg: 640x640 1 person, 2 trucks, 43.0ms\n",
      "Speed: 0.9ms preprocess, 43.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_941_jpg.rf.d95b7d6f952668967060bb1c0df36c4f.jpg: 640x640 2 persons, 40.0ms\n",
      "Speed: 0.6ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-266_jpg.rf.50e4241fd44af0788a1f3530e49b2e07.jpg: 640x640 2 persons, 46.8ms\n",
      "Speed: 0.7ms preprocess, 46.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-10_jpg.rf.f2d3fa318cf73ee2e63d1c750edda1e7.jpg: 640x640 3 persons, 37.4ms\n",
      "Speed: 0.6ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-60_jpg.rf.26d94d2901a2173354e5b1112b8466e1.jpg: 640x640 2 persons, 1 bus, 1 truck, 1 couch, 40.0ms\n",
      "Speed: 0.6ms preprocess, 40.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_716_jpg.rf.e6032ddfeb46974638f84f6cb71a24fe.jpg: 640x640 3 persons, 1 train, 1 truck, 1 cake, 44.4ms\n",
      "Speed: 0.7ms preprocess, 44.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-813-_jpg.rf.da1a383275ad8f57b7f2c6f6a35f98dd.jpg: 640x640 1 person, 2 trucks, 1 traffic light, 53.2ms\n",
      "Speed: 0.7ms preprocess, 53.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/003184_jpg.rf.e7b83a5faa2513c5d2201944e2b2bd17.jpg: 640x640 2 persons, 1 truck, 38.1ms\n",
      "Speed: 0.7ms preprocess, 38.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_1037_jpg.rf.85437bdf81bc2591c070b50693ee8f1f.jpg: 640x640 1 truck, 37.9ms\n",
      "Speed: 0.7ms preprocess, 37.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-13_jpg.rf.d3e9161b0f1e5c4afec0fe6e3ff61883.jpg: 640x640 4 persons, 1 truck, 42.4ms\n",
      "Speed: 0.6ms preprocess, 42.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_000280_jpg.rf.7c269bca3935b65ae9bf2d15593b9711.jpg: 640x640 2 persons, 1 car, 1 boat, 45.8ms\n",
      "Speed: 0.7ms preprocess, 45.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-96_jpg.rf.cb5353552d12f5f60ba0c90cda46d843.jpg: 640x640 2 persons, 1 truck, 37.1ms\n",
      "Speed: 0.6ms preprocess, 37.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_000379_jpg.rf.85d67f69b0f051e37d393b7ada4500df.jpg: 640x640 (no detections), 37.4ms\n",
      "Speed: 0.7ms preprocess, 37.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-806_jpg.rf.ff8ae63dc54a045842f720ea04194dcb.jpg: 640x640 1 person, 1 surfboard, 65.9ms\n",
      "Speed: 1.0ms preprocess, 65.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-211_jpg.rf.c91213405dec99608bbb8f739e567e8d.jpg: 640x640 (no detections), 41.6ms\n",
      "Speed: 1.3ms preprocess, 41.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_7286_JPG_jpg.rf.fc99c7fb2b162c356ff703eeaaf6af1b.jpg: 640x640 3 persons, 1 tie, 38.2ms\n",
      "Speed: 0.7ms preprocess, 38.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-574_jpg.rf.ec53f3e134d613ec561e1f7fb9e56db2.jpg: 640x640 9 persons, 1 skis, 1 surfboard, 38.1ms\n",
      "Speed: 0.7ms preprocess, 38.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0873_MOV-10_jpg.rf.ad1474589c10090ed0c7f5bd4f26bedb.jpg: 640x640 1 train, 1 dining table, 40.6ms\n",
      "Speed: 0.7ms preprocess, 40.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_991_jpg.rf.a52106bd4af0ce8bc49d9b8f6ba5c6c7.jpg: 640x640 2 books, 43.7ms\n",
      "Speed: 0.6ms preprocess, 43.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-207_jpg.rf.2b487f36db322cf9d08924a371efeeef.jpg: 640x640 2 persons, 1 bicycle, 1 truck, 49.3ms\n",
      "Speed: 0.6ms preprocess, 49.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-5_jpg.rf.3b3bc55bbbe3cad17f0dfbf621bb310e.jpg: 640x640 1 person, 41.9ms\n",
      "Speed: 0.7ms preprocess, 41.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_294_jpg.rf.53e6b4b1a469feee090f8debd1dbbaaa.jpg: 640x640 3 persons, 1 train, 3 trucks, 45.3ms\n",
      "Speed: 0.7ms preprocess, 45.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/627_jpg.rf.e58ea428f31d356d0086f7f4c0edb9de.jpg: 640x640 2 persons, 1 cup, 40.6ms\n",
      "Speed: 0.7ms preprocess, 40.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/1582_jpg.rf.a067bc50920883d43cd5cab0a1966ad4.jpg: 640x640 1 person, 1 car, 37.6ms\n",
      "Speed: 0.6ms preprocess, 37.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-166_jpg.rf.86f6e6b28c259a6dfa2a469f129c2441.jpg: 640x640 5 persons, 1 bus, 1 truck, 37.6ms\n",
      "Speed: 0.8ms preprocess, 37.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_757_jpg.rf.0b5fe9980f12489e1ca7ee83428e6b36.jpg: 640x640 2 persons, 44.2ms\n",
      "Speed: 0.7ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-23_jpg.rf.aa32c4b2d468efeee58c093fa92fd6cf.jpg: 640x640 2 persons, 1 truck, 55.0ms\n",
      "Speed: 3.5ms preprocess, 55.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-15_jpg.rf.76fab6fd46f346e7c54cbe7871091557.jpg: 640x640 2 persons, 40.3ms\n",
      "Speed: 0.6ms preprocess, 40.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/img_038_jpg.rf.aa4c4ac5cc928cadd107d7fe5ab3b8ef.jpg: 640x640 3 persons, 1 traffic light, 39.0ms\n",
      "Speed: 0.6ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-61_jpg.rf.4544dac06a788293a264c29adb5c1fbf.jpg: 640x640 3 persons, 49.1ms\n",
      "Speed: 0.6ms preprocess, 49.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_965_jpg.rf.dfadb21ac6ee92a84e7b24a3f335c64c.jpg: 640x640 3 persons, 1 truck, 38.6ms\n",
      "Speed: 0.6ms preprocess, 38.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/627_jpg.rf.efaff0a9ea6cfd24b2ed0bbf8b09edf6.jpg: 640x640 1 person, 44.5ms\n",
      "Speed: 0.6ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0550_jpg.rf.f2c346802de743043297e70687160686.jpg: 640x640 1 person, 1 truck, 1 chair, 52.2ms\n",
      "Speed: 0.6ms preprocess, 52.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-668_jpg.rf.179b654b1f4c6574010186dd4fbdd475.jpg: 640x640 5 bottles, 1 refrigerator, 41.1ms\n",
      "Speed: 0.7ms preprocess, 41.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-534_jpg.rf.623ddd4b9d44ac36ebe4d106ba859247.jpg: 640x640 1 person, 39.6ms\n",
      "Speed: 0.6ms preprocess, 39.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-55_jpg.rf.c8d6c2e9f831b945ef1ae37dbf74279c.jpg: 640x640 2 persons, 1 car, 37.5ms\n",
      "Speed: 0.7ms preprocess, 37.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-13_jpg.rf.fdc3e4fff2b5b5527949aded65a9253d.jpg: 640x640 3 persons, 1 car, 1 train, 41.2ms\n",
      "Speed: 0.6ms preprocess, 41.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_151_jpg.rf.c9d700ec806d7480fa61106081e9deac.jpg: 640x640 4 persons, 1 sports ball, 37.6ms\n",
      "Speed: 6.5ms preprocess, 37.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_1212_jpg.rf.46bf7e3788647c55a07689a6794c69ef.jpg: 640x640 3 persons, 1 motorcycle, 63.9ms\n",
      "Speed: 0.6ms preprocess, 63.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-229_jpg.rf.2aabd364d6992f30d47742fa8b611d95.jpg: 640x640 3 persons, 1 truck, 38.9ms\n",
      "Speed: 0.6ms preprocess, 38.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-188_jpg.rf.178830ca68bff7d8d67e3222bcc993e0.jpg: 640x640 3 persons, 1 truck, 49.1ms\n",
      "Speed: 0.6ms preprocess, 49.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-42_jpg.rf.ff319d323fa3973bd5b2d8784419e2b1.jpg: 640x640 4 persons, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-459_jpg.rf.f805f9dac7087523ded2d9abcc092d76.jpg: 640x640 2 persons, 1 train, 1 cake, 42.3ms\n",
      "Speed: 0.7ms preprocess, 42.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-423_jpg.rf.fdfa1b970cc3b37e43b875883bc028eb.jpg: 640x640 2 persons, 1 toothbrush, 38.9ms\n",
      "Speed: 0.7ms preprocess, 38.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ka_00884_png_jpg.rf.7e1eb708ba18a96826b2667c8da401be.jpg: 640x640 1 boat, 1 traffic light, 1 toilet, 40.9ms\n",
      "Speed: 0.6ms preprocess, 40.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-27_jpg.rf.59369fee4267c34c2a91da4e0e51acce.jpg: 640x640 1 truck, 51.3ms\n",
      "Speed: 0.7ms preprocess, 51.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-29_jpg.rf.996f85a3a30c3e69358f2013e7897e19.jpg: 640x640 2 persons, 1 bicycle, 1 truck, 43.3ms\n",
      "Speed: 0.8ms preprocess, 43.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-976-_jpg.rf.13c87c91ed02802a372c418dbbfb9e65.jpg: 640x640 1 person, 1 banana, 1 orange, 38.9ms\n",
      "Speed: 0.6ms preprocess, 38.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-187_jpg.rf.d0fb1c496573385c29fa3013f9961164.jpg: 640x640 3 persons, 1 bus, 1 train, 47.9ms\n",
      "Speed: 0.7ms preprocess, 47.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-267-_jpg.rf.5577b65d59239cdf1a583e3c0b335c9b.jpg: 640x640 3 persons, 1 car, 1 truck, 1 cell phone, 37.4ms\n",
      "Speed: 0.7ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/front_crawling_00088_jpg.rf.b451f3ce7244dfc630234b73c7e88f79.jpg: 640x640 2 persons, 42.6ms\n",
      "Speed: 6.6ms preprocess, 42.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5851_jpg.rf.61c635069db71ba9ca15d73e7f4d860c.jpg: 640x640 6 persons, 1 truck, 48.8ms\n",
      "Speed: 0.6ms preprocess, 48.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0738_jpg.rf.cc3eb93fe1d414d1d3ee07d70ba46fb5.jpg: 640x640 2 persons, 1 bed, 1 toothbrush, 41.5ms\n",
      "Speed: 0.7ms preprocess, 41.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_61_jpg.rf.08e449f739bae2e9c59d32c7c44c5571.jpg: 640x640 2 trains, 1 surfboard, 1 bed, 39.5ms\n",
      "Speed: 0.6ms preprocess, 39.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-300_jpg.rf.96830f04e5e24cd4fd66dc852d2933be.jpg: 640x640 1 person, 1 train, 1 truck, 39.9ms\n",
      "Speed: 1.1ms preprocess, 39.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-20_jpg.rf.b4016db0173136b57f350620858525b2.jpg: 640x640 4 persons, 1 car, 1 horse, 41.0ms\n",
      "Speed: 0.7ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0029_jpg.rf.4de755a33273c4a133641a62c69bea46.jpg: 640x640 3 persons, 1 baseball bat, 38.5ms\n",
      "Speed: 0.7ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-809_jpg.rf.c2ab627778ab1c33e77266fd79e6c117.jpg: 640x640 1 person, 55.0ms\n",
      "Speed: 0.6ms preprocess, 55.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-550_jpg.rf.2868d7a41481681d5455497e2d865591.jpg: 640x640 1 person, 1 truck, 38.0ms\n",
      "Speed: 0.7ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_321_jpg.rf.3172aebe86cc69469861c2956fe9e05d.jpg: 640x640 1 person, 2 books, 47.1ms\n",
      "Speed: 0.7ms preprocess, 47.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/002682_jpg.rf.32c372b1f8fe5c33729441cfa170fac6.jpg: 640x640 11 persons, 1 chair, 67.1ms\n",
      "Speed: 0.7ms preprocess, 67.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox4_mp4-111_jpg.rf.15a778bacc51e10bed531cd379353724.jpg: 640x640 2 persons, 1 motorcycle, 1 truck, 37.9ms\n",
      "Speed: 0.7ms preprocess, 37.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/235_jpg.rf.897011419739f3d81651d2c00d7ec8fa.jpg: 640x640 1 person, 52.3ms\n",
      "Speed: 0.7ms preprocess, 52.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_153_jpg.rf.fa761a0845e52a919718ca77ce2eff2a.jpg: 640x640 3 persons, 1 baseball bat, 44.0ms\n",
      "Speed: 0.7ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/maksssksksss795_png_jpg.rf.2cd6bc50151827c0161d439c2c995b00.jpg: 640x640 4 persons, 1 chair, 39.4ms\n",
      "Speed: 0.7ms preprocess, 39.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-211_jpg.rf.66ac754d184fbaeabdac89642c50d237.jpg: 640x640 2 persons, 1 truck, 38.5ms\n",
      "Speed: 0.6ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_50_jpg.rf.f32caa356378aa62bfc8a723e57d0f67.jpg: 640x640 2 persons, 2 trucks, 1 refrigerator, 47.2ms\n",
      "Speed: 0.6ms preprocess, 47.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_1009_jpg.rf.34eb16e960f75d46499ea6ab6237dabf.jpg: 640x640 1 person, 37.0ms\n",
      "Speed: 0.6ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/931_jpg.rf.f34dd82ef95234e3b6db3832ece39491.jpg: 640x640 6 persons, 40.0ms\n",
      "Speed: 0.6ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-27_jpg.rf.307c9cc40f7d992120eeee5a5c2bf9b4.jpg: 640x640 4 persons, 1 motorcycle, 48.3ms\n",
      "Speed: 0.6ms preprocess, 48.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-848_jpg.rf.420254c4553963c6c3d957e2cc961a34.jpg: 640x640 3 persons, 1 car, 3 boats, 44.4ms\n",
      "Speed: 0.7ms preprocess, 44.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_1021_jpg.rf.e0b3cf8a2d216a9599f0d3957f7effd5.jpg: 640x640 1 truck, 63.6ms\n",
      "Speed: 0.6ms preprocess, 63.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-848_jpg.rf.2ae884f82299c0a160514ba977624182.jpg: 640x640 2 persons, 1 scissors, 40.5ms\n",
      "Speed: 0.6ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-815_jpg.rf.6360a43cbf621b65d132b0b2ed706a75.jpg: 640x640 1 bottle, 45.6ms\n",
      "Speed: 0.6ms preprocess, 45.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/amz_01638_png_jpg.rf.92c962d17e176a4786e34eac1c7f6fe3.jpg: 640x640 7 persons, 2 motorcycles, 1 book, 41.7ms\n",
      "Speed: 0.7ms preprocess, 41.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Nhh_img_141_jpg.rf.539c94589100406bbd49401adc520de1.jpg: 640x640 1 car, 1 truck, 39.3ms\n",
      "Speed: 0.6ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_781_jpg.rf.1440f310fa162f472f63301fdaaf62fa.jpg: 640x640 1 person, 1 car, 1 motorcycle, 1 tie, 1 laptop, 42.1ms\n",
      "Speed: 0.7ms preprocess, 42.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-196_jpg.rf.1d5478c5f934135811d726c6916596cd.jpg: 640x640 10 persons, 1 train, 1 truck, 1 fire hydrant, 1 tie, 41.3ms\n",
      "Speed: 0.7ms preprocess, 41.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_716_jpg.rf.a50609af0eb4794c25375a9eb9869742.jpg: 640x640 1 person, 1 bird, 38.9ms\n",
      "Speed: 0.6ms preprocess, 38.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-492_jpg.rf.74685b3e61f844bad845e9bec0c6f214.jpg: 640x640 2 persons, 1 refrigerator, 39.0ms\n",
      "Speed: 0.7ms preprocess, 39.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-693_jpg.rf.c5a5784a786a21f09fa8df370f71c2e6.jpg: 640x640 1 car, 2 trucks, 41.1ms\n",
      "Speed: 0.7ms preprocess, 41.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_95_jpg.rf.5a359558ad2cb6996d1053e9bcb16960.jpg: 640x640 1 person, 1 train, 1 truck, 6 books, 53.0ms\n",
      "Speed: 0.7ms preprocess, 53.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-9_jpg.rf.2a1e55d85705b51a447540055a38ab75.jpg: 640x640 3 persons, 1 car, 2 books, 38.4ms\n",
      "Speed: 0.6ms preprocess, 38.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_302_jpg.rf.f402aef842f77140f9a9b7518e0d10a6.jpg: 640x640 2 persons, 1 car, 2 trucks, 1 traffic light, 37.1ms\n",
      "Speed: 0.7ms preprocess, 37.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-14_jpg.rf.bad949e91ac4c4967902a801e80bd803.jpg: 640x640 1 person, 1 car, 1 truck, 1 chair, 1 toilet, 69.2ms\n",
      "Speed: 0.7ms preprocess, 69.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (7).jpeg: 352x640 4 persons, 34.1ms\n",
      "Speed: 0.8ms preprocess, 34.1ms inference, 0.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-69_jpg.rf.eab734f9271694a94187a7d14d7135d2.jpg: 640x640 8 persons, 1 truck, 1 fire hydrant, 40.1ms\n",
      "Speed: 0.7ms preprocess, 40.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/165_jpg.rf.c64f254d162c3ae612e21e5f8ab4962c.jpg: 640x640 1 train, 2 trucks, 38.1ms\n",
      "Speed: 0.8ms preprocess, 38.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-457_jpg.rf.10ec1e8ec33f49a09f58e020e3e03542.jpg: 640x640 1 person, 1 car, 1 cat, 44.7ms\n",
      "Speed: 0.7ms preprocess, 44.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mms_00692_jpg.rf.48f170d00664f226cda8acb2e96ef854.jpg: 640x640 1 person, 1 truck, 1 fire hydrant, 44.5ms\n",
      "Speed: 0.7ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2297-_png_jpg.rf.feeef4f36bc6dfc96b77a1f7f686fb6c.jpg: 640x640 4 persons, 1 motorcycle, 1 train, 36.5ms\n",
      "Speed: 0.6ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-189_jpg.rf.d1e7f3d623c27f0779083ec386106007.jpg: 640x640 1 person, 2 trains, 37.1ms\n",
      "Speed: 0.6ms preprocess, 37.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-112-_jpg.rf.f19a394cc6b1ec78fb1df35e4e8005c9.jpg: 640x640 3 persons, 1 tie, 38.4ms\n",
      "Speed: 0.6ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-619-_jpg.rf.a59235e60c4da86f5647c8b8bd506ebd.jpg: 640x640 1 cow, 55.5ms\n",
      "Speed: 0.7ms preprocess, 55.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_7286_JPG_jpg.rf.1574ba0756f94359b665834f26ac4c0c.jpg: 640x640 2 persons, 63.9ms\n",
      "Speed: 0.6ms preprocess, 63.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-185_jpg.rf.e3ae03d80feff5c97b521f5acda20c42.jpg: 640x640 1 car, 1 truck, 1 traffic light, 1 teddy bear, 36.9ms\n",
      "Speed: 0.6ms preprocess, 36.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-547-_jpg.rf.017820bddb0437be352dba7b5836a545.jpg: 640x640 1 person, 1 truck, 1 oven, 47.2ms\n",
      "Speed: 0.6ms preprocess, 47.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-726_jpg.rf.9217e70297b89a7a06e94a1432196d79.jpg: 640x640 2 persons, 1 truck, 1 tie, 38.9ms\n",
      "Speed: 0.7ms preprocess, 38.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-10_jpg.rf.9adb84fcf6c62e6fa0ff3bb05ab87d26.jpg: 640x640 1 person, 1 train, 42.2ms\n",
      "Speed: 0.7ms preprocess, 42.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/329_jpg.rf.fbb0984fcb0cdd40c954287ddad65b29.jpg: 640x640 3 persons, 41.1ms\n",
      "Speed: 0.6ms preprocess, 41.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-196_jpg.rf.19c2571d6042eddfa532c523d5a34817.jpg: 640x640 1 car, 1 clock, 40.4ms\n",
      "Speed: 0.7ms preprocess, 40.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_829_jpg.rf.cc0e980e8fea6a67f92ba58c85429f98.jpg: 640x640 1 clock, 39.0ms\n",
      "Speed: 0.7ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-731_jpg.rf.3d6e40e059da03693975100ae8a204d6.jpg: 640x640 4 persons, 1 truck, 45.5ms\n",
      "Speed: 0.6ms preprocess, 45.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/maksssksksss710_png_jpg.rf.e7bbdcc722733d7a08dd5165c36f927a.jpg: 640x640 2 persons, 1 couch, 1 bed, 37.9ms\n",
      "Speed: 0.6ms preprocess, 37.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mo-justin-mask-NoMask_mov-34_jpg.rf.bdfdb1c5d02e23112cc901dcac98ce67.jpg: 640x640 4 persons, 1 truck, 1 boat, 44.8ms\n",
      "Speed: 0.7ms preprocess, 44.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_781_jpg.rf.35f24a738bc773816b5b8403305a8575.jpg: 640x640 1 person, 52.1ms\n",
      "Speed: 0.6ms preprocess, 52.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-25_jpg.rf.ddd7840e3d846cddfcc13d99f4a6999b.jpg: 640x640 4 persons, 1 car, 54.2ms\n",
      "Speed: 6.1ms preprocess, 54.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_986_jpg.rf.1d20afe31eac06733cd7ffe3df169a4d.jpg: 640x640 3 persons, 1 bus, 1 truck, 1 teddy bear, 39.1ms\n",
      "Speed: 0.7ms preprocess, 39.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-98_jpg.rf.7d678538e71bb2272fa290c4ab7760ab.jpg: 640x640 3 persons, 1 truck, 39.3ms\n",
      "Speed: 0.6ms preprocess, 39.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_321_jpg.rf.663d4872dafe186593870f58aecf967a.jpg: 640x640 1 person, 1 train, 2 trucks, 1 bed, 44.5ms\n",
      "Speed: 0.7ms preprocess, 44.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1015-_jpg.rf.e0e5d33977d463d7d88bdf4bbc43b869.jpg: 640x640 2 trucks, 41.1ms\n",
      "Speed: 0.7ms preprocess, 41.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-682_jpg.rf.2fa20caf1414b1fda785e4ade07a0bd7.jpg: 640x640 3 persons, 1 car, 1 skateboard, 1 surfboard, 41.0ms\n",
      "Speed: 0.7ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_23_jpg.rf.09b499c4e1e505b1d44817741c2dbfee.jpg: 640x640 2 persons, 38.8ms\n",
      "Speed: 0.6ms preprocess, 38.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox5_mp4-34_jpg.rf.3b424b05f74f7befdf767c9d9d8cc156.jpg: 640x640 2 persons, 45.6ms\n",
      "Speed: 0.6ms preprocess, 45.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_1006_jpg.rf.54940aeca29eda3a51abe0cc917b0da9.jpg: 640x640 3 persons, 1 train, 38.0ms\n",
      "Speed: 0.6ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_337_jpg.rf.d140a30f5e7ac00823e0cda3ae4148b7.jpg: 640x640 2 persons, 1 book, 41.6ms\n",
      "Speed: 0.6ms preprocess, 41.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-13_jpg.rf.e25ec017fd5d1db9e08c5e3a40d53214.jpg: 640x640 2 persons, 34.8ms\n",
      "Speed: 0.6ms preprocess, 34.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_120_jpg.rf.ced22b7f72738e282041434526f0d32c.jpg: 640x640 5 persons, 3 motorcycles, 2 trucks, 1 backpack, 1 bottle, 74.6ms\n",
      "Speed: 0.6ms preprocess, 74.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005239_jpg.rf.aa730ea2e24bd8c190a67478c76d14ca.jpg: 640x640 2 persons, 1 truck, 1 boat, 40.2ms\n",
      "Speed: 0.6ms preprocess, 40.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-67_jpg.rf.2ac209d6daf4ac7a4247a4ee28385fe8.jpg: 640x640 2 persons, 46.8ms\n",
      "Speed: 0.7ms preprocess, 46.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-574_jpg.rf.fd75e29135d87fc401f4379bddb5c172.jpg: 640x640 1 person, 40.9ms\n",
      "Speed: 0.7ms preprocess, 40.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-142-_jpg.rf.d11551af177b7b30b97be894c66dae1d.jpg: 640x640 6 persons, 42.2ms\n",
      "Speed: 0.7ms preprocess, 42.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-229_jpg.rf.1abc159f7f5710e59b83f731b3d71378.jpg: 640x640 2 persons, 2 trucks, 42.4ms\n",
      "Speed: 0.7ms preprocess, 42.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-741-_jpg.rf.d540272efa40183048907304589ebba0.jpg: 640x640 1 person, 1 tie, 46.2ms\n",
      "Speed: 0.7ms preprocess, 46.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_841_jpg.rf.08463a010c475c732497176882629cdc.jpg: 640x640 1 person, 1 car, 1 cow, 39.3ms\n",
      "Speed: 0.7ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-1680-_png_jpg.rf.175b8e375a256e36cbe84985db1d8768.jpg: 640x640 5 persons, 38.5ms\n",
      "Speed: 0.6ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/277_jpg.rf.d6e4f58885b944d6f7daaca27e2b8cea.jpg: 640x640 2 persons, 1 bottle, 66.9ms\n",
      "Speed: 0.6ms preprocess, 66.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-212-_jpg.rf.276f0a7fdf6fca4c0c75a1d69c095c28.jpg: 640x640 1 person, 1 train, 37.1ms\n",
      "Speed: 0.6ms preprocess, 37.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-197_jpg.rf.befb7861a598e77e4dd2353f116c7d50.jpg: 640x640 1 person, 1 truck, 44.0ms\n",
      "Speed: 0.6ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-385-_jpg.rf.9f93c4ac5c55c8d091e71d7820d964c2.jpg: 640x640 (no detections), 39.6ms\n",
      "Speed: 0.9ms preprocess, 39.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-221_jpg.rf.1f2f1da597212a707dd3529618089532.jpg: 640x640 1 truck, 54.6ms\n",
      "Speed: 0.7ms preprocess, 54.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox4_mp4-112_jpg.rf.f19a9dc748d2bcfebbedbf5877b6f76e.jpg: 640x640 1 traffic light, 1 surfboard, 42.1ms\n",
      "Speed: 0.7ms preprocess, 42.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-118-_jpg.rf.71912edae594bbed121901d051e4e04c.jpg: 640x640 (no detections), 43.4ms\n",
      "Speed: 0.7ms preprocess, 43.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-69_jpg.rf.8e6ec8dff332d388423c2656ef02e07e.jpg: 640x640 2 persons, 1 train, 1 traffic light, 1 couch, 1 laptop, 2 books, 38.8ms\n",
      "Speed: 0.7ms preprocess, 38.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/627_jpg.rf.88c9bd753317933682dfb7618c406ee1.jpg: 640x640 1 person, 2 trucks, 43.4ms\n",
      "Speed: 0.9ms preprocess, 43.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/MariusConePic60_png_jpg.rf.82315d1290db9082ae25297a9007311b.jpg: 640x640 7 persons, 1 cat, 1 skateboard, 38.7ms\n",
      "Speed: 0.7ms preprocess, 38.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-741-_jpg.rf.35c19fbb2693a7d3b4af1cee8c68711c.jpg: 640x640 1 person, 1 truck, 37.2ms\n",
      "Speed: 0.6ms preprocess, 37.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_16_jpg.rf.3571bc43ca60b330412ce3498c958839.jpg: 640x640 1 airplane, 1 truck, 38.4ms\n",
      "Speed: 0.6ms preprocess, 38.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-39_jpg.rf.c2cf15dcfe418d02b74133b56a81de66.jpg: 640x640 1 person, 49.8ms\n",
      "Speed: 0.6ms preprocess, 49.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-709_jpg.rf.c67448753df01a846b96b11b26101d80.jpg: 640x640 3 persons, 38.9ms\n",
      "Speed: 0.6ms preprocess, 38.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox3_mp4-49_jpg.rf.d7456fd447bd86e27aaa1d689c73f605.jpg: 640x640 1 train, 50.2ms\n",
      "Speed: 0.6ms preprocess, 50.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-9_jpg.rf.e58e573ca41180b78bf69f552d78f1ba.jpg: 640x640 1 person, 1 truck, 68.4ms\n",
      "Speed: 0.6ms preprocess, 68.4ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_093_jpg.rf.dd61b48eee287a645c064dba6e207f5f.jpg: 640x640 6 persons, 1 motorcycle, 39.9ms\n",
      "Speed: 0.7ms preprocess, 39.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-334_jpg.rf.51fd7c36651eed0fd6e08aa5d6763367.jpg: 640x640 3 persons, 43.6ms\n",
      "Speed: 0.6ms preprocess, 43.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-182_jpg.rf.6f936d9de1e32444b7c2a075e3e4305d.jpg: 640x640 1 person, 1 truck, 1 boat, 39.3ms\n",
      "Speed: 0.7ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-396_jpg.rf.4f572c63abb01bb67be5e300f0f0f34c.jpg: 640x640 2 persons, 1 chair, 45.3ms\n",
      "Speed: 0.6ms preprocess, 45.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-543-_jpg.rf.26fd2adfe49b41fe17f7190716a718fe.jpg: 640x640 1 person, 38.8ms\n",
      "Speed: 0.7ms preprocess, 38.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-276_jpg.rf.603b4c8af1bdb3b3858166bc2877048e.jpg: 640x640 1 person, 1 train, 2 trucks, 38.4ms\n",
      "Speed: 0.7ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_880_jpg.rf.7ae0f3f78e9faa62399d04b1257a879f.jpg: 640x640 1 person, 41.2ms\n",
      "Speed: 0.7ms preprocess, 41.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mms_00691_jpg.rf.bbc034a90a824c2b05b2081f3a4c06c5.jpg: 640x640 2 persons, 46.1ms\n",
      "Speed: 0.7ms preprocess, 46.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/01235_jpg.rf.a9a777b5a318084f48a13a5f125554f5.jpg: 640x640 2 persons, 36.5ms\n",
      "Speed: 0.6ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_95_jpg.rf.fad09fd7dd1ab70d9ffd27d37272f21c.jpg: 640x640 1 person, 1 bus, 37.1ms\n",
      "Speed: 0.7ms preprocess, 37.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_246_jpg.rf.621beeead20488bd72251d6546e059bb.jpg: 640x640 2 persons, 2 trucks, 53.0ms\n",
      "Speed: 1.6ms preprocess, 53.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-464_jpg.rf.270dc5c89f2d25b354d4cb1ba1d79a79.jpg: 640x640 1 person, 2 trucks, 1 boat, 40.3ms\n",
      "Speed: 0.7ms preprocess, 40.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-276_jpg.rf.c3164d2b38f7d28b4f840daceb1de822.jpg: 640x640 1 person, 49.3ms\n",
      "Speed: 0.7ms preprocess, 49.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-116_jpg.rf.e8009a00e3b89cbbf8af90a6338c1777.jpg: 640x640 3 persons, 1 truck, 37.8ms\n",
      "Speed: 0.6ms preprocess, 37.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_475_jpg.rf.0dec553a921d58b2dfba1183323a196e.jpg: 640x640 2 persons, 1 truck, 45.4ms\n",
      "Speed: 0.7ms preprocess, 45.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-651_jpg.rf.2e6e94353f949ae2b161172623470230.jpg: 640x640 7 persons, 37.7ms\n",
      "Speed: 0.6ms preprocess, 37.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_28_jpg.rf.5362986b509d3f803a13895c369a03e9.jpg: 640x640 1 person, 1 truck, 37.3ms\n",
      "Speed: 0.6ms preprocess, 37.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-13_jpg.rf.ce1043cc4496f9f6641cf0cd70ef6301.jpg: 640x640 6 persons, 1 vase, 63.5ms\n",
      "Speed: 0.6ms preprocess, 63.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-507-_jpg.rf.82647995d5c71c87aabe15f5ea23d088.jpg: 640x640 1 person, 1 book, 48.1ms\n",
      "Speed: 0.7ms preprocess, 48.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-51_jpg.rf.3d017fb1c926511b1e0aea478e16aa2f.jpg: 640x640 1 person, 1 car, 3 trucks, 38.9ms\n",
      "Speed: 0.6ms preprocess, 38.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-64_jpg.rf.01c975a86e82e9384e40a40f5d0bece4.jpg: 640x640 2 persons, 1 truck, 43.8ms\n",
      "Speed: 0.6ms preprocess, 43.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-3_jpg.rf.6153ea96525294c99f2a3b3c0d678fd0.jpg: 640x640 1 person, 43.5ms\n",
      "Speed: 0.7ms preprocess, 43.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_991_jpg.rf.22c230afdfec51ec63afe3599fffab94.jpg: 640x640 1 person, 1 car, 1 motorcycle, 1 bus, 1 truck, 60.5ms\n",
      "Speed: 0.7ms preprocess, 60.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_003000_jpg.rf.ff5ff339e78a910b92fdcb62c8c3ce3a.jpg: 640x640 7 persons, 1 surfboard, 1 refrigerator, 38.3ms\n",
      "Speed: 0.6ms preprocess, 38.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class5_012_jpg.rf.91a8109030706b5ab458c84d5aadcf67.jpg: 640x640 1 person, 1 truck, 37.8ms\n",
      "Speed: 0.6ms preprocess, 37.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox4_mp4-42_jpg.rf.168d938b73a3fad1e02467e01689fb8d.jpg: 640x640 1 motorcycle, 1 truck, 1 traffic light, 42.7ms\n",
      "Speed: 0.6ms preprocess, 42.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-693_jpg.rf.a48f08b9f05f3c39a406fd1eb9aab12e.jpg: 640x640 (no detections), 39.1ms\n",
      "Speed: 0.7ms preprocess, 39.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-3_jpg.rf.91fa5986eb374f2552a7aec70309a4c0.jpg: 640x640 4 persons, 38.5ms\n",
      "Speed: 0.6ms preprocess, 38.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/002682_jpg.rf.495badbe291ebb8518eec8a9d947f0c7.jpg: 640x640 5 persons, 3 trucks, 1 tie, 64.8ms\n",
      "Speed: 0.6ms preprocess, 64.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-113_jpg.rf.22f74f290e2fa8942d2cc57141573823.jpg: 640x640 3 persons, 1 bicycle, 3 trucks, 44.2ms\n",
      "Speed: 0.6ms preprocess, 44.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/hqdefault_jpg.rf.9b6deb29f2b6c1e6e3ef167a8ecb1b9f.jpg: 640x640 3 persons, 1 truck, 37.8ms\n",
      "Speed: 0.6ms preprocess, 37.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-361_jpg.rf.f57807321fed0f42a348f58306403ca1.jpg: 640x640 1 person, 1 motorcycle, 1 skateboard, 1 surfboard, 41.5ms\n",
      "Speed: 0.7ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-28_jpg.rf.d09472b2ed3b379a045a4ba8ac95dc85.jpg: 640x640 1 person, 1 bicycle, 42.8ms\n",
      "Speed: 0.7ms preprocess, 42.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-667_jpg.rf.83a1f7d903a7d652fa31dff151768768.jpg: 640x640 1 person, 5 trucks, 49.2ms\n",
      "Speed: 0.7ms preprocess, 49.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3094_mp4-45_jpg.rf.d30a1cdf3924b6c25b3241f5a5bbc312.jpg: 640x640 1 person, 3 trucks, 51.5ms\n",
      "Speed: 0.7ms preprocess, 51.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/bookstore_38_02_altavista_jpg.rf.75e95418a92b328483c1c1ef9859b0ac.jpg: 640x640 1 person, 1 sports ball, 40.4ms\n",
      "Speed: 0.6ms preprocess, 40.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-131_jpg.rf.39bc29951a25ed8fe34bdf05599d8b5e.jpg: 640x640 2 persons, 38.9ms\n",
      "Speed: 0.6ms preprocess, 38.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-480_jpg.rf.f56b518c19b3d3bb20226a0d0cb52cdf.jpg: 640x640 1 truck, 45.2ms\n",
      "Speed: 0.7ms preprocess, 45.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox6_mp4-157_jpg.rf.5083cfa42053e2766397344e36be6ca8.jpg: 640x640 2 persons, 2 trucks, 38.1ms\n",
      "Speed: 0.7ms preprocess, 38.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_288_jpg.rf.b1293d82f4892b97d0592ad08d205650.jpg: 640x640 1 toilet, 65.1ms\n",
      "Speed: 0.6ms preprocess, 65.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005310_jpg.rf.462b38e32ee1aed612c4ed119dc9a06e.jpg: 640x640 2 persons, 1 dining table, 45.8ms\n",
      "Speed: 0.6ms preprocess, 45.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-268-_jpg.rf.490efdae0552a8fd8c71a6f6a2a6f6ea.jpg: 640x640 1 truck, 38.2ms\n",
      "Speed: 0.6ms preprocess, 38.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Bookstore111_jpg.rf.49397b7bdc4e2a3fa4947b42a57be10e.jpg: 640x640 1 person, 2 airplanes, 2 clocks, 39.2ms\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_781_jpg.rf.48121c8c51335dc21d89cbac2412d31e.jpg: 640x640 1 person, 1 sink, 42.7ms\n",
      "Speed: 0.8ms preprocess, 42.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-209_jpg.rf.96d7162aeb580a1dc36c5fbbc2f2777a.jpg: 640x640 1 train, 40.1ms\n",
      "Speed: 0.7ms preprocess, 40.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-210_jpg.rf.1222f0c74009045d57808b9e1fe6f12e.jpg: 640x640 1 person, 4 trucks, 53.0ms\n",
      "Speed: 0.7ms preprocess, 53.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/n190039_jpg.rf.ac2ef3422c18ec974d83ba84b23e5b2c.jpg: 640x640 1 person, 1 umbrella, 2 potted plants, 49.5ms\n",
      "Speed: 0.7ms preprocess, 49.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_004301_jpg.rf.d7534033a977f8e93915559cdc4fd15e.jpg: 640x640 4 persons, 1 truck, 38.1ms\n",
      "Speed: 0.6ms preprocess, 38.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-230_jpg.rf.7b66ab32ce1d6db9d1ef161833e31ab6.jpg: 640x640 3 persons, 1 bird, 1 handbag, 44.8ms\n",
      "Speed: 0.6ms preprocess, 44.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_620_jpg.rf.305fa19f39497ad2b70f8a7ad556a004.jpg: 640x640 1 person, 2 cars, 1 motorcycle, 1 truck, 1 banana, 37.4ms\n",
      "Speed: 0.6ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/707_jpg.rf.7f919876d3848975af00bd13370ba92f.jpg: 640x640 1 person, 1 train, 1 truck, 38.1ms\n",
      "Speed: 0.6ms preprocess, 38.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_1037_jpg.rf.217089bf7b79d7f9ab1e5543954fd72f.jpg: 640x640 8 persons, 1 train, 1 tie, 63.5ms\n",
      "Speed: 0.6ms preprocess, 63.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_527_jpg.rf.b58d8bf71e2a9ae6c06f1dd895c8f5c3.jpg: 640x640 1 person, 1 bus, 1 train, 1 giraffe, 36.9ms\n",
      "Speed: 7.0ms preprocess, 36.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_074_jpg.rf.ae4be5b9019c6a7f0239923b379aaa78.jpg: 640x640 3 persons, 1 bus, 37.2ms\n",
      "Speed: 0.6ms preprocess, 37.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-252_jpg.rf.e9a5f72cd76d2c8a603d445843eb92f1.jpg: 640x640 (no detections), 38.1ms\n",
      "Speed: 0.6ms preprocess, 38.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008753_jpg.rf.96b05f76830c2a6d37ddd3d669725532.jpg: 640x640 1 person, 1 suitcase, 40.2ms\n",
      "Speed: 0.6ms preprocess, 40.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-1_jpg.rf.98922ba5765b76f9e6c26b714b90f5d8.jpg: 640x640 4 persons, 1 truck, 63.2ms\n",
      "Speed: 0.6ms preprocess, 63.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5024_mp4-4_jpg.rf.20e82f90e1a93960b6d3ba20323ee4d5.jpg: 640x640 2 persons, 1 tie, 40.0ms\n",
      "Speed: 0.7ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-848_jpg.rf.bef04dc9e34440277e80f82cbdce6e8a.jpg: 640x640 2 persons, 40.0ms\n",
      "Speed: 0.7ms preprocess, 40.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/bowling_0014_jpg.rf.3868e64af06f185495043f847b0d5aab.jpg: 640x640 4 persons, 44.0ms\n",
      "Speed: 0.7ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-188_jpg.rf.b432a7682ba15224171e52a9c7d30a71.jpg: 640x640 1 person, 1 car, 1 tie, 1 refrigerator, 40.1ms\n",
      "Speed: 0.6ms preprocess, 40.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-6_jpg.rf.6d3bf85c0ee0b95b3b9e84759125d470.jpg: 640x640 1 person, 1 truck, 1 cake, 37.7ms\n",
      "Speed: 0.6ms preprocess, 37.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-504_jpg.rf.898c82c61c0fcdedf81373003de9719a.jpg: 640x640 1 person, 2 trucks, 37.7ms\n",
      "Speed: 0.6ms preprocess, 37.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_326_jpg.rf.d422a75b8604f734538583306e328bac.jpg: 640x640 1 truck, 42.5ms\n",
      "Speed: 0.6ms preprocess, 42.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-615_jpg.rf.7f41bbb94234c00582504401d4a76a60.jpg: 640x640 4 persons, 38.7ms\n",
      "Speed: 0.6ms preprocess, 38.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0985_jpg.rf.1210df4da3a12e8cadf70cd70e38e7c1.jpg: 640x640 3 persons, 2 trains, 1 toothbrush, 40.5ms\n",
      "Speed: 0.6ms preprocess, 40.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-667_jpg.rf.730ceb4b36b1417c6f952e2f5b0e6406.jpg: 640x640 1 person, 37.0ms\n",
      "Speed: 0.6ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_566_jpg.rf.077fd5f720f734a4087c020d58b16269.jpg: 640x640 2 persons, 1 bus, 2 trucks, 51.2ms\n",
      "Speed: 0.6ms preprocess, 51.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-207-_jpg.rf.67da281e0dc359a3d8e0ff40b561dfac.jpg: 640x640 1 person, 1 truck, 1 cow, 79.6ms\n",
      "Speed: 0.7ms preprocess, 79.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Industrial-3-Part-Skymaster-insitu_jpg.rf.3655be228fc86e1053c10a51a5d16b34.jpg: 640x640 9 persons, 1 truck, 1 clock, 45.6ms\n",
      "Speed: 0.7ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_46_jpg.rf.89b7dbc38378711e0f67bc3111df2884.jpg: 640x640 3 persons, 1 bottle, 46.3ms\n",
      "Speed: 0.6ms preprocess, 46.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005773_jpg.rf.8d8eb7d11388f2283ec465d523c98a6a.jpg: 640x640 1 person, 1 airplane, 1 truck, 38.4ms\n",
      "Speed: 0.7ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-94_jpg.rf.306d385f632cd1fdac5d7c649a4dc5e1.jpg: 640x640 3 persons, 1 motorcycle, 1 truck, 36.7ms\n",
      "Speed: 0.6ms preprocess, 36.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_296_jpg.rf.9c5575cedbe04636384f4221d86e7b02.jpg: 640x640 3 persons, 37.5ms\n",
      "Speed: 0.6ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_326_jpg.rf.268c733f1ea6e27ba95a8fba388109d0.jpg: 640x640 1 person, 1 tv, 41.0ms\n",
      "Speed: 0.7ms preprocess, 41.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_61_jpg.rf.d5e8864ef89417603f542c210b1d5c3a.jpg: 640x640 10 persons, 1 truck, 47.4ms\n",
      "Speed: 1.0ms preprocess, 47.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_302_jpg.rf.b454d24f87fcb222af99d76a757a9222.jpg: 640x640 1 person, 1 airplane, 4 trucks, 38.0ms\n",
      "Speed: 0.7ms preprocess, 38.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-67_jpg.rf.0c47d8b4097c133fc9320c56d5838ede.jpg: 640x640 1 person, 1 truck, 1 bed, 37.1ms\n",
      "Speed: 0.7ms preprocess, 37.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-821-_jpg.rf.e115e26ca11f1107503c01c9b2d4f404.jpg: 640x640 4 persons, 1 truck, 51.4ms\n",
      "Speed: 0.6ms preprocess, 51.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2_jpg.rf.7c5f480de276d0dbd11edbcc4a81c19f.jpg: 640x640 2 trucks, 1 toilet, 67.2ms\n",
      "Speed: 0.8ms preprocess, 67.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-234_jpg.rf.7ef1837f9909e7f0472f118282c28a7e.jpg: 640x640 3 persons, 1 bicycle, 1 train, 1 chair, 43.2ms\n",
      "Speed: 0.7ms preprocess, 43.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-229_jpg.rf.5550c3f91704753036b10a4f6af95eaa.jpg: 640x640 1 truck, 1 cup, 40.0ms\n",
      "Speed: 0.7ms preprocess, 40.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/download (3).jpeg: 448x640 3 persons, 35.1ms\n",
      "Speed: 0.8ms preprocess, 35.1ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-474_jpg.rf.58f399a349808873e81a5592ceb49bbd.jpg: 640x640 3 cars, 2 trucks, 40.7ms\n",
      "Speed: 0.7ms preprocess, 40.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-5_jpg.rf.709a3dfb442616bb46e772602d8417c0.jpg: 640x640 1 person, 1 boat, 37.0ms\n",
      "Speed: 0.6ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-860-_jpg.rf.e5cafb3fde90c38990c846516ac4996c.jpg: 640x640 1 person, 39.2ms\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_302_jpg.rf.d1e49a99a973868b0bb7ac26ac154552.jpg: 640x640 2 persons, 62.8ms\n",
      "Speed: 0.7ms preprocess, 62.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_732_jpg.rf.3e61e8858fc4d7ac702c276b3d416fbf.jpg: 640x640 1 person, 1 umbrella, 48.1ms\n",
      "Speed: 0.7ms preprocess, 48.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_9949-1-_mp4-63_jpg.rf.65042c1efe0eb9bb51a1b14ab8b0033d.jpg: 640x640 2 trucks, 1 bench, 1 chair, 1 toilet, 38.0ms\n",
      "Speed: 0.6ms preprocess, 38.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/01437_jpg.rf.ee92d3e0667ed377273097b6ddec65f6.jpg: 640x640 4 persons, 1 truck, 50.5ms\n",
      "Speed: 0.6ms preprocess, 50.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_880_jpg.rf.ce35870f18d9aec9717a1ba463a216f6.jpg: 640x640 1 person, 1 truck, 1 surfboard, 43.7ms\n",
      "Speed: 0.8ms preprocess, 43.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/165_jpg.rf.b04fddf04e5b76ae6a68fa12f94390d0.jpg: 640x640 2 persons, 2 cars, 42.8ms\n",
      "Speed: 0.7ms preprocess, 42.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-1_jpg.rf.a6c869480023273b342a6e8b334829d3.jpg: 640x640 1 person, 3 trucks, 41.2ms\n",
      "Speed: 0.7ms preprocess, 41.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008629_jpg.rf.61500c26db60c3df2396ffe74f4f07cf.jpg: 640x640 4 persons, 1 motorcycle, 1 bench, 1 book, 47.9ms\n",
      "Speed: 0.7ms preprocess, 47.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-207_jpg.rf.1dfc95d60337990bec28b0f132c148ec.jpg: 640x640 2 persons, 36.8ms\n",
      "Speed: 0.7ms preprocess, 36.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-844-_jpg.rf.9374d63a45b73f848efaa07e7beebf57.jpg: 640x640 4 persons, 1 cell phone, 42.4ms\n",
      "Speed: 0.7ms preprocess, 42.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-1670-_png_jpg.rf.b42b26d784545ce1a033679674a4f3e5.jpg: 640x640 3 persons, 1 fire hydrant, 36.9ms\n",
      "Speed: 0.6ms preprocess, 36.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-235_jpg.rf.f437b5b9cfb68293d373c5b533083772.jpg: 640x640 3 persons, 39.6ms\n",
      "Speed: 0.7ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Libreria_09_20_altavista_jpg.rf.21bb72e47994b3d520ec7b4aa603e8a7.jpg: 640x640 1 truck, 4 books, 38.3ms\n",
      "Speed: 0.7ms preprocess, 38.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_784_jpg.rf.35115c58b557752630a00e05998d8ae8.jpg: 640x640 3 persons, 1 airplane, 1 truck, 1 traffic light, 40.1ms\n",
      "Speed: 0.6ms preprocess, 40.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_833_jpg.rf.3ea30907534274005c210558c69f531a.jpg: 640x640 2 persons, 1 baseball bat, 47.9ms\n",
      "Speed: 0.8ms preprocess, 47.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_31_jpg.rf.def230a91172b5472d173410bc978c40.jpg: 640x640 1 person, 43.4ms\n",
      "Speed: 0.6ms preprocess, 43.4ms inference, 8.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-260-_jpg.rf.5dccef746c330ba13c8a3df9c138a1d4.jpg: 640x640 1 umbrella, 44.1ms\n",
      "Speed: 0.9ms preprocess, 44.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_158_jpg.rf.e36164a84f58c26b39f986eb6e01bbf2.jpg: 640x640 3 persons, 1 truck, 40.4ms\n",
      "Speed: 0.6ms preprocess, 40.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-504_jpg.rf.241ea52c86257e2116da083c77deb845.jpg: 640x640 1 person, 1 truck, 1 bed, 41.4ms\n",
      "Speed: 0.8ms preprocess, 41.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_187_jpg.rf.41c31a0f0e9d59715b6d91d66a6ee5ac.jpg: 640x640 1 person, 1 car, 50.3ms\n",
      "Speed: 0.7ms preprocess, 50.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_1025_jpg.rf.f4f8eed01172df173ae33e8e0e292a80.jpg: 640x640 1 person, 39.2ms\n",
      "Speed: 0.7ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_418_jpg.rf.e566fa0d44b45d557b0b035a7d8d9e4e.jpg: 640x640 2 persons, 41.4ms\n",
      "Speed: 0.7ms preprocess, 41.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-376_jpg.rf.89fe45b8428d34108dc9e4a5f4fe6fed.jpg: 640x640 2 persons, 1 scissors, 38.9ms\n",
      "Speed: 0.6ms preprocess, 38.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-228_jpg.rf.86631d2324f9e5ecf334a439994d33de.jpg: 640x640 3 persons, 2 trucks, 1 horse, 67.6ms\n",
      "Speed: 0.6ms preprocess, 67.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_151_jpg.rf.c690c0834b8a4d77844db032744a2e96.jpg: 640x640 1 car, 37.3ms\n",
      "Speed: 0.6ms preprocess, 37.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-246_jpg.rf.a580acb881072051a837c544b7fb1e91.jpg: 640x640 1 person, 48.7ms\n",
      "Speed: 0.6ms preprocess, 48.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_151_jpg.rf.1bbd03c09d03633a0fd61f32543da73e.jpg: 640x640 2 persons, 1 car, 1 bus, 50.4ms\n",
      "Speed: 0.6ms preprocess, 50.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/n457047_jpg.rf.50fd5a986202af938990ee887b0e4d74.jpg: 640x640 1 bench, 1 umbrella, 1 chair, 37.8ms\n",
      "Speed: 0.6ms preprocess, 37.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/download.jpeg: 448x640 3 persons, 29.2ms\n",
      "Speed: 0.8ms preprocess, 29.2ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0029_jpg.rf.d5722a09add4a8032fdef2f6c6fa0861.jpg: 640x640 1 person, 43.2ms\n",
      "Speed: 0.7ms preprocess, 43.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008444_jpg.rf.88f63ad836e2885c2e4d56d8f4ebf471.jpg: 640x640 2 persons, 1 train, 50.1ms\n",
      "Speed: 0.7ms preprocess, 50.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-385-_jpg.rf.86125480d75900ef929e72158f67bc92.jpg: 640x640 (no detections), 42.9ms\n",
      "Speed: 0.7ms preprocess, 42.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/002458_jpg.rf.dca744088199d83f8e9236beda1f336b.jpg: 640x640 4 persons, 38.1ms\n",
      "Speed: 0.6ms preprocess, 38.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-710_jpg.rf.336082a2d1af65c8d9184fe1dbdf7ac1.jpg: 640x640 1 person, 1 suitcase, 1 chair, 36.7ms\n",
      "Speed: 0.6ms preprocess, 36.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_379_jpg.rf.54efebfb83a98bf4589d896c36fc717b.jpg: 640x640 1 person, 1 truck, 1 couch, 43.6ms\n",
      "Speed: 0.6ms preprocess, 43.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-0_jpg.rf.17449a231054cf8460daca7adc59c09c.jpg: 640x640 1 person, 1 truck, 1 cow, 1 suitcase, 1 surfboard, 1 chair, 1 potted plant, 1 vase, 64.9ms\n",
      "Speed: 0.6ms preprocess, 64.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_MOV-30_jpg.rf.e102dc225c297966196cf0f8f8c6e239.jpg: 640x640 2 persons, 1 chair, 50.1ms\n",
      "Speed: 0.6ms preprocess, 50.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5850_jpg.rf.2aa73bed7732daebfbde3f13fa13f740.jpg: 640x640 5 persons, 1 truck, 1 book, 43.9ms\n",
      "Speed: 0.6ms preprocess, 43.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox4_mp4-112_jpg.rf.889d826e6c48099cdbaffc4cde949c1a.jpg: 640x640 1 truck, 1 traffic light, 39.8ms\n",
      "Speed: 0.7ms preprocess, 39.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-806_jpg.rf.3936fe02845166f31a01d107b81c2243.jpg: 640x640 3 persons, 41.8ms\n",
      "Speed: 0.6ms preprocess, 41.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-137_jpg.rf.7e1f934f6be9187e7d369869703657dc.jpg: 640x640 2 persons, 1 truck, 2 traffic lights, 1 clock, 41.7ms\n",
      "Speed: 0.7ms preprocess, 41.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-113_jpg.rf.b9c7bbcaf17702d65b9cccb60a39bb47.jpg: 640x640 5 persons, 1 motorcycle, 1 cake, 49.8ms\n",
      "Speed: 0.7ms preprocess, 49.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_941_jpg.rf.9ce815eb34cff79f814a6e53ac470498.jpg: 640x640 4 persons, 1 bird, 1 cake, 36.2ms\n",
      "Speed: 0.7ms preprocess, 36.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-579_jpg.rf.63915f1d2bdbbf415e11659ea0024168.jpg: 640x640 3 persons, 39.0ms\n",
      "Speed: 0.6ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/931_jpg.rf.53f65203b4afb8ca9ecbd4b4db03ffcf.jpg: 640x640 7 persons, 39.8ms\n",
      "Speed: 0.6ms preprocess, 39.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-332_jpg.rf.b7a75e3e3e84a76bfe76ff228d95d664.jpg: 640x640 1 person, 1 car, 2 trucks, 1 stop sign, 66.9ms\n",
      "Speed: 0.6ms preprocess, 66.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-266_jpg.rf.11f1d5063b9db18dd346c2c5fe9b3524.jpg: 640x640 2 persons, 1 train, 1 clock, 36.9ms\n",
      "Speed: 0.7ms preprocess, 36.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_003000_jpg.rf.9ae660adccbf418ece332c07d30daef5.jpg: 640x640 2 persons, 1 train, 1 truck, 1 chair, 49.4ms\n",
      "Speed: 0.6ms preprocess, 49.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_566_jpg.rf.50ab19696fafd47d14ff508a70cc4911.jpg: 640x640 2 trains, 1 bench, 50.0ms\n",
      "Speed: 0.7ms preprocess, 50.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-824_jpg.rf.7c7e967cd3132bc0a9236facb9d8a9b8.jpg: 640x640 2 persons, 2 trucks, 38.5ms\n",
      "Speed: 0.7ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_721_jpg.rf.4a4136fb39dcd1f7fbfeb6265e94f12b.jpg: 640x640 2 persons, 1 train, 39.6ms\n",
      "Speed: 0.7ms preprocess, 39.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2544-_png_jpg.rf.13bfe27776b4d713faf93d42421ae13f.jpg: 640x640 12 persons, 2 ties, 37.8ms\n",
      "Speed: 0.7ms preprocess, 37.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-564_jpg.rf.0bd1880a77344188952361b26e244871.jpg: 640x640 1 truck, 1 cat, 1 chair, 50.8ms\n",
      "Speed: 0.6ms preprocess, 50.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5847_jpg.rf.c9bb83b73ce7dfdec5f3a37f18a5fc4b.jpg: 640x640 10 persons, 1 potted plant, 40.7ms\n",
      "Speed: 0.7ms preprocess, 40.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-51_jpg.rf.2b25d288a8e8ad0429f9f22277c532b8.jpg: 640x640 1 person, 1 dining table, 3 tvs, 38.5ms\n",
      "Speed: 0.6ms preprocess, 38.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-230_jpg.rf.65c2abbd527fec6bb9ae68626c456ecf.jpg: 640x640 1 person, 1 kite, 1 donut, 67.0ms\n",
      "Speed: 0.6ms preprocess, 67.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_743_jpg.rf.062cdfe451165053d002809e11c43073.jpg: 640x640 (no detections), 45.2ms\n",
      "Speed: 0.7ms preprocess, 45.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-3394-_png_jpg.rf.a0f81aeb67bec81f0a77c518490205bc.jpg: 640x640 2 persons, 39.3ms\n",
      "Speed: 0.6ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-300_jpg.rf.ed1370f0e2150986042b633380be1be5.jpg: 640x640 6 persons, 52.0ms\n",
      "Speed: 0.8ms preprocess, 52.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_241_jpg.rf.15108c94dc04d438c25f0ccc715215bf.jpg: 640x640 1 person, 2 trains, 47.5ms\n",
      "Speed: 0.7ms preprocess, 47.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-550_jpg.rf.2a83bed08e8a623e8261f9c935f70e09.jpg: 640x640 1 person, 1 truck, 1 bottle, 1 chair, 43.8ms\n",
      "Speed: 0.7ms preprocess, 43.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5848_jpg.rf.276bb36b3b72258634e631184da7852d.jpg: 640x640 4 persons, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-385-_jpg.rf.df8efee4943d3867e3ba784f9c995499.jpg: 640x640 1 person, 1 truck, 38.6ms\n",
      "Speed: 0.6ms preprocess, 38.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-234_jpg.rf.701a07861feb9ea391993ea44e385111.jpg: 640x640 4 persons, 1 truck, 48.4ms\n",
      "Speed: 0.7ms preprocess, 48.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Bookstore111_jpg.rf.61468d8cdf9e27204c825a3b14ce5410.jpg: 640x640 1 suitcase, 40.5ms\n",
      "Speed: 0.6ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-27_jpg.rf.b8542d8311255bda3b5c5e0bbca8979d.jpg: 640x640 1 person, 1 airplane, 2 surfboards, 1 chair, 63.0ms\n",
      "Speed: 0.6ms preprocess, 63.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-693_jpg.rf.71b09193e1c12911ffd92e1647e3ef14.jpg: 640x640 1 person, 1 truck, 1 clock, 38.5ms\n",
      "Speed: 0.6ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-267-_jpg.rf.36fd4d82d55aa7d307deccc95bb1b68e.jpg: 640x640 2 persons, 47.7ms\n",
      "Speed: 0.7ms preprocess, 47.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-98_jpg.rf.02e8260150fd9b4d149ebdf1b77ae87b.jpg: 640x640 4 persons, 1 car, 40.9ms\n",
      "Speed: 0.6ms preprocess, 40.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-3_jpg.rf.bbe3b996c43b5fb58eb28b099c5e4c8d.jpg: 640x640 7 persons, 1 bicycle, 50.9ms\n",
      "Speed: 0.6ms preprocess, 50.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-196_jpg.rf.a700e740fec48edb0579e1e037cf347f.jpg: 640x640 1 suitcase, 54.8ms\n",
      "Speed: 0.7ms preprocess, 54.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-10_jpg.rf.9217901c124f2f8c9d39c4a7348df43f.jpg: 640x640 2 persons, 40.3ms\n",
      "Speed: 0.7ms preprocess, 40.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_673_jpg.rf.2d060997ea449f2a81778629a44ec187.jpg: 640x640 1 person, 1 car, 2 trucks, 1 traffic light, 44.2ms\n",
      "Speed: 0.7ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-165_jpg.rf.83bd25ccef7130f42dc72db173853c96.jpg: 640x640 1 person, 1 airplane, 1 parking meter, 1 cup, 41.1ms\n",
      "Speed: 0.7ms preprocess, 41.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-185_jpg.rf.2f9a20acb20029a8d99caf5f3b76e0b3.jpg: 640x640 1 bus, 2 trucks, 38.9ms\n",
      "Speed: 0.6ms preprocess, 38.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-305-_jpg.rf.f3631b40d6158e6dd009e5f237d42422.jpg: 640x640 6 persons, 1 truck, 43.2ms\n",
      "Speed: 0.6ms preprocess, 43.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/amz_01638_png_jpg.rf.f7e798738c704d161996d8dbfba2a994.jpg: 640x640 9 persons, 1 chair, 40.9ms\n",
      "Speed: 0.6ms preprocess, 40.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_498_jpg.rf.ef40b17e50a80c7f7f3fb240a15d9d60.jpg: 640x640 1 person, 37.6ms\n",
      "Speed: 0.6ms preprocess, 37.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-344_jpg.rf.ff80ed7ecff2504eedbdfdb055c612ca.jpg: 640x640 2 persons, 1 bus, 1 train, 1 truck, 68.0ms\n",
      "Speed: 0.7ms preprocess, 68.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_18_jpg.rf.aab4fae499db35c3eeb73026ffa62380.jpg: 640x640 1 person, 1 truck, 37.1ms\n",
      "Speed: 0.6ms preprocess, 37.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/YouTube_FreeStockFootage_People-wearing-face-mask_Empty-Street_Covid19-D_DbgrvhlGs-720p_mp4-11_jpg.rf.beca7821153673629c7d133ac8e4a71e.jpg: 640x640 (no detections), 52.6ms\n",
      "Speed: 0.7ms preprocess, 52.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class1_199_jpg.rf.40b9ed9b838a4ec0c2fe23d234a34914.jpg: 640x640 5 persons, 1 handbag, 39.9ms\n",
      "Speed: 0.7ms preprocess, 39.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-44_jpg.rf.1d571bccfb30ef3f7ad8d2b53dcb64e0.jpg: 640x640 2 persons, 2 cars, 1 toothbrush, 48.8ms\n",
      "Speed: 0.7ms preprocess, 48.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_16_jpg.rf.db35e5e260e92cbfb80c0bbc18204610.jpg: 640x640 4 persons, 2 trucks, 41.9ms\n",
      "Speed: 0.7ms preprocess, 41.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-267-_jpg.rf.5c65fe4e77d4493d6788f644468d3939.jpg: 640x640 1 person, 1 bus, 2 trucks, 42.7ms\n",
      "Speed: 0.8ms preprocess, 42.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Apple-Tests-Face-ID-Feature-While-Wearing-a-Mask-Shorts_mp4-51_jpg.rf.6e4aebb6aa9899d08aa5771931f80607.jpg: 640x640 1 refrigerator, 13 books, 41.7ms\n",
      "Speed: 0.7ms preprocess, 41.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-815_jpg.rf.d0a3a41d0f4f9f78660d0a6b84937302.jpg: 640x640 1 person, 1 truck, 2 bottles, 1 bed, 36.5ms\n",
      "Speed: 3.3ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-23_jpg.rf.d8cd3b06d19d953b57e6e010c2212c81.jpg: 640x640 2 persons, 1 donut, 38.0ms\n",
      "Speed: 0.6ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-14_jpg.rf.67597db5dc2bad280121bbd22170d9d5.jpg: 640x640 3 persons, 40.7ms\n",
      "Speed: 0.7ms preprocess, 40.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-560-_jpg.rf.2ce0dca7431fa99fdc542ddb0b8f9651.jpg: 640x640 2 persons, 2 buss, 1 truck, 1 chair, 70.8ms\n",
      "Speed: 0.6ms preprocess, 70.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_257_jpg.rf.d4630ce8c7553aa88c3ec41431a01621.jpg: 640x640 5 persons, 1 truck, 37.4ms\n",
      "Speed: 0.6ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-57_jpg.rf.0cc0715dd80cc227cb0881b170dc7c50.jpg: 640x640 1 person, 49.6ms\n",
      "Speed: 0.6ms preprocess, 49.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/002682_jpg.rf.b6b693995a740eb1a889f07fb5529845.jpg: 640x640 3 persons, 1 truck, 41.3ms\n",
      "Speed: 0.7ms preprocess, 41.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/1582_jpg.rf.6b13cf235d91a186b9849393992d26d9.jpg: 640x640 (no detections), 54.0ms\n",
      "Speed: 0.7ms preprocess, 54.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mms_00691_jpg.rf.3de5fb292ef5fd607a5ec5e259a09648.jpg: 640x640 3 persons, 41.2ms\n",
      "Speed: 0.7ms preprocess, 41.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-682-_jpg.rf.f3a78ec545db4329587ad62582e5f3cb.jpg: 640x640 1 person, 2 trucks, 1 fire hydrant, 40.1ms\n",
      "Speed: 0.7ms preprocess, 40.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-360_jpg.rf.d8f4e53b70e15b71532d3e43a4dc948c.jpg: 640x640 2 persons, 43.5ms\n",
      "Speed: 0.6ms preprocess, 43.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-0_jpg.rf.3c56f6f0e15308cd3691329655b205e1.jpg: 640x640 2 persons, 1 bus, 2 trains, 1 boat, 46.5ms\n",
      "Speed: 0.8ms preprocess, 46.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_995_jpg.rf.60c0e78f49bac4cf43c00466d73bbcb7.jpg: 640x640 3 persons, 1 motorcycle, 1 truck, 38.6ms\n",
      "Speed: 0.6ms preprocess, 38.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_7286_JPG_jpg.rf.163e2f93984512595dc662c098c14455.jpg: 640x640 1 person, 1 skis, 36.8ms\n",
      "Speed: 0.6ms preprocess, 36.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mms_00692_jpg.rf.aec50254ecb9bcc5c3c2edcdb4a539b4.jpg: 640x640 2 persons, 2 trucks, 72.4ms\n",
      "Speed: 0.6ms preprocess, 72.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-89_jpg.rf.b38839d6aa5394c4b939dcb4d54953ab.jpg: 640x640 1 person, 2 trucks, 2 chairs, 1 tv, 44.2ms\n",
      "Speed: 0.8ms preprocess, 44.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_294_jpg.rf.42bccbf87a08517227f2506fd6c13592.jpg: 640x640 2 persons, 1 car, 1 train, 38.3ms\n",
      "Speed: 0.6ms preprocess, 38.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-579_jpg.rf.2e8ec58ecee119571d0d63434430c40f.jpg: 640x640 1 person, 1 fire hydrant, 1 skateboard, 37.9ms\n",
      "Speed: 0.6ms preprocess, 37.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-21_jpg.rf.b0e2a552b62ea3eb6658a5496f6c57f1.jpg: 640x640 2 persons, 1 fire hydrant, 50.8ms\n",
      "Speed: 0.7ms preprocess, 50.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_818_jpg.rf.08992adf635b5399deabf2fcf25c9f98.jpg: 640x640 3 persons, 1 bicycle, 1 bus, 39.0ms\n",
      "Speed: 0.7ms preprocess, 39.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_13_jpg.rf.c8b3eebd3caa8e8b980753e055ec6e0a.jpg: 640x640 1 person, 1 car, 1 motorcycle, 40.0ms\n",
      "Speed: 0.7ms preprocess, 40.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/01235_jpg.rf.888a393865d848ca1fce7fd8c190f3b4.jpg: 640x640 2 persons, 40.0ms\n",
      "Speed: 0.6ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005577_jpg.rf.566862c761348eb4f58647d4d420213b.jpg: 640x640 2 persons, 1 tv, 1 book, 40.5ms\n",
      "Speed: 0.7ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/598_jpg.rf.92e4f3ce086a97c13042066ab56e4725.jpg: 640x640 2 persons, 1 bottle, 38.8ms\n",
      "Speed: 0.6ms preprocess, 38.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-651_jpg.rf.7cf7174eefd2010db67d1bb1bfd6be39.jpg: 640x640 1 person, 46.7ms\n",
      "Speed: 0.9ms preprocess, 46.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-14_jpg.rf.28d2371d0c22551ce422ac53cdcfb304.jpg: 640x640 5 persons, 1 bus, 1 truck, 49.1ms\n",
      "Speed: 0.6ms preprocess, 49.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5850_jpg.rf.90ccf023db51c6905c0e271534e707b5.jpg: 640x640 4 persons, 1 bus, 1 truck, 74.1ms\n",
      "Speed: 0.7ms preprocess, 74.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-506_jpg.rf.a875a18a89c3e735c82a495101f27c82.jpg: 640x640 1 person, 37.5ms\n",
      "Speed: 0.6ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005376_jpg.rf.de5b78706607737619faa1ba9ad6cd2e.jpg: 640x640 6 persons, 1 tie, 1 snowboard, 1 couch, 39.3ms\n",
      "Speed: 0.6ms preprocess, 39.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-618_jpg.rf.d8eab6517bd8e0a0aa5e6881a8a3b0b3.jpg: 640x640 3 persons, 1 tv, 48.3ms\n",
      "Speed: 0.6ms preprocess, 48.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-10_jpg.rf.a76217e1b8a14424f279d8ae65cbbee6.jpg: 640x640 2 persons, 2 trucks, 2 chairs, 41.1ms\n",
      "Speed: 0.6ms preprocess, 41.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-136_jpg.rf.5781617c5a56e26adb37b2889ca6a0b8.jpg: 640x640 1 person, 2 trucks, 41.0ms\n",
      "Speed: 0.7ms preprocess, 41.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_288_jpg.rf.f3ce8a0cb0824f37d91f151e6bc9e4e8.jpg: 640x640 1 truck, 40.7ms\n",
      "Speed: 0.7ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-369-_jpg.rf.93c7fff1119cddf6e1aa3ca99113d7c9.jpg: 640x640 3 persons, 1 carrot, 38.6ms\n",
      "Speed: 0.7ms preprocess, 38.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5847_jpg.rf.c4a1a43cc7ddc97ffd628bbd61204511.jpg: 640x640 5 persons, 1 car, 1 truck, 1 boat, 1 bench, 1 tv, 40.9ms\n",
      "Speed: 0.6ms preprocess, 40.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-211_jpg.rf.7a50e0bbc5b5dcf920cbd67eeaa0c576.jpg: 640x640 2 trucks, 2 boats, 54.4ms\n",
      "Speed: 0.7ms preprocess, 54.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/smartmi-3pcs-filter-mask-pm25-haze-dustproof-mask-with-vent_jpg.rf.419267d856e963880de8dc3f15b3520f.jpg: 640x640 2 persons, 1 truck, 38.2ms\n",
      "Speed: 0.6ms preprocess, 38.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/002654_jpg.rf.91da067adc57784316a2dc4685f239e0.jpg: 640x640 3 persons, 1 skateboard, 70.0ms\n",
      "Speed: 0.7ms preprocess, 70.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0073_jpg.rf.44956bc5c96d8c7ef52f49f67e3c907a.jpg: 640x640 3 persons, 2 trucks, 1 surfboard, 37.6ms\n",
      "Speed: 0.7ms preprocess, 37.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/helmet999595_jpg.rf.490d4ca004264ef763e06e9256e0a2fc.jpg: 640x640 1 person, 1 car, 40.0ms\n",
      "Speed: 0.7ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-763-_jpg.rf.b7d10e3fc6006bc4d88e89194c52685c.jpg: 640x640 3 persons, 1 train, 1 truck, 48.2ms\n",
      "Speed: 0.7ms preprocess, 48.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-39_jpg.rf.c209156691b8954bf0bd2732bbcacf18.jpg: 640x640 1 person, 2 cars, 2 trucks, 1 traffic light, 39.7ms\n",
      "Speed: 0.7ms preprocess, 39.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-684-_jpg.rf.f62968bca482b0ec40fd2771d94c2633.jpg: 640x640 2 persons, 1 truck, 39.7ms\n",
      "Speed: 0.7ms preprocess, 39.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0214_jpg.rf.55aa735ddec0ec8b610b74d2cc8e840c.jpg: 640x640 2 persons, 1 bed, 43.1ms\n",
      "Speed: 0.6ms preprocess, 43.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-252_jpg.rf.03f835bfbb40ca3239a0e2693b12c3b5.jpg: 640x640 3 persons, 1 boat, 3 surfboards, 47.2ms\n",
      "Speed: 0.7ms preprocess, 47.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-20_jpg.rf.b380f084461b5d0e7e745df6ca7c5313.jpg: 640x640 (no detections), 50.7ms\n",
      "Speed: 0.8ms preprocess, 50.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-15_jpg.rf.cbab80300ef1d1918dfc98bd605c80ff.jpg: 640x640 3 persons, 1 airplane, 63.7ms\n",
      "Speed: 0.6ms preprocess, 63.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-131_jpg.rf.ff277dc6867c30778ecdb28d1da664c6.jpg: 640x640 1 person, 1 toothbrush, 46.1ms\n",
      "Speed: 0.6ms preprocess, 46.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5850_jpg.rf.b2f0b8486ed051e5d870f74d9100edbb.jpg: 640x640 12 persons, 1 horse, 37.1ms\n",
      "Speed: 0.6ms preprocess, 37.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-23_jpg.rf.2d222c86e70657ebc42c765548e6c3ca.jpg: 640x640 3 persons, 1 truck, 39.2ms\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_875_jpg.rf.3e0310b562aea94a81d054a40fcdc146.jpg: 640x640 1 person, 38.9ms\n",
      "Speed: 0.6ms preprocess, 38.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-528-_jpg.rf.8aca598ebfb9d8074d1e7f4763674d73.jpg: 640x640 7 persons, 1 truck, 51.5ms\n",
      "Speed: 0.7ms preprocess, 51.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-30_jpg.rf.c2c7b6840df377580a7cafbae3f39794.jpg: 640x640 2 persons, 44.6ms\n",
      "Speed: 0.7ms preprocess, 44.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_620_jpg.rf.b56121f1434e0734f9e56cb6ee1df648.jpg: 640x640 1 person, 1 train, 1 horse, 41.7ms\n",
      "Speed: 0.7ms preprocess, 41.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_46_jpg.rf.8b8b0c9c22bebd55286447c0f28b5cba.jpg: 640x640 1 person, 2 trucks, 40.7ms\n",
      "Speed: 0.7ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-0_jpg.rf.65c9f22c6f564367ff49bc40df833721.jpg: 640x640 2 persons, 2 benchs, 1 cup, 1 bowl, 50.9ms\n",
      "Speed: 0.7ms preprocess, 50.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-615_jpg.rf.140bccdde73e1884ede155dcc39f6e32.jpg: 640x640 2 persons, 39.6ms\n",
      "Speed: 0.7ms preprocess, 39.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_818_jpg.rf.70eb74f10fcceabf24a58bd6d208ce34.jpg: 640x640 2 persons, 1 motorcycle, 2 trains, 2 trucks, 37.8ms\n",
      "Speed: 0.7ms preprocess, 37.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2297-_png_jpg.rf.202d3429d297ae78245d5fce0f84a81b.jpg: 640x640 1 person, 1 bicycle, 65.9ms\n",
      "Speed: 0.6ms preprocess, 65.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_221_jpg.rf.48896f8df2ad2199102cfaff5fff3472.jpg: 640x640 1 person, 1 car, 1 bird, 2 horses, 1 surfboard, 37.5ms\n",
      "Speed: 2.5ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_624_jpg.rf.300c4ba33e4ebba976d92ff7e547f58e.jpg: 640x640 1 person, 4 cars, 4 trucks, 2 tvs, 1 refrigerator, 42.1ms\n",
      "Speed: 0.7ms preprocess, 42.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-246-_jpg.rf.14aa29bcdbdea08faea88cc0f97d3db7.jpg: 640x640 1 bus, 1 train, 1 truck, 39.8ms\n",
      "Speed: 0.6ms preprocess, 39.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class1_253_jpg.rf.122650046bf29ce612abeb7114621da2.jpg: 640x640 5 persons, 38.4ms\n",
      "Speed: 0.7ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_986_jpg.rf.804ca97679a176c1e595e0c180584238.jpg: 640x640 1 person, 1 truck, 47.3ms\n",
      "Speed: 0.8ms preprocess, 47.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mms_00692_jpg.rf.a67d77e378aa35ede794ddd1946cc877.jpg: 640x640 2 trucks, 42.3ms\n",
      "Speed: 0.7ms preprocess, 42.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_647_jpg.rf.7a4748a4ae0def38e3189b16e872fa45.jpg: 640x640 1 elephant, 52.1ms\n",
      "Speed: 0.7ms preprocess, 52.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-235_jpg.rf.f136e4455ee18e0a5fd25415f3eb1381.jpg: 640x640 2 persons, 1 potted plant, 45.1ms\n",
      "Speed: 0.7ms preprocess, 45.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_1004_jpg.rf.de519703cdcdd06d06edd7cfa60b8184.jpg: 640x640 1 person, 2 cars, 1 bus, 2 trains, 1 truck, 1 elephant, 1 toilet, 37.7ms\n",
      "Speed: 0.6ms preprocess, 37.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-1_jpg.rf.dd2fa809ba888fea1271c9931bca7b20.jpg: 640x640 2 persons, 2 bicycles, 39.1ms\n",
      "Speed: 0.6ms preprocess, 39.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008629_jpg.rf.e6001817254342b9aa367260e7013eab.jpg: 640x640 2 persons, 3 bicycles, 1 motorcycle, 38.1ms\n",
      "Speed: 0.6ms preprocess, 38.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-573_jpg.rf.458129309c1c8850dbb06583b40a222a.jpg: 640x640 4 persons, 68.4ms\n",
      "Speed: 0.7ms preprocess, 68.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-872-_jpg.rf.5bd5245429e828eddf7be1afcb9080de.jpg: 640x640 3 cars, 1 truck, 38.5ms\n",
      "Speed: 0.7ms preprocess, 38.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-641_jpg.rf.4724b1e29ecd316e64dc41f811a3470d.jpg: 640x640 1 person, 2 trucks, 1 surfboard, 40.5ms\n",
      "Speed: 0.7ms preprocess, 40.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-360_jpg.rf.151b68e0476e17421d107ddd2ad07127.jpg: 640x640 1 person, 1 truck, 39.2ms\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-64_jpg.rf.b2ae0a3b107077c64df0812b0f8d2531.jpg: 640x640 2 persons, 1 bus, 46.4ms\n",
      "Speed: 0.6ms preprocess, 46.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-24_jpg.rf.04f8e0e63c52a64b7c0b5bfcf48e84db.jpg: 640x640 3 persons, 1 truck, 53.2ms\n",
      "Speed: 0.9ms preprocess, 53.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-464_jpg.rf.7bb53b3a3ff538572b629a90c80ee56d.jpg: 640x640 1 person, 1 car, 1 truck, 40.2ms\n",
      "Speed: 0.7ms preprocess, 40.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Bookstore111_jpg.rf.6bfc21fc307442d1983f046eb88cf76a.jpg: 640x640 2 persons, 1 tv, 46.8ms\n",
      "Speed: 0.6ms preprocess, 46.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/download (1).jpeg: 448x640 4 persons, 28.6ms\n",
      "Speed: 0.8ms preprocess, 28.6ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0738_jpg.rf.0d196ef7d084c400cd416c81c785642f.jpg: 640x640 5 persons, 1 skateboard, 39.3ms\n",
      "Speed: 0.6ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Nhh_img_141_jpg.rf.9c0deb5a98f350e6a55e5e0a2baf5b57.jpg: 640x640 1 person, 2 trucks, 1 bird, 40.1ms\n",
      "Speed: 0.6ms preprocess, 40.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Screenshot_20210830-123141_Instagram_jpg.rf.4a3c4007565eaaf662d7a5c802e44e45.jpg: 640x640 3 persons, 1 traffic light, 70.8ms\n",
      "Speed: 0.7ms preprocess, 70.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mms_00691_jpg.rf.dcec30837206b02a1e5bdb85bd49de37.jpg: 640x640 1 person, 37.3ms\n",
      "Speed: 0.6ms preprocess, 37.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-813_jpg.rf.430a808da28c9d5e38dae40ae8db9863.jpg: 640x640 1 person, 1 truck, 2 bottles, 39.1ms\n",
      "Speed: 0.6ms preprocess, 39.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008337_jpg.rf.be5dc6de298823538b429246aa5dfa42.jpg: 640x640 3 persons, 1 bicycle, 1 horse, 40.6ms\n",
      "Speed: 0.6ms preprocess, 40.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-165_jpg.rf.e6ee3b2accd8d127ef2d8aa1964cd0d4.jpg: 640x640 (no detections), 53.0ms\n",
      "Speed: 0.7ms preprocess, 53.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_187_jpg.rf.eda6e40cb0d1467695f0698504f48b2e.jpg: 640x640 3 persons, 1 bench, 41.2ms\n",
      "Speed: 0.7ms preprocess, 41.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-344_jpg.rf.86d332d55a3bc8381c851f1386fdd010.jpg: 640x640 2 persons, 42.7ms\n",
      "Speed: 0.7ms preprocess, 42.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-619-_jpg.rf.195c36f2b32843181bf4dfb5ffad2707.jpg: 640x640 2 persons, 41.4ms\n",
      "Speed: 0.7ms preprocess, 41.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/additional_tests-Nomask-wearing_mp4-35_jpg.rf.20bdea6ebef0f4d4cdcd9a9c829eecbd.jpg: 640x640 3 persons, 1 kite, 47.0ms\n",
      "Speed: 0.6ms preprocess, 47.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008593_jpg.rf.326b2332c5ad72b7eb4ff01251abbf4e.jpg: 640x640 2 persons, 1 truck, 2 books, 37.5ms\n",
      "Speed: 0.7ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_004148_jpg.rf.c86d73788f965b515d5f8ecd00031354.jpg: 640x640 2 persons, 36.7ms\n",
      "Speed: 0.6ms preprocess, 36.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-486_jpg.rf.8c3ddcbf72ab2e3904465d37481131ae.jpg: 640x640 4 persons, 1 dining table, 38.1ms\n",
      "Speed: 0.6ms preprocess, 38.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_9949-1-_mp4-24_jpg.rf.1526244bddbcfccb6b4090c068e2aa27.jpg: 640x640 4 persons, 68.8ms\n",
      "Speed: 0.7ms preprocess, 68.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_566_jpg.rf.5949d42c2b92e40bc7d0d9130c5b1920.jpg: 640x640 1 potted plant, 37.2ms\n",
      "Speed: 0.6ms preprocess, 37.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-3_jpg.rf.32329e906db245dfec761d70409f4b17.jpg: 640x640 2 persons, 1 car, 2 trucks, 1 bed, 51.4ms\n",
      "Speed: 0.6ms preprocess, 51.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-137_jpg.rf.18429a947527af2fda1fba3874086ed4.jpg: 640x640 1 person, 1 clock, 45.3ms\n",
      "Speed: 0.7ms preprocess, 45.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-235_jpg.rf.f1487e49616b02eb93e372f07fbd52a1.jpg: 640x640 8 persons, 1 truck, 1 surfboard, 40.1ms\n",
      "Speed: 0.7ms preprocess, 40.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-345_jpg.rf.70a980cb709ab5ea2317ccc1cc1195e5.jpg: 640x640 3 persons, 43.9ms\n",
      "Speed: 0.7ms preprocess, 43.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images.jpeg: 384x640 1 horse, 24.9ms\n",
      "Speed: 0.6ms preprocess, 24.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-806_jpg.rf.a1aba01a08a482a3fbee13720838ff96.jpg: 640x640 2 persons, 41.3ms\n",
      "Speed: 0.7ms preprocess, 41.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/bookstore_38_02_altavista_jpg.rf.76d6e2768892d1648dfd64dddb51316f.jpg: 640x640 3 persons, 47.2ms\n",
      "Speed: 0.6ms preprocess, 47.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-523-_jpg.rf.269c0f01c12f196d4de7511811a10dc7.jpg: 640x640 1 person, 1 motorcycle, 1 clock, 40.6ms\n",
      "Speed: 0.7ms preprocess, 40.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-497_jpg.rf.de718ed675c4ac0cb19ccccac738aeb2.jpg: 640x640 1 truck, 63.9ms\n",
      "Speed: 0.6ms preprocess, 63.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-42_jpg.rf.19ea5285f45d536c6440ee4fdf8efe66.jpg: 640x640 2 persons, 1 motorcycle, 1 clock, 46.6ms\n",
      "Speed: 0.6ms preprocess, 46.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-23_jpg.rf.e863f14921c3e6bd77c777c790b5af72.jpg: 640x640 2 persons, 1 car, 1 bus, 49.3ms\n",
      "Speed: 0.7ms preprocess, 49.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/000415_jpg.rf.c62308395a66d63dfabcd495662a22e6.jpg: 640x640 1 person, 1 truck, 1 book, 40.5ms\n",
      "Speed: 0.7ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008444_jpg.rf.260d91b51ebae045fe3a5ed752628307.jpg: 640x640 3 persons, 1 car, 39.1ms\n",
      "Speed: 0.7ms preprocess, 39.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5847_jpg.rf.b3c1a0e8834bfc57efcb59090121c44e.jpg: 640x640 7 persons, 1 train, 1 truck, 44.1ms\n",
      "Speed: 0.7ms preprocess, 44.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5024_mp4-4_jpg.rf.061f812fe9c60acea6bea51416026e13.jpg: 640x640 1 person, 49.8ms\n",
      "Speed: 0.8ms preprocess, 49.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/727_jpg.rf.58c264f473552ed0c30df918d68122da.jpg: 640x640 1 person, 1 truck, 40.8ms\n",
      "Speed: 0.7ms preprocess, 40.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_622_jpg.rf.7f40278be1943ab3e52ff7a990435ef0.jpg: 640x640 1 person, 1 train, 1 truck, 1 cup, 39.0ms\n",
      "Speed: 0.7ms preprocess, 39.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_46_jpg.rf.424d191f6c0ad06155c8fb53f662d005.jpg: 640x640 2 persons, 1 bus, 1 parking meter, 38.6ms\n",
      "Speed: 0.6ms preprocess, 38.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-589_jpg.rf.07d0bad22d2eb2e35280ae94ba8d359f.jpg: 640x640 8 persons, 3 surfboards, 66.1ms\n",
      "Speed: 0.6ms preprocess, 66.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/165_jpg.rf.6f14e3bb36293644e2dc07082e4e19ee.jpg: 640x640 2 persons, 1 horse, 1 bottle, 1 chair, 1 potted plant, 1 book, 38.0ms\n",
      "Speed: 0.6ms preprocess, 38.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_246_jpg.rf.95dc4339438bd272b9a2d2221e77945d.jpg: 640x640 1 person, 50.7ms\n",
      "Speed: 0.6ms preprocess, 50.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/istockphoto-1224034104-612x612.jpg: 384x640 3 persons, 24.9ms\n",
      "Speed: 0.8ms preprocess, 24.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-705-_jpg.rf.d76333a45a7d164a5ecbc40f95379d95.jpg: 640x640 2 persons, 1 truck, 1 boat, 49.5ms\n",
      "Speed: 0.7ms preprocess, 49.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-10_jpg.rf.3473cf1a8ce431126a38d48853c10368.jpg: 640x640 2 persons, 1 motorcycle, 1 traffic light, 2 chairs, 38.6ms\n",
      "Speed: 0.7ms preprocess, 38.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-260-_jpg.rf.bed6cb4622027ec2bf56e6e5f0e8b2cc.jpg: 640x640 1 person, 1 car, 3 trucks, 51.2ms\n",
      "Speed: 0.6ms preprocess, 51.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-502_jpg.rf.a17be40a7edd6cd947c24e8902b3abea.jpg: 640x640 3 persons, 1 truck, 1 backpack, 1 tie, 1 chair, 2 potted plants, 44.6ms\n",
      "Speed: 0.8ms preprocess, 44.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-274_jpg.rf.210bbecc47b79db3612a94b1930eaf9b.jpg: 640x640 2 persons, 1 truck, 40.1ms\n",
      "Speed: 0.7ms preprocess, 40.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ezgif-frame-049_jpg.rf.a3772345243245ad76fa5ab1ebcd7cc1.jpg: 640x640 2 bottles, 1 toilet, 39.2ms\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_55_jpg.rf.c2bafab72e0cdd8f765964b73df61128.jpg: 640x640 1 person, 5 cars, 1 truck, 1 boat, 48.3ms\n",
      "Speed: 0.7ms preprocess, 48.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_28_jpg.rf.31a8acf89c15d278a5293e4af7df77a4.jpg: 640x640 (no detections), 41.3ms\n",
      "Speed: 0.7ms preprocess, 41.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-20_jpg.rf.b48c445c1a77f7a3c915978dff3d24a6.jpg: 640x640 3 persons, 50.3ms\n",
      "Speed: 0.7ms preprocess, 50.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/w1240-p16x9-fa978043deff83fed485af12d16e39c61398fc30_jpg.rf.8de47b1c3023956723e65745b86b63f2.jpg: 640x640 1 person, 2 trucks, 39.0ms\n",
      "Speed: 0.6ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-507_jpg.rf.60bda088152f43f075e6a2826e93aaf1.jpg: 640x640 3 persons, 1 suitcase, 2 tvs, 38.5ms\n",
      "Speed: 4.0ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class1_075_jpg.rf.a03d62c65431fdb47562593e28991d07.jpg: 640x640 2 persons, 1 truck, 1 couch, 37.2ms\n",
      "Speed: 0.6ms preprocess, 37.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-699_jpg.rf.816d0269b7cb1a8621904f2e0b48624f.jpg: 640x640 1 person, 9 bottles, 1 toothbrush, 37.9ms\n",
      "Speed: 0.6ms preprocess, 37.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-693_jpg.rf.1fe523c5b5c19d9b16bfb8b8a20fb29f.jpg: 640x640 1 person, 47.2ms\n",
      "Speed: 0.7ms preprocess, 47.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005100_jpg.rf.2994d16a99c03162e7b756fa13fdd3c5.jpg: 640x640 1 person, 1 bus, 2 trains, 2 trucks, 41.9ms\n",
      "Speed: 0.7ms preprocess, 41.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/amz_02354_png_jpg.rf.a3aba4dcbc962e937a2b590392aec320.jpg: 640x640 1 person, 42.0ms\n",
      "Speed: 0.7ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/move_in_corridor_jpg.rf.732ef1db38c1ab08afb0d8f457545a5f.jpg: 640x640 1 boat, 38.7ms\n",
      "Speed: 0.6ms preprocess, 38.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/istockphoto-1332558192-612x612.jpg: 416x640 4 persons, 1 tie, 35.8ms\n",
      "Speed: 0.9ms preprocess, 35.8ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-260-_jpg.rf.b8584809048dd6843855f0f8c5b0a7a9.jpg: 640x640 1 person, 1 train, 75.2ms\n",
      "Speed: 0.6ms preprocess, 75.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-369-_jpg.rf.27b76b8bb58e9f12d60cb654abdbf508.jpg: 640x640 1 person, 1 bus, 2 trucks, 38.0ms\n",
      "Speed: 0.6ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5850_jpg.rf.f23e8a7be47b7adb26b92f5646fd996b.jpg: 640x640 10 persons, 1 car, 38.6ms\n",
      "Speed: 0.6ms preprocess, 38.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-196_jpg.rf.d8967f9f13b4c3d6fe15fbe1441184c8.jpg: 640x640 1 person, 37.8ms\n",
      "Speed: 0.7ms preprocess, 37.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/277_jpg.rf.093e99de12a75b9c38c17759345870aa.jpg: 640x640 1 person, 2 trucks, 1 vase, 39.6ms\n",
      "Speed: 0.6ms preprocess, 39.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/01437_jpg.rf.dd545905fd49027442d36f029745a7c3.jpg: 640x640 4 persons, 1 bottle, 37.9ms\n",
      "Speed: 0.6ms preprocess, 37.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_731_jpg.rf.17cfa9b22b1a08842a7bcd0219aff4b4.jpg: 640x640 (no detections), 40.5ms\n",
      "Speed: 0.6ms preprocess, 40.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1062-_jpg.rf.d99c91577106c58bacf933b6fdd2cafc.jpg: 640x640 1 person, 82.1ms\n",
      "Speed: 0.7ms preprocess, 82.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_622_jpg.rf.1e2e707a0352f7c80cc9236ae9161112.jpg: 640x640 2 persons, 39.7ms\n",
      "Speed: 0.6ms preprocess, 39.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_861_jpg.rf.44045e1408d7d09c8e41903158c121ff.jpg: 640x640 5 persons, 1 truck, 1 skateboard, 40.5ms\n",
      "Speed: 0.7ms preprocess, 40.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/002654_jpg.rf.893fab88ba85b2b20f6a1654447abb2a.jpg: 640x640 3 persons, 56.6ms\n",
      "Speed: 0.9ms preprocess, 56.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_560_jpg.rf.875cbd2977b258fd7efee784880bf40f.jpg: 640x640 3 persons, 1 bus, 1 truck, 37.2ms\n",
      "Speed: 0.6ms preprocess, 37.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-6_jpg.rf.7cccca092c407beef90e1a53f83ab88d.jpg: 640x640 2 persons, 38.5ms\n",
      "Speed: 0.6ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-362_jpg.rf.cac568e5332482b8b1d7c58abb5c5096.jpg: 640x640 4 persons, 1 scissors, 39.8ms\n",
      "Speed: 0.6ms preprocess, 39.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/move_in_corridor_jpg.rf.5b9d356b81a8ebcf90bf076911aab3fe.jpg: 640x640 1 person, 1 motorcycle, 38.5ms\n",
      "Speed: 0.6ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_796_jpg.rf.853d0ea8303cedda3b36c59f65f03cbe.jpg: 640x640 1 person, 2 trucks, 1 microwave, 38.4ms\n",
      "Speed: 0.6ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_841_jpg.rf.92fcccf16dc0fefd594e006222dc306f.jpg: 640x640 (no detections), 40.4ms\n",
      "Speed: 0.9ms preprocess, 40.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (6).jpeg: 448x640 2 persons, 2 books, 26.3ms\n",
      "Speed: 0.8ms preprocess, 26.3ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-60_jpg.rf.645d185e1b6e0050a5c70dbd2136824c.jpg: 640x640 3 persons, 45.7ms\n",
      "Speed: 0.6ms preprocess, 45.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-1_jpg.rf.5489c13165e43f0f28ee0b835777c06f.jpg: 640x640 4 persons, 43.2ms\n",
      "Speed: 0.6ms preprocess, 43.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-523-_jpg.rf.398c68aba3492f7ba13e48f7399c8344.jpg: 640x640 5 persons, 1 refrigerator, 53.8ms\n",
      "Speed: 0.7ms preprocess, 53.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-75_jpg.rf.fc0027e06829c22dbe4e71c973a99069.jpg: 640x640 1 person, 1 cow, 41.8ms\n",
      "Speed: 0.7ms preprocess, 41.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ins30_jpg.rf.9a68c27ba37a2ff961e674ab0a791c0d.jpg: 640x640 5 persons, 46.6ms\n",
      "Speed: 0.6ms preprocess, 46.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-224_jpg.rf.294c04b139675b7d7c335a0e1908fcbc.jpg: 640x640 1 truck, 37.2ms\n",
      "Speed: 0.7ms preprocess, 37.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-554_jpg.rf.96fa687f516ad834ceb539a61eda81f7.jpg: 640x640 4 persons, 64.4ms\n",
      "Speed: 0.6ms preprocess, 64.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0491_jpg.rf.1c27756b6705c215f08a091a08f31522.jpg: 640x640 3 persons, 1 dog, 2 cell phones, 1 toothbrush, 44.0ms\n",
      "Speed: 0.6ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-134_jpg.rf.8c2a6336edd07a69318445ce085a35f8.jpg: 640x640 2 persons, 37.3ms\n",
      "Speed: 0.6ms preprocess, 37.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_288_jpg.rf.cc732dd1330cb00ab835c7f48e7dc741.jpg: 640x640 1 person, 44.0ms\n",
      "Speed: 0.7ms preprocess, 44.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (34).jpeg: 384x640 12 persons, 1 train, 1 truck, 26.7ms\n",
      "Speed: 0.7ms preprocess, 26.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-165_jpg.rf.0ff0aeb885257372cf6482aa4ab3214d.jpg: 640x640 3 persons, 1 snowboard, 38.9ms\n",
      "Speed: 0.6ms preprocess, 38.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-242_jpg.rf.abca1cc102d6a680b50ea76207a752f3.jpg: 640x640 4 persons, 1 train, 55.2ms\n",
      "Speed: 0.6ms preprocess, 55.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0629_jpg.rf.f74c54685a0dbe492f4d49b6bf0edfdd.jpg: 640x640 1 person, 1 truck, 46.6ms\n",
      "Speed: 1.1ms preprocess, 46.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-897-_jpg.rf.7db8bb44a664e76878ebd2156a59b5a6.jpg: 640x640 2 persons, 41.9ms\n",
      "Speed: 0.8ms preprocess, 41.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-460_jpg.rf.c139e10c0facf98f3677e2fb847dfd74.jpg: 640x640 1 person, 60.9ms\n",
      "Speed: 0.7ms preprocess, 60.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-571_jpg.rf.4b3c9270b37ac373025b12708d33df09.jpg: 640x640 4 persons, 1 tie, 36.9ms\n",
      "Speed: 0.7ms preprocess, 36.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-849_jpg.rf.dfaabf6f93250fdbe0809582859b6397.jpg: 640x640 1 person, 1 truck, 40.3ms\n",
      "Speed: 0.6ms preprocess, 40.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox4_mp4-42_jpg.rf.7cd00519a8916b471f617fc9d406eb8b.jpg: 640x640 2 trucks, 38.4ms\n",
      "Speed: 0.7ms preprocess, 38.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-369-_jpg.rf.30fa5e9b5231010dabadf061d2db52d3.jpg: 640x640 2 persons, 66.6ms\n",
      "Speed: 0.7ms preprocess, 66.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-14_jpg.rf.39bf04e4984c0a5a3eace338c4c59499.jpg: 640x640 3 persons, 1 train, 1 truck, 42.1ms\n",
      "Speed: 0.6ms preprocess, 42.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005773_jpg.rf.7918c8b086473cb1e6fcae60d5ad24e0.jpg: 640x640 2 persons, 1 bottle, 38.9ms\n",
      "Speed: 0.6ms preprocess, 38.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-459_jpg.rf.395f16aff5655d92ac8204ed967eb157.jpg: 640x640 2 persons, 1 car, 1 airplane, 50.9ms\n",
      "Speed: 0.6ms preprocess, 50.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-210_jpg.rf.aaa1c8020f94fbd33d24bdaba9d308cf.jpg: 640x640 3 persons, 43.5ms\n",
      "Speed: 0.6ms preprocess, 43.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-41_jpg.rf.f6fa04b0e08026d620829a2ff14b6c32.jpg: 640x640 1 person, 1 traffic light, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-344_jpg.rf.443d1c9ae3cb991d3480ba0e3f026e58.jpg: 640x640 4 persons, 1 bus, 39.4ms\n",
      "Speed: 0.6ms preprocess, 39.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_296_jpg.rf.cbfc96ac0666e1a1a4dd5018da3860b5.jpg: 640x640 2 persons, 45.7ms\n",
      "Speed: 0.6ms preprocess, 45.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_13_jpg.rf.4bfa0a269577590f4f27b3b92ecbe117.jpg: 640x640 1 person, 38.0ms\n",
      "Speed: 0.7ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/4c43875bc97cdaece84ac6ce555235f1_jpg.rf.ffff7c84903cfc442c33b81472f99ab0.jpg: 640x640 3 persons, 1 laptop, 37.7ms\n",
      "Speed: 0.7ms preprocess, 37.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/727_jpg.rf.fb24f3c0038f7e32d4b4199ecc7c937e.jpg: 640x640 1 traffic light, 1 cat, 1 couch, 38.2ms\n",
      "Speed: 0.7ms preprocess, 38.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_740_jpg.rf.92657171f87bcedef193b7abaa2fef39.jpg: 640x640 4 persons, 1 car, 1 bus, 1 traffic light, 71.3ms\n",
      "Speed: 0.6ms preprocess, 71.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Apple-Tests-Face-ID-Feature-While-Wearing-a-Mask-Shorts_mp4-51_jpg.rf.27396fc04a6ccea3ce80c61bfd773d3c.jpg: 640x640 2 persons, 1 bus, 1 truck, 37.7ms\n",
      "Speed: 0.6ms preprocess, 37.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-332_jpg.rf.412a156b848acbd8ff3432e014c3f771.jpg: 640x640 1 person, 1 truck, 1 toothbrush, 49.5ms\n",
      "Speed: 0.7ms preprocess, 49.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-641_jpg.rf.aa36d0a940f13bcbd69f98d5309960b4.jpg: 640x640 1 person, 39.1ms\n",
      "Speed: 0.6ms preprocess, 39.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-3_jpg.rf.abf1bf422e052a7a44c307a1f7c94b7a.jpg: 640x640 2 persons, 1 boat, 2 benchs, 1 book, 52.6ms\n",
      "Speed: 0.7ms preprocess, 52.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-64_jpg.rf.863242580b0ac922541b8f479eaaf5ac.jpg: 640x640 4 persons, 41.4ms\n",
      "Speed: 0.7ms preprocess, 41.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-639_jpg.rf.351b2d526e4925e2d0bb07cca4f0609d.jpg: 640x640 1 person, 1 car, 2 trucks, 1 dog, 42.2ms\n",
      "Speed: 0.6ms preprocess, 42.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/YouTube-FreeStockFootage_Child-playing-with-parents-JoyLaughterHD-RQ_qqCZOkZk-720p_mp4-42_jpg.rf.24f70d1d2b1dfabb4b50ec9aa1a44302.jpg: 640x640 3 persons, 44.7ms\n",
      "Speed: 0.7ms preprocess, 44.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_255_jpg.rf.c869df859426935a42b5c37d74a862df.jpg: 640x640 5 persons, 1 truck, 37.8ms\n",
      "Speed: 0.6ms preprocess, 37.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-25_jpg.rf.0fd299cee2f5cff99543871ec17d935e.jpg: 640x640 1 person, 1 car, 1 train, 3 trucks, 46.9ms\n",
      "Speed: 0.6ms preprocess, 46.9ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_1009_jpg.rf.0bf853f3b4fecf3a8bbe288872dd303e.jpg: 640x640 1 person, 1 horse, 37.6ms\n",
      "Speed: 0.7ms preprocess, 37.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-486_jpg.rf.7ed1717194f2f52486146320aa6f41a5.jpg: 640x640 2 persons, 47.8ms\n",
      "Speed: 0.7ms preprocess, 47.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_181_jpg.rf.0a8f716210a4da8c791d983e6d8d49f1.jpg: 640x640 2 persons, 1 truck, 49.8ms\n",
      "Speed: 0.7ms preprocess, 49.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-619-_jpg.rf.a55792fce1fec65b17f4631c5330e0a5.jpg: 640x640 1 person, 1 truck, 1 surfboard, 37.0ms\n",
      "Speed: 0.7ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox6_mp4-157_jpg.rf.ed679126806aeab74db2f3b9d1a728f3.jpg: 640x640 2 persons, 1 car, 3 trucks, 1 fire hydrant, 44.3ms\n",
      "Speed: 0.6ms preprocess, 44.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_7286_JPG_jpg.rf.f3e308debd4cc4d6fc39218cb5c41ab5.jpg: 640x640 5 persons, 1 truck, 1 horse, 1 tie, 52.5ms\n",
      "Speed: 0.8ms preprocess, 52.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-731-_jpg.rf.74c1bf3dd3936f126806047dd71df558.jpg: 640x640 10 persons, 1 bus, 1 chair, 1 remote, 39.8ms\n",
      "Speed: 0.7ms preprocess, 39.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-182_jpg.rf.492a9e7be9451e34149bcbcb89c11810.jpg: 640x640 2 persons, 2 bicycles, 41.5ms\n",
      "Speed: 0.7ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-17_jpg.rf.2ff2b16a7d9b2a53552695c49fb34105.jpg: 640x640 1 person, 1 truck, 43.4ms\n",
      "Speed: 0.6ms preprocess, 43.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/video_CDC-YOUTUBE_mp4-60_jpg.rf.b3e3d72f289dd1159dd93c1c3326e087.jpg: 640x640 2 persons, 38.2ms\n",
      "Speed: 0.6ms preprocess, 38.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-370_jpg.rf.5c21800e4a180039fa8c029132eaa81d.jpg: 640x640 1 person, 1 truck, 64.6ms\n",
      "Speed: 0.6ms preprocess, 64.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-17_jpg.rf.f4ab2ba525257f589db913357678e99b.jpg: 640x640 1 person, 1 airplane, 1 bus, 1 truck, 1 parking meter, 39.9ms\n",
      "Speed: 0.6ms preprocess, 39.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-5_jpg.rf.0b87132ffac16c0ce01d3e302af09422.jpg: 640x640 2 persons, 1 bus, 1 bottle, 54.5ms\n",
      "Speed: 0.7ms preprocess, 54.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/helmet999863_jpg.rf.9667435fc8a05ffd5508057026b8e869.jpg: 640x640 2 persons, 1 truck, 38.7ms\n",
      "Speed: 0.6ms preprocess, 38.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (21).jpeg: 352x640 3 persons, 1 umbrella, 27.2ms\n",
      "Speed: 0.6ms preprocess, 27.2ms inference, 0.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0491_jpg.rf.4f334efca51ba5b5f9c6a95a94de1ba4.jpg: 640x640 3 persons, 39.0ms\n",
      "Speed: 0.7ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/istockphoto-1391992996-612x612.jpg: 448x640 1 person, 36.8ms\n",
      "Speed: 0.9ms preprocess, 36.8ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0550_jpg.rf.1288f7c63eed908dac7b6ba24c868ad8.jpg: 640x640 1 person, 1 bus, 1 toilet, 2 tvs, 70.8ms\n",
      "Speed: 0.7ms preprocess, 70.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2406-_png_jpg.rf.58e52da2e6d3e816d59d716f3a2a1ae2.jpg: 640x640 4 persons, 1 bus, 2 trucks, 1 cat, 54.4ms\n",
      "Speed: 0.6ms preprocess, 54.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2_jpg.rf.9360d1df64e52841007492e10100ffcd.jpg: 640x640 3 persons, 1 bicycle, 50.5ms\n",
      "Speed: 0.8ms preprocess, 50.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/helmet999595_jpg.rf.6a6b0da0eaf9935229661a8a938ac91a.jpg: 640x640 1 person, 38.7ms\n",
      "Speed: 0.7ms preprocess, 38.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-60_jpg.rf.c6eeedbfe53887330879b637eddecfbb.jpg: 640x640 4 persons, 2 trucks, 54.1ms\n",
      "Speed: 0.6ms preprocess, 54.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-15_jpg.rf.bcfb839a9423f23eb2417ccca265d49f.jpg: 640x640 1 person, 5 cars, 1 truck, 1 boat, 1 traffic light, 48.5ms\n",
      "Speed: 0.6ms preprocess, 48.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-25_jpg.rf.3313bb2b19a7aa3a0af745abe858ec8e.jpg: 640x640 4 persons, 49.9ms\n",
      "Speed: 0.8ms preprocess, 49.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-13_jpg.rf.46d2f83a51eebc4459719d2f1861c222.jpg: 640x640 3 persons, 1 truck, 64.2ms\n",
      "Speed: 0.6ms preprocess, 64.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_181_jpg.rf.cd6c683a112d80f17f33d55553f431c0.jpg: 640x640 2 tvs, 43.0ms\n",
      "Speed: 0.6ms preprocess, 43.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-46_jpg.rf.4ba287f4dd6fff9aadf4b49e0171de48.jpg: 640x640 2 trains, 1 truck, 49.8ms\n",
      "Speed: 0.6ms preprocess, 49.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-391_jpg.rf.7b5d9b2652344f2cfacb205f4a3263a3.jpg: 640x640 3 persons, 44.7ms\n",
      "Speed: 0.6ms preprocess, 44.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-64_jpg.rf.d1ef98ecec242ae069270ff89347d925.jpg: 640x640 1 person, 1 train, 1 giraffe, 48.1ms\n",
      "Speed: 0.6ms preprocess, 48.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-695_jpg.rf.19a86e22fe4a33c49cba7546d5e6498d.jpg: 640x640 7 persons, 1 truck, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008382_jpg.rf.23c52bce2cca27ec7c476e91b24de0ae.jpg: 640x640 1 person, 1 train, 1 truck, 57.6ms\n",
      "Speed: 0.9ms preprocess, 57.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-15_jpg.rf.5a2a37538c16a83554327e6f910dde88.jpg: 640x640 4 persons, 1 tie, 1 bed, 1 laptop, 39.8ms\n",
      "Speed: 0.6ms preprocess, 39.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-89_jpg.rf.346054697ac0f316fcb36b5da4e1869b.jpg: 640x640 2 persons, 2 trucks, 5 surfboards, 65.0ms\n",
      "Speed: 0.6ms preprocess, 65.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1116-_jpg.rf.89204e926b55ec2da9541d47c0b88309.jpg: 640x640 1 person, 1 truck, 41.9ms\n",
      "Speed: 0.7ms preprocess, 41.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/598_jpg.rf.eb88df29b6754e75da36398d182384c1.jpg: 640x640 1 person, 1 bottle, 45.6ms\n",
      "Speed: 0.6ms preprocess, 45.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-534_jpg.rf.95e5ec43eaf6f5570750ad6944d9b11e.jpg: 640x640 1 person, 1 toothbrush, 42.5ms\n",
      "Speed: 0.7ms preprocess, 42.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ka_00884_png_jpg.rf.cfbcd01afdb3e6274dc39708b04b125d.jpg: 640x640 1 person, 42.8ms\n",
      "Speed: 0.6ms preprocess, 42.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/bookstore_38_02_altavista_jpg.rf.ae0ecbdcf798d341ca28b85a9f4918c6.jpg: 640x640 2 persons, 48.5ms\n",
      "Speed: 0.7ms preprocess, 48.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/istockphoto-149319933-612x612.jpg: 448x640 1 person, 32.9ms\n",
      "Speed: 0.9ms preprocess, 32.9ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-115_jpg.rf.3180062637f2f2c6dac5a1a773a3d006.jpg: 640x640 1 stop sign, 61.0ms\n",
      "Speed: 0.7ms preprocess, 61.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_426_jpg.rf.77fdc5e051ecdcd4dbc26e25df161a42.jpg: 640x640 1 truck, 2 boats, 50.4ms\n",
      "Speed: 0.7ms preprocess, 50.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/maksssksksss710_png_jpg.rf.1bb1ad9ca1220cf1be8cd970bc963006.jpg: 640x640 5 persons, 41.0ms\n",
      "Speed: 0.7ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_28_jpg.rf.83228814ea921754456d144a3d128bf4.jpg: 640x640 5 persons, 1 train, 66.3ms\n",
      "Speed: 0.7ms preprocess, 66.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0750_jpg.rf.61c463517d619e03e3baf0d413c99315.jpg: 640x640 2 persons, 1 traffic light, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/006012_jpg.rf.140391c68102321f02973bd473f607da.jpg: 640x640 2 persons, 1 potted plant, 49.3ms\n",
      "Speed: 0.7ms preprocess, 49.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-813_jpg.rf.394e935ab265f4a722685abfa5c64aca.jpg: 640x640 1 person, 2 bottles, 42.9ms\n",
      "Speed: 0.6ms preprocess, 42.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_662_jpg.rf.8ca986b03ea30d8485ccedfd44295260.jpg: 640x640 2 persons, 1 train, 1 truck, 45.2ms\n",
      "Speed: 0.6ms preprocess, 45.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/video_CDC-YOUTUBE_mp4-60_jpg.rf.f0c74e62803aebc2c66afe8c01f2a773.jpg: 640x640 3 persons, 3 trucks, 49.1ms\n",
      "Speed: 0.6ms preprocess, 49.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-118-_jpg.rf.97ebf941e2db53ff604959f7fb3adbda.jpg: 640x640 2 persons, 1 truck, 60.7ms\n",
      "Speed: 0.6ms preprocess, 60.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_796_jpg.rf.999fd298ae6666a80a6394f2ca7ed999.jpg: 640x640 1 train, 44.3ms\n",
      "Speed: 0.7ms preprocess, 44.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_294_jpg.rf.a6b3f449c64aee5f74e1c46e85ab15a3.jpg: 640x640 4 persons, 1 bus, 2 tvs, 44.3ms\n",
      "Speed: 0.7ms preprocess, 44.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_475_jpg.rf.fe0fbe9d9078e375daa15d81a6eb20ab.jpg: 640x640 1 motorcycle, 54.6ms\n",
      "Speed: 0.7ms preprocess, 54.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Libreria_09_20_altavista_jpg.rf.4ac020cfe29c2ad86b310d0f602d84d1.jpg: 640x640 2 persons, 2 books, 39.6ms\n",
      "Speed: 0.6ms preprocess, 39.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-305-_jpg.rf.7212ecf73d86bcd5fbfc5611f3e08b8a.jpg: 640x640 1 truck, 69.1ms\n",
      "Speed: 0.6ms preprocess, 69.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mo-justin-mask-NoMask_mov-34_jpg.rf.862437287915459ee551ea4e4cc9bdf6.jpg: 640x640 3 persons, 1 truck, 46.1ms\n",
      "Speed: 0.7ms preprocess, 46.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-135_jpg.rf.02aba8687f6a54763ddaa03a479ff3dc.jpg: 640x640 2 persons, 1 bicycle, 1 train, 37.8ms\n",
      "Speed: 0.6ms preprocess, 37.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-682_jpg.rf.99f339a7bafc1582a19cd354e3ce059d.jpg: 640x640 8 persons, 41.9ms\n",
      "Speed: 0.6ms preprocess, 41.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-448_jpg.rf.d5ba5cfa93fdd4d8610d02627f9b7761.jpg: 640x640 2 persons, 1 train, 1 truck, 54.5ms\n",
      "Speed: 0.6ms preprocess, 54.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-832_jpg.rf.45c0405782581cbf4192e788bcb8665b.jpg: 640x640 1 person, 1 truck, 50.5ms\n",
      "Speed: 0.9ms preprocess, 50.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-567_jpg.rf.1482e6c104401564d8293ee68f3369ac.jpg: 640x640 (no detections), 42.9ms\n",
      "Speed: 0.6ms preprocess, 42.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Industrial-3-Part-Skymaster-insitu_jpg.rf.b8b0caef1419e9ebab1f75f780f91acb.jpg: 640x640 1 person, 45.8ms\n",
      "Speed: 0.7ms preprocess, 45.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/londres_023_jpg.rf.aa01188945c0c281f478311642fc796f.jpg: 640x640 9 persons, 49.1ms\n",
      "Speed: 0.8ms preprocess, 49.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0750_jpg.rf.81e0f8e91c20616315e03f93799ec5b7.jpg: 640x640 3 persons, 1 umbrella, 41.8ms\n",
      "Speed: 0.6ms preprocess, 41.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-348_jpg.rf.afbf521c4e2d7f221b58b6bbc3f39f4f.jpg: 640x640 1 person, 1 car, 1 boat, 1 suitcase, 68.6ms\n",
      "Speed: 0.6ms preprocess, 68.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-112-_jpg.rf.f8d9f3850971d148a63d2c102197a651.jpg: 640x640 1 person, 1 dining table, 37.3ms\n",
      "Speed: 0.6ms preprocess, 37.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-260_jpg.rf.c900a4666030c00529812bae01331790.jpg: 640x640 1 bus, 1 truck, 45.8ms\n",
      "Speed: 0.7ms preprocess, 45.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5851_jpg.rf.e86249fb1684ab8fe574800182fd3d58.jpg: 640x640 7 persons, 1 horse, 58.3ms\n",
      "Speed: 0.7ms preprocess, 58.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-560-_jpg.rf.114f9f0f47688c4843cc7cd8a35c95c8.jpg: 640x640 1 person, 1 bus, 3 trucks, 41.3ms\n",
      "Speed: 0.6ms preprocess, 41.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-519_jpg.rf.87d82e436cdd1af634d5ce239b333d0f.jpg: 640x640 4 persons, 1 sink, 55.7ms\n",
      "Speed: 0.7ms preprocess, 55.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-507-_jpg.rf.b860c2a88ce6fc719ca2a6465e5991c4.jpg: 640x640 1 person, 2 horses, 1 skis, 1 scissors, 45.0ms\n",
      "Speed: 0.6ms preprocess, 45.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-39_jpg.rf.fb059423109df5c7c98835e2a92b073f.jpg: 640x640 1 person, 1 truck, 45.8ms\n",
      "Speed: 0.7ms preprocess, 45.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_1004_jpg.rf.b214044582d882b35bc97ae766d7f518.jpg: 640x640 1 person, 2 cars, 46.0ms\n",
      "Speed: 0.6ms preprocess, 46.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-837_jpg.rf.ba028856408fe5c32864742ea227a7e8.jpg: 640x640 2 persons, 1 motorcycle, 50.4ms\n",
      "Speed: 1.7ms preprocess, 50.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-210_jpg.rf.6e3354f079d01a5c68d56911020e31ce.jpg: 640x640 1 person, 1 truck, 42.2ms\n",
      "Speed: 0.6ms preprocess, 42.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-187_jpg.rf.f79cdc12a3c1e1d17d27c93036518f0a.jpg: 640x640 2 persons, 1 tie, 1 banana, 61.5ms\n",
      "Speed: 0.6ms preprocess, 61.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005577_jpg.rf.28a70bd7ad7c4a004b19903de1eafc9e.jpg: 640x640 2 persons, 2 trucks, 1 giraffe, 57.4ms\n",
      "Speed: 0.7ms preprocess, 57.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5024_mp4-5_jpg.rf.6cd31342886e81ced03d5af2ece44767.jpg: 640x640 2 persons, 2 birds, 42.3ms\n",
      "Speed: 0.7ms preprocess, 42.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-170_jpg.rf.8d44e32dcefe974fc0173d7b8bd4753e.jpg: 640x640 2 persons, 39.9ms\n",
      "Speed: 0.6ms preprocess, 39.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-999-_jpg.rf.42f408dd8763c7b71e01ecad8d87ae20.jpg: 640x640 2 persons, 45.1ms\n",
      "Speed: 0.6ms preprocess, 45.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/60_jpg.rf.0641313d1b5ddfbf24f89aad0d2326cc.jpg: 640x640 4 persons, 1 bicycle, 1 bottle, 43.1ms\n",
      "Speed: 8.3ms preprocess, 43.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-25_jpg.rf.e139b5218288ad035d5a201d1b115793.jpg: 640x640 1 motorcycle, 1 truck, 1 suitcase, 49.0ms\n",
      "Speed: 0.6ms preprocess, 49.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/p65621379_jpg.rf.0b6c6decc1f55d5fe6afe977125b858a.jpg: 640x640 1 person, 1 bottle, 1 refrigerator, 45.9ms\n",
      "Speed: 0.7ms preprocess, 45.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-816-_jpg.rf.8dc9e2198fc86bd12a488c34fc4fa02e.jpg: 640x640 1 person, 1 train, 2 trucks, 53.3ms\n",
      "Speed: 0.7ms preprocess, 53.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/4c43875bc97cdaece84ac6ce555235f1_jpg.rf.8f711c6b8a5d905cd6c0011a1a37e71b.jpg: 640x640 4 persons, 1 car, 1 train, 40.3ms\n",
      "Speed: 0.6ms preprocess, 40.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0629_jpg.rf.2ce72e23a7a0e2842971a32b45f71b38.jpg: 640x640 2 persons, 1 truck, 56.2ms\n",
      "Speed: 0.6ms preprocess, 56.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_MOV-30_jpg.rf.2134662fedec3bb07d20eb107c911520.jpg: 640x640 1 person, 1 truck, 1 potted plant, 1 book, 63.4ms\n",
      "Speed: 0.6ms preprocess, 63.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-41_jpg.rf.ab0b49bfa0036086c3d484b988e99934.jpg: 640x640 2 persons, 1 motorcycle, 3 trucks, 38.9ms\n",
      "Speed: 0.6ms preprocess, 38.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-550_jpg.rf.ecfaefad29921794973e7f5f6ad83500.jpg: 640x640 3 persons, 4 chairs, 49.7ms\n",
      "Speed: 0.7ms preprocess, 49.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_093_jpg.rf.7b80c39438a5b6c591341b76b449e55f.jpg: 640x640 1 person, 2 buss, 2 trucks, 39.3ms\n",
      "Speed: 0.6ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008593_jpg.rf.a6f37b5452eb88ac2cd643e744e78529.jpg: 640x640 2 persons, 1 couch, 2 clocks, 50.3ms\n",
      "Speed: 0.7ms preprocess, 50.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_321_jpg.rf.f4432cc1ed4ecde1f2c4dde752eb4ef8.jpg: 640x640 2 persons, 1 bicycle, 1 truck, 1 tennis racket, 41.7ms\n",
      "Speed: 0.8ms preprocess, 41.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008593_jpg.rf.a997ae409b26bbc3efa95dd6da91554e.jpg: 640x640 4 persons, 1 train, 47.4ms\n",
      "Speed: 0.7ms preprocess, 47.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox4_mp4-42_jpg.rf.b46d66b710aa73867b319e1c40104df9.jpg: 640x640 5 persons, 44.8ms\n",
      "Speed: 0.7ms preprocess, 44.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008382_jpg.rf.9c0e50eae212ceaba5d487cfc1789a8d.jpg: 640x640 1 person, 1 train, 1 truck, 1 bed, 47.2ms\n",
      "Speed: 8.2ms preprocess, 47.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-210_jpg.rf.20c5e827a60cba37ba6a4247128cf9a2.jpg: 640x640 2 persons, 1 bicycle, 1 bottle, 43.3ms\n",
      "Speed: 0.6ms preprocess, 43.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-9_jpg.rf.ef54b5e3163b15404afe12f96f0d3fd0.jpg: 640x640 2 persons, 1 chair, 2 books, 39.2ms\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_678_jpg.rf.21b0fd0f5371ac6bfa4c8d9cf61d6ca4.jpg: 640x640 7 persons, 1 truck, 61.6ms\n",
      "Speed: 0.7ms preprocess, 61.6ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/additional_tests-Nomask-wearing_mp4-35_jpg.rf.3585f3a01afcfd9cf8d2f1660e331084.jpg: 640x640 2 persons, 40.6ms\n",
      "Speed: 0.7ms preprocess, 40.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-448_jpg.rf.cbe301db586a0f6cf382a8037cd6b98e.jpg: 640x640 1 person, 45.7ms\n",
      "Speed: 0.7ms preprocess, 45.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_170_jpg.rf.e01f9e0379c6073e0463f37eab94dd77.jpg: 640x640 4 persons, 1 bus, 1 train, 1 chair, 46.7ms\n",
      "Speed: 0.6ms preprocess, 46.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-708-_jpg.rf.9f1f70baaef9412fd85d56d0793fc672.jpg: 640x640 3 trains, 47.2ms\n",
      "Speed: 0.6ms preprocess, 47.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_995_jpg.rf.ce3948922b1aca03e2b3fbd247bc9150.jpg: 640x640 2 persons, 1 car, 7 trucks, 42.8ms\n",
      "Speed: 0.7ms preprocess, 42.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0073_jpg.rf.36b9f79347faa9106a1d2575987e0924.jpg: 640x640 1 person, 1 bed, 57.2ms\n",
      "Speed: 0.6ms preprocess, 57.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-134_jpg.rf.b9f98efd07116d2e25adbc9685b959ca.jpg: 640x640 2 persons, 39.5ms\n",
      "Speed: 0.6ms preprocess, 39.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Mask2_mov-44_jpg.rf.7e8d95ce75a599860a7fff8c669ae851.jpg: 640x640 2 persons, 3 trucks, 46.9ms\n",
      "Speed: 0.7ms preprocess, 46.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_731_jpg.rf.5659c6a57ec8c695269d4e192f3ace10.jpg: 640x640 1 train, 1 truck, 67.9ms\n",
      "Speed: 0.7ms preprocess, 67.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-96_jpg.rf.ac37d2e09cdbfe8a45a670d5d9bd9b3e.jpg: 640x640 1 person, 1 train, 3 trucks, 49.0ms\n",
      "Speed: 0.7ms preprocess, 49.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/helmet999595_jpg.rf.f2eb6111970813c351aa83e7fb3aa21d.jpg: 640x640 1 person, 41.5ms\n",
      "Speed: 0.6ms preprocess, 41.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-219_jpg.rf.e149ec4783f96c308569ab885cf98edf.jpg: 640x640 3 persons, 1 truck, 1 laptop, 41.6ms\n",
      "Speed: 0.6ms preprocess, 41.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Industrial-3-Part-Skymaster-insitu_jpg.rf.9228fbc3ed8dbced49fb6e003a31ac91.jpg: 640x640 1 car, 1 airplane, 41.2ms\n",
      "Speed: 0.7ms preprocess, 41.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-224_jpg.rf.a9716401b7b5bc5d95eaf41d731d319e.jpg: 640x640 8 persons, 1 train, 48.7ms\n",
      "Speed: 0.6ms preprocess, 48.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-23_jpg.rf.4354bc777a9ea088f606a97292b17844.jpg: 640x640 2 persons, 3 bottles, 62.8ms\n",
      "Speed: 0.6ms preprocess, 62.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005100_jpg.rf.8f58de6f4be40f7e676c1e35773b2056.jpg: 640x640 2 persons, 42.4ms\n",
      "Speed: 0.8ms preprocess, 42.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/60_jpg.rf.4edf14ca3e3d857d2a32b33adbc6e1c1.jpg: 640x640 2 persons, 45.6ms\n",
      "Speed: 0.7ms preprocess, 45.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-824_jpg.rf.52a1bda32589a2e4564cc3f21f3dfb6b.jpg: 640x640 1 person, 1 toothbrush, 40.2ms\n",
      "Speed: 0.7ms preprocess, 40.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_004301_jpg.rf.950def400852f7e9096bb7a2c7c5e900.jpg: 640x640 4 persons, 1 truck, 1 tv, 38.6ms\n",
      "Speed: 0.7ms preprocess, 38.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-384_jpg.rf.7e7e9554b607534351d62775b0355079.jpg: 640x640 2 persons, 1 bench, 38.1ms\n",
      "Speed: 0.6ms preprocess, 38.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-813-_jpg.rf.5399e99ca598ff02316d420184b77a09.jpg: 640x640 1 train, 1 truck, 41.9ms\n",
      "Speed: 0.6ms preprocess, 41.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_288_jpg.rf.45c7f0134ba6495b00dce8a10b98c922.jpg: 640x640 1 person, 42.3ms\n",
      "Speed: 0.9ms preprocess, 42.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0460_jpg.rf.a412becf4d099d3a7a8f5bd61cbab0e2.jpg: 640x640 2 persons, 1 truck, 69.5ms\n",
      "Speed: 0.7ms preprocess, 69.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/download (5).jpeg: 448x640 3 persons, 43.6ms\n",
      "Speed: 0.8ms preprocess, 43.6ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-519_jpg.rf.9f89f818578f6aac6486b358a28d1fe1.jpg: 640x640 3 persons, 1 toilet, 1 tv, 48.9ms\n",
      "Speed: 0.7ms preprocess, 48.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-175_jpg.rf.42efa8b28ba1ccb4779c2b169023c27d.jpg: 640x640 1 person, 1 airplane, 1 truck, 1 bed, 45.9ms\n",
      "Speed: 0.7ms preprocess, 45.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-28_jpg.rf.19fc8076a9b40a6d0126deea4050d2fb.jpg: 640x640 3 persons, 1 bicycle, 1 truck, 43.5ms\n",
      "Speed: 0.7ms preprocess, 43.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-709_jpg.rf.34745146d2ae2dbc7b5605b15d06c949.jpg: 640x640 1 person, 47.9ms\n",
      "Speed: 0.7ms preprocess, 47.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-48_jpg.rf.82ca9f1ab7f0394a237c4938bdd913f9.jpg: 640x640 2 trucks, 44.0ms\n",
      "Speed: 0.7ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_002711_jpg.rf.c5342ac0316773ec167d3bc6f61ec8ac.jpg: 640x640 1 person, 1 car, 41.7ms\n",
      "Speed: 0.7ms preprocess, 41.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-763-_jpg.rf.297581ce662979764c273bc4aa5c19c6.jpg: 640x640 3 persons, 1 bicycle, 4 cars, 1 truck, 41.5ms\n",
      "Speed: 0.6ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/video_CDC-YOUTUBE_mp4-50_jpg.rf.cb32d15d49f5f5a43a828b26ef50c6f9.jpg: 640x640 2 persons, 1 bed, 1 dining table, 40.1ms\n",
      "Speed: 0.6ms preprocess, 40.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-209_jpg.rf.8eb69019cfb7e173c47442a5ceac5900.jpg: 640x640 1 person, 1 bicycle, 1 train, 54.8ms\n",
      "Speed: 0.7ms preprocess, 54.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2270-_png_jpg.rf.cc2c95b44846f13084b60e847aaa692a.jpg: 640x640 1 book, 64.3ms\n",
      "Speed: 0.6ms preprocess, 64.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_624_jpg.rf.f62d07b53d05ad529896b9db8c7bd08e.jpg: 640x640 1 person, 43.1ms\n",
      "Speed: 0.6ms preprocess, 43.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class1_075_jpg.rf.2a623fcaaa9ee3c192f00ce605dc44f6.jpg: 640x640 1 person, 1 motorcycle, 2 trucks, 53.2ms\n",
      "Speed: 0.7ms preprocess, 53.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_003000_jpg.rf.cf61f4b407ecc0250f3f8a204311e086.jpg: 640x640 5 persons, 4 surfboards, 45.9ms\n",
      "Speed: 0.6ms preprocess, 45.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-213_jpg.rf.3dc254f0ee3f229e0766837fcb916d24.jpg: 640x640 1 person, 2 cars, 3 trucks, 40.3ms\n",
      "Speed: 1.0ms preprocess, 40.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-474_jpg.rf.a83afe8f012f7c5c51bd973bd4efc3c1.jpg: 640x640 1 person, 1 truck, 49.8ms\n",
      "Speed: 0.7ms preprocess, 49.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-115_jpg.rf.d0c6fa0cdb93e0dcda95fcf82b93d7f2.jpg: 640x640 1 person, 1 car, 1 truck, 1 chair, 41.9ms\n",
      "Speed: 0.6ms preprocess, 41.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_673_jpg.rf.5b0d43297701b36d7b9f870dabf04752.jpg: 640x640 (no detections), 54.3ms\n",
      "Speed: 0.7ms preprocess, 54.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-148_jpg.rf.b032a56f7ba893a520c79ed256a65f02.jpg: 640x640 2 cars, 1 truck, 41.2ms\n",
      "Speed: 0.7ms preprocess, 41.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_004301_jpg.rf.91ec90a81cecd19e78920c6ceaf0d01e.jpg: 640x640 1 person, 1 baseball bat, 51.3ms\n",
      "Speed: 0.6ms preprocess, 51.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (20).jpeg: 448x640 2 persons, 50.4ms\n",
      "Speed: 0.8ms preprocess, 50.4ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1029-_jpg.rf.f34331d792a26cbe94ef77e3251989ac.jpg: 640x640 1 person, 1 truck, 41.3ms\n",
      "Speed: 1.0ms preprocess, 41.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-504_jpg.rf.586cfb3ab06e7ec9cd9846fb1414fd7d.jpg: 640x640 1 train, 51.3ms\n",
      "Speed: 0.6ms preprocess, 51.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-196_jpg.rf.df3c8acab8adcce2adc69e1ae58abca1.jpg: 640x640 1 person, 1 car, 47.2ms\n",
      "Speed: 0.6ms preprocess, 47.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/move_in_corridor_jpg.rf.c13fac4f09c8776ba3ed1789fb1645ad.jpg: 640x640 2 persons, 1 airplane, 45.2ms\n",
      "Speed: 0.7ms preprocess, 45.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-667_jpg.rf.d2f2249f002ec216499a1284b54abb00.jpg: 640x640 1 car, 1 train, 1 bench, 1 chair, 46.0ms\n",
      "Speed: 0.7ms preprocess, 46.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-39_jpg.rf.6c742e62c3f1af3aeeb97ba16bffd3b7.jpg: 640x640 1 person, 1 bicycle, 56.7ms\n",
      "Speed: 0.7ms preprocess, 56.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-554_jpg.rf.9546dec733b426a9358402a0f27b2648.jpg: 640x640 1 person, 1 train, 41.4ms\n",
      "Speed: 0.6ms preprocess, 41.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/405_jpg.rf.534cf3056a780b84def0ce12ced849b7.jpg: 640x640 3 persons, 64.6ms\n",
      "Speed: 0.6ms preprocess, 64.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_314_jpg.rf.3496a5fdbb273b0f8388224cd07a6dfe.jpg: 640x640 1 car, 1 truck, 1 umbrella, 1 bottle, 1 clock, 45.9ms\n",
      "Speed: 0.7ms preprocess, 45.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-10_jpg.rf.c0fb2322113188e5da9d1716b1a04ebd.jpg: 640x640 1 person, 39.9ms\n",
      "Speed: 0.6ms preprocess, 39.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/02629_jpg.rf.c3231f30e24be87a70d431d81ae730ee.jpg: 640x640 2 persons, 1 train, 1 horse, 1 bottle, 43.0ms\n",
      "Speed: 0.6ms preprocess, 43.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-170_jpg.rf.271811f43fc83abd75aaeaad926b43d6.jpg: 640x640 1 person, 44.8ms\n",
      "Speed: 0.7ms preprocess, 44.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RTX7CD4D-e1580252893876_jpg.rf.11077cef10f1b6963612c7f4803018fa.jpg: 640x640 2 persons, 55.6ms\n",
      "Speed: 0.7ms preprocess, 55.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox2_mp4-74_jpg.rf.bf9aaf27108385d7246130699dd1556c.jpg: 640x640 3 persons, 1 car, 42.7ms\n",
      "Speed: 0.7ms preprocess, 42.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/02629_jpg.rf.0521012466fb729b8c9cf3291d35077a.jpg: 640x640 6 persons, 1 truck, 57.3ms\n",
      "Speed: 0.7ms preprocess, 57.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-13_jpg.rf.2c6528020ce23351ad0d21110a578b0d.jpg: 640x640 2 persons, 46.5ms\n",
      "Speed: 0.6ms preprocess, 46.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0363_jpg.rf.2bd76491393097e118e12be3c9ff93cf.jpg: 640x640 2 persons, 44.2ms\n",
      "Speed: 5.4ms preprocess, 44.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-693-_jpg.rf.7d6b68c84e22ddbad80479d689c2e96e.jpg: 640x640 1 person, 64.2ms\n",
      "Speed: 0.7ms preprocess, 64.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/004720_jpg.rf.44b8db920085c7034b6b0637fa85fe11.jpg: 640x640 3 persons, 1 car, 1 truck, 1 chair, 44.2ms\n",
      "Speed: 0.6ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox4_mp4-111_jpg.rf.dd047d61ebf9b70f351d8faf0e850fe9.jpg: 640x640 2 persons, 46.0ms\n",
      "Speed: 0.7ms preprocess, 46.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-235_jpg.rf.145865b91fed5333f9e75f4d72a8c3fc.jpg: 640x640 3 persons, 40.6ms\n",
      "Speed: 0.6ms preprocess, 40.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-131_jpg.rf.8a1878f8ac8b76e1dbd8518bf4cf3e77.jpg: 640x640 3 persons, 1 bottle, 47.8ms\n",
      "Speed: 0.6ms preprocess, 47.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-20_jpg.rf.189ac754788bcbde504cec9ccd800aa4.jpg: 640x640 2 persons, 55.2ms\n",
      "Speed: 0.6ms preprocess, 55.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-534_jpg.rf.b99e856a6009778e822431e4e4858a82.jpg: 640x640 1 truck, 1 bowl, 54.3ms\n",
      "Speed: 0.7ms preprocess, 54.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-28_jpg.rf.1fe0d6f0aac876e1c14d2c6752ecb47b.jpg: 640x640 10 persons, 1 bicycle, 1 truck, 1 chair, 43.6ms\n",
      "Speed: 0.7ms preprocess, 43.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_781_jpg.rf.9cd7d35563f5721f34d5316402030bff.jpg: 640x640 2 persons, 1 truck, 38.6ms\n",
      "Speed: 0.6ms preprocess, 38.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-3_jpg.rf.a0a4ec4e54b1f1b04803df827c6329c8.jpg: 640x640 2 persons, 1 truck, 2 backpacks, 66.4ms\n",
      "Speed: 0.7ms preprocess, 66.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_61_jpg.rf.a33e08a95825cb2760879674f3f61813.jpg: 640x640 1 train, 1 banana, 1 dining table, 1 clock, 42.3ms\n",
      "Speed: 0.6ms preprocess, 42.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-0_jpg.rf.2515251d95f3983654cb680fac4e37bb.jpg: 640x640 5 persons, 1 truck, 1 chair, 40.3ms\n",
      "Speed: 0.6ms preprocess, 40.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/616_jpg.rf.fdef094924d19a5cd197494c1cb81759.jpg: 640x640 5 persons, 1 truck, 47.7ms\n",
      "Speed: 0.6ms preprocess, 47.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-46_jpg.rf.0fca56e42cb2e4474ea760ad23a71d1f.jpg: 640x640 2 persons, 41.8ms\n",
      "Speed: 0.7ms preprocess, 41.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/329_jpg.rf.4a5e5473d213e592580c29c03b2db094.jpg: 640x640 2 persons, 1 umbrella, 48.0ms\n",
      "Speed: 0.7ms preprocess, 48.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_9949-1-_mp4-63_jpg.rf.d8a5f7b498a085df51dcb6dbdd374b93.jpg: 640x640 3 persons, 1 horse, 2 chairs, 56.9ms\n",
      "Speed: 0.7ms preprocess, 56.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-639_jpg.rf.0858ba004953521ae92ee56e6f95a993.jpg: 640x640 3 persons, 1 fire hydrant, 56.2ms\n",
      "Speed: 0.6ms preprocess, 56.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-460_jpg.rf.d2dee92d138a460505332c0a5dd32432.jpg: 640x640 2 persons, 1 bench, 42.6ms\n",
      "Speed: 0.7ms preprocess, 42.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-235_jpg.rf.7f563a11c15ff20d1b5ffb5caa9aa060.jpg: 640x640 1 traffic light, 1 bed, 39.7ms\n",
      "Speed: 0.6ms preprocess, 39.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-499_jpg.rf.770be9f4a896c3f7d05b353f13faaa08.jpg: 640x640 3 persons, 72.7ms\n",
      "Speed: 0.6ms preprocess, 72.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_93_jpg.rf.fbc2f4ad1c8a06a166c5d2bb7fdcddda.jpg: 640x640 1 truck, 1 bench, 1 refrigerator, 43.9ms\n",
      "Speed: 0.6ms preprocess, 43.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-579_jpg.rf.fb63d26647576c4068406dd26f6cae42.jpg: 640x640 2 persons, 43.4ms\n",
      "Speed: 0.6ms preprocess, 43.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_4921-2_mp4-40_jpg.rf.ed65cd53f5ac4d4f278c4cf9359d0b79.jpg: 640x640 3 persons, 3 trucks, 1 dining table, 39.7ms\n",
      "Speed: 0.7ms preprocess, 39.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-79_jpg.rf.a31577e9de8bac4f2ea33df90a0f0ccc.jpg: 640x640 2 persons, 1 truck, 1 bottle, 53.8ms\n",
      "Speed: 0.7ms preprocess, 53.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/01235_jpg.rf.cf94f7423325a92529343ffdc6deb074.jpg: 640x640 2 persons, 57.5ms\n",
      "Speed: 0.7ms preprocess, 57.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_39_jpg.rf.05703385c8acf10754c714403717d287.jpg: 640x640 (no detections), 44.3ms\n",
      "Speed: 0.7ms preprocess, 44.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5024_mp4-2_jpg.rf.6010c9cc7112bad8ad73d19f4f44a0d0.jpg: 640x640 2 persons, 1 truck, 47.1ms\n",
      "Speed: 0.7ms preprocess, 47.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_732_jpg.rf.7e34583546e61772c24efb92dcb60fe8.jpg: 640x640 1 train, 1 truck, 1 bed, 43.9ms\n",
      "Speed: 0.6ms preprocess, 43.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008364_jpg.rf.0457e5579a2dcd24852278b5657b25b5.jpg: 640x640 2 persons, 1 motorcycle, 64.0ms\n",
      "Speed: 0.7ms preprocess, 64.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/img17_jpg.rf.a88d83be344f9592580a2e5c0c4dbfe4.jpg: 640x640 4 persons, 2 cars, 1 motorcycle, 1 surfboard, 1 banana, 49.7ms\n",
      "Speed: 0.7ms preprocess, 49.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-693-_jpg.rf.9c967ca4147923ccdf1f58b3df441a8f.jpg: 640x640 7 persons, 2 trains, 40.6ms\n",
      "Speed: 0.7ms preprocess, 40.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-3_jpg.rf.a1a56319f7cc598049380bcf7f10ddfc.jpg: 640x640 3 persons, 47.9ms\n",
      "Speed: 0.6ms preprocess, 47.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_1025_jpg.rf.5f717caaf19eef8596c6b891131909ab.jpg: 640x640 2 persons, 1 motorcycle, 1 bird, 39.5ms\n",
      "Speed: 0.6ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-667_jpg.rf.8c29596b7486388ed0cdf3da93f73cd4.jpg: 640x640 1 person, 1 bus, 3 trucks, 1 dog, 55.3ms\n",
      "Speed: 0.7ms preprocess, 55.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-170_jpg.rf.f371d64f8eec000f8c0ea59ab367b71e.jpg: 640x640 1 person, 1 train, 1 truck, 77.5ms\n",
      "Speed: 0.7ms preprocess, 77.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mask-wearing-1632932085584_png_jpg.rf.25173d12a53c03ee1b12dbc1c023f7d6.jpg: 640x640 8 persons, 1 chair, 2 laptops, 46.5ms\n",
      "Speed: 0.7ms preprocess, 46.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-303_jpg.rf.07b3e04bed6cfb84b6f10f2c02a305c3.jpg: 640x640 1 person, 1 traffic light, 50.5ms\n",
      "Speed: 0.7ms preprocess, 50.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_732_jpg.rf.7c28959bfc3cbbf97b386de3f53c5892.jpg: 640x640 1 train, 1 truck, 39.3ms\n",
      "Speed: 0.6ms preprocess, 39.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-112-_jpg.rf.7a5466131778ab7835ee50d29040fb1e.jpg: 640x640 (no detections), 44.4ms\n",
      "Speed: 0.7ms preprocess, 44.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-543-_jpg.rf.e521748f6ab8083fb9705f92e1f4bf02.jpg: 640x640 1 person, 1 truck, 41.3ms\n",
      "Speed: 0.6ms preprocess, 41.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-276_jpg.rf.9dd339d208802462bc19a4f66967b3f7.jpg: 640x640 1 clock, 48.0ms\n",
      "Speed: 0.8ms preprocess, 48.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-1_jpg.rf.c93495dc1c470abfba67c34e2c21f695.jpg: 640x640 2 persons, 1 motorcycle, 44.1ms\n",
      "Speed: 0.7ms preprocess, 44.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-474_jpg.rf.a69f31210940425bb2099ce9f6683645.jpg: 640x640 1 person, 86.1ms\n",
      "Speed: 0.6ms preprocess, 86.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-639_jpg.rf.31820317a457e2ca8001577f46b6220e.jpg: 640x640 2 persons, 1 backpack, 1 banana, 2 cell phones, 54.9ms\n",
      "Speed: 0.7ms preprocess, 54.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0073_jpg.rf.405ba1048616d99ee5168b6affb4938e.jpg: 640x640 1 suitcase, 54.7ms\n",
      "Speed: 0.7ms preprocess, 54.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_187_jpg.rf.8d5940916dee2ba1633831c2b993ba0c.jpg: 640x640 6 persons, 49.4ms\n",
      "Speed: 0.7ms preprocess, 49.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class1_235_jpg.rf.c95e6d030c77585b441564c612b5ec8b.jpg: 640x640 2 persons, 1 car, 1 bus, 1 train, 1 truck, 48.1ms\n",
      "Speed: 0.7ms preprocess, 48.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-824_jpg.rf.66d684a9888bb29ffe83793dd2ed3528.jpg: 640x640 2 persons, 1 dog, 40.8ms\n",
      "Speed: 0.7ms preprocess, 40.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/135e-huxwryw6451820_jpg.rf.934c0f8f070cf99570b4fe46256e9c0f.jpg: 640x640 2 persons, 69.4ms\n",
      "Speed: 0.6ms preprocess, 69.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/004720_jpg.rf.38351f09d6df1004a9d6fccb2f1cdf5c.jpg: 640x640 2 persons, 1 train, 2 trucks, 38.4ms\n",
      "Speed: 0.6ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/amz_01638_png_jpg.rf.a5977d57aca5da492de5943c25631e3e.jpg: 640x640 6 persons, 1 banana, 40.2ms\n",
      "Speed: 0.7ms preprocess, 40.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-763-_jpg.rf.b1b2992eab87ad60c8b0cc6c71a42ee1.jpg: 640x640 1 truck, 1 boat, 1 bench, 1 chair, 60.1ms\n",
      "Speed: 0.6ms preprocess, 60.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-855-_jpg.rf.3631ade3b57ef3e8c3acd6104bfbd1e0.jpg: 640x640 1 motorcycle, 1 train, 1 truck, 46.8ms\n",
      "Speed: 0.8ms preprocess, 46.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-816-_jpg.rf.dcd3ed6a69a914c9f54050d3e07ca5a8.jpg: 640x640 3 persons, 1 truck, 45.5ms\n",
      "Speed: 0.7ms preprocess, 45.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-189_jpg.rf.dcbbd17d32c0e03130324482d02dbb50.jpg: 640x640 1 person, 42.3ms\n",
      "Speed: 0.6ms preprocess, 42.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_678_jpg.rf.5c07f3a8e380b2683312bb73284eb9ff.jpg: 640x640 1 truck, 45.4ms\n",
      "Speed: 0.6ms preprocess, 45.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-976-_jpg.rf.d44b0911fa5da0256efd02bb596ca62e.jpg: 640x640 2 persons, 2 trucks, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-60_jpg.rf.c71d352bf4375d6b743d9c58444d04d0.jpg: 640x640 2 persons, 63.8ms\n",
      "Speed: 0.6ms preprocess, 63.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-589_jpg.rf.3d7feeffd99331e03adfca8c51e5e325.jpg: 640x640 12 persons, 1 motorcycle, 48.4ms\n",
      "Speed: 0.7ms preprocess, 48.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-15_jpg.rf.71ec98f5b5e5d497c2de8d9edaf8c7b8.jpg: 640x640 3 persons, 1 car, 1 traffic light, 1 laptop, 40.3ms\n",
      "Speed: 0.7ms preprocess, 40.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-219_jpg.rf.0ad7ddf87079cf198c8d4c90fb679f49.jpg: 640x640 1 person, 57.3ms\n",
      "Speed: 0.7ms preprocess, 57.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/931_jpg.rf.56bbe894e27de1944e2f990573228e2f.jpg: 640x640 2 persons, 1 skateboard, 41.3ms\n",
      "Speed: 0.6ms preprocess, 41.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class1_253_jpg.rf.e8dbb66bc9377a3be293ce677b65c6e5.jpg: 640x640 4 persons, 1 truck, 62.3ms\n",
      "Speed: 0.7ms preprocess, 62.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005180_jpg.rf.765ddd4046b2ce2755fde8140f5009f1.jpg: 640x640 2 persons, 1 tie, 42.9ms\n",
      "Speed: 0.7ms preprocess, 42.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/01235_jpg.rf.5602858e3d72530c62b1d2f4c3e15770.jpg: 640x640 1 person, 40.1ms\n",
      "Speed: 0.6ms preprocess, 40.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (15).jpeg: 640x640 3 persons, 1 horse, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-486_jpg.rf.2054453ea6cb0f6e0d70231d298023b7.jpg: 640x640 1 person, 49.1ms\n",
      "Speed: 0.7ms preprocess, 49.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-618-_jpg.rf.b1c7243e9ca367424591231467dad5c1.jpg: 640x640 4 persons, 1 bus, 1 train, 1 keyboard, 62.1ms\n",
      "Speed: 0.7ms preprocess, 62.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_1037_jpg.rf.872488c3380b84757e8f117351a46005.jpg: 640x640 1 person, 43.8ms\n",
      "Speed: 0.6ms preprocess, 43.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1099-_jpg.rf.ca716ce58849931be359cfcebf24b0fc.jpg: 640x640 3 persons, 1 bus, 1 truck, 57.4ms\n",
      "Speed: 0.7ms preprocess, 57.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/006858_jpg.rf.f39d0c81a93d765d935f0f93295969d1.jpg: 640x640 3 persons, 2 wine glasss, 41.4ms\n",
      "Speed: 0.6ms preprocess, 41.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_743_jpg.rf.b82c9548b6bb067d207541efc1c80513.jpg: 640x640 1 person, 40.8ms\n",
      "Speed: 0.6ms preprocess, 40.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-135-_jpg.rf.42dfecd04d31bec9b04596d68fc2d01d.jpg: 640x640 1 person, 1 airplane, 1 truck, 43.8ms\n",
      "Speed: 0.7ms preprocess, 43.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-122_jpg.rf.0bf7d059fd927edf3286b16f9f4fc764.jpg: 640x640 1 person, 1 train, 1 truck, 74.1ms\n",
      "Speed: 1.0ms preprocess, 74.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_241_jpg.rf.179998a1907f7ec0efb31058dfadfcfc.jpg: 640x640 1 boat, 1 bench, 47.8ms\n",
      "Speed: 1.2ms preprocess, 47.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-708-_jpg.rf.4e32fc46ba7c1ce57833437ef93e6f77.jpg: 640x640 3 persons, 1 truck, 50.4ms\n",
      "Speed: 0.7ms preprocess, 50.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-848_jpg.rf.34557233fc8c0c4c14d113ac78c85283.jpg: 640x640 2 persons, 1 truck, 41.8ms\n",
      "Speed: 1.1ms preprocess, 41.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0873_MOV-10_jpg.rf.91649c04a7357b4b1a46325be873536b.jpg: 640x640 4 persons, 1 truck, 38.8ms\n",
      "Speed: 0.7ms preprocess, 38.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_7211_PNG_jpg.rf.436a55ef9789c8bcb84261a58c72fb3b.jpg: 640x640 8 surfboards, 1 chair, 1 potted plant, 1 vase, 58.3ms\n",
      "Speed: 0.7ms preprocess, 58.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-89_jpg.rf.7ad949dbe6175f71ce099daf5dce5b6e.jpg: 640x640 2 persons, 1 truck, 1 surfboard, 68.0ms\n",
      "Speed: 0.8ms preprocess, 68.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-3394-_png_jpg.rf.61441b8707107e91850cd9f576dd0ce8.jpg: 640x640 6 persons, 39.4ms\n",
      "Speed: 0.6ms preprocess, 39.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0629_jpg.rf.d95844bf887d9a486a3d5b4074edd25d.jpg: 640x640 3 persons, 1 tie, 42.8ms\n",
      "Speed: 0.6ms preprocess, 42.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-331-_jpg.rf.6a529020c79917955c43e5d7087b73dd.jpg: 640x640 2 persons, 1 bicycle, 1 truck, 1 boat, 52.9ms\n",
      "Speed: 0.6ms preprocess, 52.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-122_jpg.rf.63834f13775dce36318f7dea0ade6f66.jpg: 640x640 1 person, 4 cars, 1 truck, 43.4ms\n",
      "Speed: 0.6ms preprocess, 43.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005239_jpg.rf.20727bffc9c5afe39c9bfdddf3a4f222.jpg: 640x640 4 persons, 2 trains, 42.4ms\n",
      "Speed: 0.7ms preprocess, 42.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-0_jpg.rf.68984554e9decf5117f6fc2e2fb2d8b5.jpg: 640x640 1 person, 2 bicycles, 1 truck, 45.5ms\n",
      "Speed: 0.7ms preprocess, 45.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1029-_jpg.rf.e40ed9707d9ea79a66586b7eafe0ae52.jpg: 640x640 2 persons, 42.0ms\n",
      "Speed: 0.7ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_475_jpg.rf.f805d2b598de611f7fde3102264a8ba2.jpg: 640x640 2 persons, 1 cat, 54.5ms\n",
      "Speed: 0.6ms preprocess, 54.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-I1-MS09uaqsLdGTFkgnS0Rcg1mmPyAj95ySg_eckoM_jpeg_jpg.rf.ebf4adda36378f39ccb4a751d9c18183.jpg: 640x640 4 persons, 1 bottle, 1 toilet, 1 tv, 73.0ms\n",
      "Speed: 0.8ms preprocess, 73.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-5_jpg.rf.598cd5f251a2fbbf918368bf198c25cf.jpg: 640x640 2 persons, 1 bicycle, 1 train, 1 cat, 1 cow, 1 chair, 48.0ms\n",
      "Speed: 0.7ms preprocess, 48.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-395_jpg.rf.adc53c60bee577e3e1a70893ba7dfbdd.jpg: 640x640 3 persons, 5 surfboards, 39.7ms\n",
      "Speed: 0.6ms preprocess, 39.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-5_jpg.rf.ccef0f78d59cded299511b43a1b899cc.jpg: 640x640 1 person, 45.8ms\n",
      "Speed: 0.6ms preprocess, 45.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-0_jpg.rf.4abdea6d3496fff646d9cb9abdee22d8.jpg: 640x640 4 persons, 1 potted plant, 40.5ms\n",
      "Speed: 0.7ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-347-_jpg.rf.93d15a4e3702fc5d9284d9f1cabb832c.jpg: 640x640 1 truck, 1 horse, 51.3ms\n",
      "Speed: 0.6ms preprocess, 51.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-182_jpg.rf.627a7713bb1819c97760a93546151040.jpg: 640x640 5 persons, 1 truck, 74.6ms\n",
      "Speed: 0.7ms preprocess, 74.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-46_jpg.rf.02aaecb5779de6b8bd1dde4d0de11cd9.jpg: 640x640 1 person, 1 bicycle, 1 clock, 61.9ms\n",
      "Speed: 0.7ms preprocess, 61.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005773_jpg.rf.db74cb55673015df5c01266d0965c1e0.jpg: 640x640 (no detections), 45.7ms\n",
      "Speed: 2.3ms preprocess, 45.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-334_jpg.rf.650a058b0c97ae4b3a7dc3e91555bdbc.jpg: 640x640 1 person, 1 truck, 40.8ms\n",
      "Speed: 0.8ms preprocess, 40.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_337_jpg.rf.384b81a87dd39579a75d705d9870d88a.jpg: 640x640 3 persons, 46.5ms\n",
      "Speed: 0.7ms preprocess, 46.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.e65c339a3dc986701e765116332dba2d.jpg: 640x640 4 persons, 53.6ms\n",
      "Speed: 0.7ms preprocess, 53.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-844-_jpg.rf.a7627602fbf3ea6d5ca64bc7782706ff.jpg: 640x640 1 train, 1 traffic light, 71.9ms\n",
      "Speed: 0.6ms preprocess, 71.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-849_jpg.rf.cdf29746fafb9adf4faa0db8deb66e54.jpg: 640x640 4 persons, 1 train, 44.3ms\n",
      "Speed: 0.7ms preprocess, 44.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/amz_01638_png_jpg.rf.2d3765b15e87cfb801569c6c91fba87a.jpg: 640x640 1 person, 47.1ms\n",
      "Speed: 0.6ms preprocess, 47.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_1006_jpg.rf.4b9023dd190b5e5fe196969df1040761.jpg: 640x640 1 person, 1 bird, 59.0ms\n",
      "Speed: 0.6ms preprocess, 59.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-618_jpg.rf.fb80997b1ffbc44d3e874418c1750e3c.jpg: 640x640 10 persons, 3 surfboards, 45.7ms\n",
      "Speed: 0.7ms preprocess, 45.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/MariusConePic60_png_jpg.rf.327ac75b6e428a917d61ca056e4be99a.jpg: 640x640 1 bottle, 45.0ms\n",
      "Speed: 0.6ms preprocess, 45.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005100_jpg.rf.11d7bd86fe6608dc8ca416382c74d469.jpg: 640x640 3 persons, 60.7ms\n",
      "Speed: 0.8ms preprocess, 60.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/60_jpg.rf.1f7012c2b0ee548df03ff592fe324835.jpg: 640x640 2 persons, 49.7ms\n",
      "Speed: 0.7ms preprocess, 49.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-492_jpg.rf.86e61eaaffcdff5e4a71394055a3d967.jpg: 640x640 7 persons, 1 frisbee, 63.5ms\n",
      "Speed: 0.7ms preprocess, 63.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_181_jpg.rf.c47ea3350fd6f06b42b3fad1db2c2512.jpg: 640x640 2 persons, 2 trucks, 50.4ms\n",
      "Speed: 1.3ms preprocess, 50.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-753-_jpg.rf.79c6f65288af95c6a5d4c2b1d2b263d8.jpg: 640x640 1 person, 1 train, 2 trucks, 48.0ms\n",
      "Speed: 0.8ms preprocess, 48.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1050-_jpg.rf.6906df9b82b1cfb9a06fe3fa8aa1ad3f.jpg: 640x640 (no detections), 65.6ms\n",
      "Speed: 0.8ms preprocess, 65.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_435_jpg.rf.acd9bfe83c9ddd61febf6b792d8d074a.jpg: 640x640 2 persons, 1 truck, 1 suitcase, 1 potted plant, 54.2ms\n",
      "Speed: 0.7ms preprocess, 54.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-213_jpg.rf.db5dce09a34596f043d005b316590eaf.jpg: 640x640 1 person, 1 toilet, 48.0ms\n",
      "Speed: 0.9ms preprocess, 48.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-15_jpg.rf.f9df1006248df05f97c270dcd1620bec.jpg: 640x640 3 persons, 5 bottles, 1 cell phone, 48.5ms\n",
      "Speed: 0.7ms preprocess, 48.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_004148_jpg.rf.15237e8ab0bab257f48c8e0b97afeb71.jpg: 640x640 5 persons, 1 truck, 1 laptop, 83.5ms\n",
      "Speed: 0.8ms preprocess, 83.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_861_jpg.rf.084188e53e8f57c52d982c7a064afda9.jpg: 640x640 1 horse, 46.3ms\n",
      "Speed: 0.7ms preprocess, 46.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-362_jpg.rf.fe798d76b8ab678f3d86dae831b2e09a.jpg: 640x640 6 persons, 50.2ms\n",
      "Speed: 0.7ms preprocess, 50.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1062-_jpg.rf.bb9d74532f809eda6343cb0f354fc269.jpg: 640x640 1 person, 1 bird, 1 potted plant, 1 book, 50.2ms\n",
      "Speed: 0.7ms preprocess, 50.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-64_jpg.rf.333df47a2727bb154654857a9b997445.jpg: 640x640 (no detections), 62.0ms\n",
      "Speed: 0.7ms preprocess, 62.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-999-_jpg.rf.c301fa8a4124813f3e5c544505322f37.jpg: 640x640 2 persons, 42.6ms\n",
      "Speed: 0.7ms preprocess, 42.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/hqdefault_jpg.rf.15058891e8e34cb59338ac40e7c1ba67.jpg: 640x640 2 persons, 54.5ms\n",
      "Speed: 0.8ms preprocess, 54.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-175_jpg.rf.43dd4680523315f10c35983495275887.jpg: 640x640 1 person, 51.0ms\n",
      "Speed: 0.7ms preprocess, 51.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005139_jpg.rf.b51d392a15c3ca4943cfe750427ceb97.jpg: 640x640 2 persons, 1 car, 52.7ms\n",
      "Speed: 0.8ms preprocess, 52.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-23_jpg.rf.111461b3bc308932167364e329194edd.jpg: 640x640 2 persons, 1 truck, 82.9ms\n",
      "Speed: 0.7ms preprocess, 82.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/001425_jpg.rf.02937146b9b48ec81a3c3cf7f0d4d50e.jpg: 640x640 4 persons, 1 horse, 1 bottle, 40.8ms\n",
      "Speed: 0.6ms preprocess, 40.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox6_mp4-157_jpg.rf.b63cdf38ad7d4f47f511babad4ea2458.jpg: 640x640 2 persons, 1 chair, 1 dining table, 41.6ms\n",
      "Speed: 0.6ms preprocess, 41.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/amz_02354_png_jpg.rf.6f192e3fc3461a07887582a6e44fd46e.jpg: 640x640 2 persons, 62.7ms\n",
      "Speed: 1.0ms preprocess, 62.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/fnacc_corridor_jpg.rf.9ee7350e3805120d251c4de5a7756848.jpg: 640x640 2 trucks, 48.6ms\n",
      "Speed: 0.7ms preprocess, 48.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008618_jpg.rf.08333b53ff8de881498a70bac2f1cec6.jpg: 640x640 7 persons, 1 train, 51.6ms\n",
      "Speed: 0.9ms preprocess, 51.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/002682_jpg.rf.29171c747ef34470238dd52b997917d8.jpg: 640x640 4 persons, 52.9ms\n",
      "Speed: 0.7ms preprocess, 52.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-185_jpg.rf.46455ef8e0ac8459810c8de85ba27787.jpg: 640x640 1 person, 1 car, 2 boats, 1 clock, 49.9ms\n",
      "Speed: 0.8ms preprocess, 49.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-211_jpg.rf.a59e7bd9c031f0128fdde8485a5031f3.jpg: 640x640 4 persons, 2 trucks, 44.8ms\n",
      "Speed: 0.8ms preprocess, 44.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-547-_jpg.rf.c52e164f4ba0cb32256dab37ae4ac8c6.jpg: 640x640 1 person, 1 bus, 1 truck, 1 cow, 39.0ms\n",
      "Speed: 0.6ms preprocess, 39.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/amz_02354_png_jpg.rf.d74fcc68ca92923700f106656525292d.jpg: 640x640 1 person, 2 trucks, 71.4ms\n",
      "Speed: 0.7ms preprocess, 71.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ins30_jpg.rf.7f166adf69fa78d310884393216ef467.jpg: 640x640 1 truck, 91.6ms\n",
      "Speed: 1.6ms preprocess, 91.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_337_jpg.rf.ca3aa462235185a1d309798f889f14fa.jpg: 640x640 (no detections), 52.8ms\n",
      "Speed: 0.8ms preprocess, 52.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-370_jpg.rf.d22c6ad3835da982aee0a6cb60964a67.jpg: 640x640 5 persons, 1 truck, 49.4ms\n",
      "Speed: 0.8ms preprocess, 49.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-196_jpg.rf.949f50bfd27d739dbbab25d266456419.jpg: 640x640 5 persons, 1 car, 55.2ms\n",
      "Speed: 0.7ms preprocess, 55.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-15_jpg.rf.d7e8a84fc7e9d53fe348320ea3af0e94.jpg: 640x640 6 persons, 46.1ms\n",
      "Speed: 1.0ms preprocess, 46.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/istockphoto-1215866584-612x612.jpg: 448x640 1 person, 31.3ms\n",
      "Speed: 1.0ms preprocess, 31.3ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-855-_jpg.rf.18c0a338f56e727083633e5dcae2aed8.jpg: 640x640 5 cars, 1 motorcycle, 1 truck, 43.3ms\n",
      "Speed: 0.7ms preprocess, 43.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/maksssksksss710_png_jpg.rf.faeb1cc9ddc4e6c506648fc7324f54d0.jpg: 640x640 2 persons, 67.3ms\n",
      "Speed: 0.7ms preprocess, 67.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/YouTube_FreeStockFootage_People-wearing-face-mask_Empty-Street_Covid19-D_DbgrvhlGs-720p_mp4-11_jpg.rf.d3cdda5a6cc03c53f501c541ce35f055.jpg: 640x640 5 persons, 55.3ms\n",
      "Speed: 0.7ms preprocess, 55.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-855_jpg.rf.ca4e205a81e38caeee1ae4bfce760904.jpg: 640x640 1 person, 1 car, 2 trucks, 42.3ms\n",
      "Speed: 0.6ms preprocess, 42.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class1_199_jpg.rf.7470f7f5a9af05a8cab23a126ab247b1.jpg: 640x640 2 persons, 1 airplane, 1 truck, 1 chair, 41.2ms\n",
      "Speed: 0.7ms preprocess, 41.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-726_jpg.rf.08f436dcdaeb181b4fc17028d60c2c3c.jpg: 640x640 2 trucks, 44.8ms\n",
      "Speed: 0.6ms preprocess, 44.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-148_jpg.rf.07346a7ecc8e3fe6a1d39371f416e540.jpg: 640x640 1 person, 1 truck, 66.6ms\n",
      "Speed: 0.6ms preprocess, 66.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005773_jpg.rf.f74645690452329b76e09a3fe0a26735.jpg: 640x640 1 car, 1 truck, 1 traffic light, 44.5ms\n",
      "Speed: 0.7ms preprocess, 44.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-829_jpg.rf.8a28fd44dfc3d1e6af171a7958a4aec1.jpg: 640x640 1 person, 1 toilet, 42.4ms\n",
      "Speed: 1.1ms preprocess, 42.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0629_jpg.rf.5b22ac96e5d13708ad0d3c760684ed67.jpg: 640x640 3 persons, 1 tie, 1 bed, 45.6ms\n",
      "Speed: 16.6ms preprocess, 45.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-550_jpg.rf.ca2b4e9e24ac87d20d6223ac8785b650.jpg: 640x640 3 persons, 79.6ms\n",
      "Speed: 0.8ms preprocess, 79.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-684-_jpg.rf.f7633094313d336503445e977c4b4813.jpg: 640x640 2 persons, 1 truck, 1 boat, 45.0ms\n",
      "Speed: 0.7ms preprocess, 45.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-457_jpg.rf.2d689c0133ef87350ad8b8896690328a.jpg: 640x640 4 persons, 1 truck, 2 chairs, 1 tv, 44.8ms\n",
      "Speed: 0.6ms preprocess, 44.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008593_jpg.rf.d56866006a516df1e61df4c19d11e159.jpg: 640x640 5 persons, 44.9ms\n",
      "Speed: 0.7ms preprocess, 44.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-731-_jpg.rf.2f78a9cbfcccb40f0d51d6761963e2f7.jpg: 640x640 1 person, 1 truck, 6 books, 41.4ms\n",
      "Speed: 0.7ms preprocess, 41.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-564_jpg.rf.e8df3780028df1e34ca0aa9d40a87fb0.jpg: 640x640 2 persons, 116.1ms\n",
      "Speed: 0.7ms preprocess, 116.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-242_jpg.rf.6c65ab2da2b0600445f732397b6be671.jpg: 640x640 2 persons, 1 train, 1 truck, 44.1ms\n",
      "Speed: 0.7ms preprocess, 44.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-221_jpg.rf.3a2b829e17c5030726fbd51e28c02aed.jpg: 640x640 1 person, 1 truck, 1 boat, 50.9ms\n",
      "Speed: 0.7ms preprocess, 50.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/n190039_jpg.rf.b9a89f85281fec158031a656b666c415.jpg: 640x640 2 persons, 2 cars, 54.1ms\n",
      "Speed: 0.8ms preprocess, 54.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_221_jpg.rf.ae016b16cd940612fcf0454f1fe5d4a9.jpg: 640x640 2 persons, 41.9ms\n",
      "Speed: 0.6ms preprocess, 41.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-246-_jpg.rf.fd9bfe8b6726e60a3a00b7f7b03cb7e8.jpg: 640x640 1 truck, 1 couch, 1 tv, 44.8ms\n",
      "Speed: 0.6ms preprocess, 44.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-94_jpg.rf.ed816f287bc4996348f474833197cdc0.jpg: 640x640 (no detections), 66.5ms\n",
      "Speed: 0.6ms preprocess, 66.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/n190039_jpg.rf.88627d9e82a53fef7f6c11b7029faeaf.jpg: 640x640 3 persons, 1 bottle, 43.4ms\n",
      "Speed: 0.7ms preprocess, 43.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5850_jpg.rf.03ab0fe3cfb17b8bab4c149542d6b970.jpg: 640x640 5 persons, 1 truck, 46.8ms\n",
      "Speed: 0.7ms preprocess, 46.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_624_jpg.rf.99accd60d948add0df3d2eec557e237e.jpg: 640x640 2 persons, 1 tie, 49.4ms\n",
      "Speed: 0.7ms preprocess, 49.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-252_jpg.rf.f09f4003bd7b1bbc60be3e7a3a7b5568.jpg: 640x640 3 trucks, 50.6ms\n",
      "Speed: 0.8ms preprocess, 50.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-268-_jpg.rf.221b4a2ffc9ea512bdf6545a32a9ff33.jpg: 640x640 4 persons, 1 traffic light, 1 potted plant, 54.9ms\n",
      "Speed: 0.7ms preprocess, 54.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-434-_jpg.rf.0da1846417898f4705b991db5ddf9892.jpg: 640x640 4 persons, 65.4ms\n",
      "Speed: 0.7ms preprocess, 65.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-253-_jpg.rf.7db6b21086f397355d9373f0d575e148.jpg: 640x640 2 persons, 1 train, 1 truck, 42.3ms\n",
      "Speed: 0.7ms preprocess, 42.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_16_jpg.rf.a3f1d05e403a63ada89669d9b61a1276.jpg: 640x640 3 persons, 1 bicycle, 1 traffic light, 1 skateboard, 40.5ms\n",
      "Speed: 0.6ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-246-_jpg.rf.b85e00bf930ece1924a70d0b5b408a75.jpg: 640x640 1 person, 1 bus, 1 train, 1 truck, 44.0ms\n",
      "Speed: 0.7ms preprocess, 44.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/277_jpg.rf.1f9c34c877f19f92f71b8325c99b89a5.jpg: 640x640 2 persons, 1 car, 1 truck, 69.6ms\n",
      "Speed: 0.7ms preprocess, 69.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-564_jpg.rf.bb1e1e7b8cbbf050ca00be0128f428cc.jpg: 640x640 5 persons, 41.6ms\n",
      "Speed: 0.7ms preprocess, 41.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-197_jpg.rf.84e48afd1eb2f504aecfb6456a196950.jpg: 640x640 (no detections), 40.4ms\n",
      "Speed: 0.6ms preprocess, 40.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/494_jpg.rf.10fc39826f79a214ec850d3adb62bf81.jpg: 640x640 2 persons, 1 bicycle, 63.9ms\n",
      "Speed: 0.7ms preprocess, 63.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_004148_jpg.rf.5a40d87b1f2f75213b65d0b6d3cc9ee1.jpg: 640x640 3 persons, 46.7ms\n",
      "Speed: 1.1ms preprocess, 46.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/fnacc_corridor_jpg.rf.9650bd5f5ec69e22870d64a7e5d6452b.jpg: 640x640 2 persons, 2 trucks, 45.4ms\n",
      "Speed: 0.6ms preprocess, 45.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-11_jpg.rf.c1348fe207a4162c9fd2025869a0d744.jpg: 640x640 1 truck, 1 bed, 44.7ms\n",
      "Speed: 0.6ms preprocess, 44.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_7211_PNG_jpg.rf.6114b3b603b72886bde2507762ffb713.jpg: 640x640 1 person, 1 truck, 46.1ms\n",
      "Speed: 0.7ms preprocess, 46.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-622_jpg.rf.227bf75c5b7e51d3208d32dd248f83f7.jpg: 640x640 1 person, 43.1ms\n",
      "Speed: 0.7ms preprocess, 43.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_818_jpg.rf.d8b4fb6e814eaadb784c7ceeda8fcfe8.jpg: 640x640 7 persons, 67.9ms\n",
      "Speed: 0.7ms preprocess, 67.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_95_jpg.rf.01a4e40a282db6f049ac60156a611923.jpg: 640x640 1 person, 45.7ms\n",
      "Speed: 0.7ms preprocess, 45.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_861_jpg.rf.669a2ef10b751ba8851bde01c22a5632.jpg: 640x640 4 persons, 2 birds, 1 dog, 1 baseball glove, 54.0ms\n",
      "Speed: 0.6ms preprocess, 54.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/p65621379_jpg.rf.d0149504b7cfc4bdaa4fceb5a54f7a9e.jpg: 640x640 6 persons, 41.3ms\n",
      "Speed: 0.7ms preprocess, 41.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0449_jpg.rf.35c19793e0cb4175859e5ad6831d2fce.jpg: 640x640 1 truck, 51.9ms\n",
      "Speed: 0.6ms preprocess, 51.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-23_jpg.rf.56e52a54a8316188c2a9584db9f40143.jpg: 640x640 1 car, 1 motorcycle, 2 trucks, 46.6ms\n",
      "Speed: 0.7ms preprocess, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008652_jpg.rf.abbfd744196d5826bb402880b9124526.jpg: 640x640 2 potted plants, 1 book, 2 vases, 44.7ms\n",
      "Speed: 0.7ms preprocess, 44.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_435_jpg.rf.937d1472b0bb03a48c1e2766b20fd283.jpg: 640x640 2 persons, 1 car, 1 fire hydrant, 1 surfboard, 45.3ms\n",
      "Speed: 0.7ms preprocess, 45.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_757_jpg.rf.77d2e9e137cb91349fad23f3bb976007.jpg: 640x640 2 persons, 1 train, 2 ties, 47.9ms\n",
      "Speed: 0.7ms preprocess, 47.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mask-wearing-1632933572733_png_jpg.rf.ef7fc5df6b537c8c859bd7a0e4524a7d.jpg: 640x640 3 persons, 66.4ms\n",
      "Speed: 0.6ms preprocess, 66.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_302_jpg.rf.fbd0288a0615f960d0513bd83714fde1.jpg: 640x640 2 cars, 56.5ms\n",
      "Speed: 0.7ms preprocess, 56.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/329_jpg.rf.1f99013be8407ede7c9df84d93b6a700.jpg: 640x640 3 persons, 44.7ms\n",
      "Speed: 0.8ms preprocess, 44.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-10_jpg.rf.9aa13660a190b7e065d7af4ffe14241b.jpg: 640x640 4 persons, 1 bird, 40.9ms\n",
      "Speed: 0.6ms preprocess, 40.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008337_jpg.rf.74e6e11733218da0128165788cc3d7bb.jpg: 640x640 1 person, 1 bicycle, 1 truck, 40.6ms\n",
      "Speed: 0.7ms preprocess, 40.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-25_jpg.rf.0a21e9e91348b61c6c1483d6884d2135.jpg: 640x640 2 persons, 5 trucks, 1 cell phone, 44.6ms\n",
      "Speed: 0.8ms preprocess, 44.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-684-_jpg.rf.7963a972eb4b888dcd876e0b10c824e6.jpg: 640x640 5 persons, 1 car, 1 truck, 52.1ms\n",
      "Speed: 0.7ms preprocess, 52.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2252-_png_jpg.rf.5d2ba68a39912deb9e4383661418224f.jpg: 640x640 5 persons, 1 tie, 1 book, 69.7ms\n",
      "Speed: 0.7ms preprocess, 69.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-17_jpg.rf.5cb34f635f907bb8dd64d8143522c94a.jpg: 640x640 1 person, 1 boat, 1 traffic light, 1 dog, 44.3ms\n",
      "Speed: 1.7ms preprocess, 44.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-395_jpg.rf.c96f418ca6745816e4d204d36453f59f.jpg: 640x640 2 cars, 1 train, 2 trucks, 1 surfboard, 62.4ms\n",
      "Speed: 0.8ms preprocess, 62.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-499_jpg.rf.e4dcff7127244607c7c6915495d3aa6f.jpg: 640x640 3 persons, 40.9ms\n",
      "Speed: 0.7ms preprocess, 40.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_187_jpg.rf.0d7353521d2c44ca566a10f336cf67d4.jpg: 640x640 3 persons, 39.4ms\n",
      "Speed: 0.6ms preprocess, 39.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-254_jpg.rf.511e3d5737b7272af3965f5ddfe4ac25.jpg: 640x640 1 truck, 1 kite, 50.2ms\n",
      "Speed: 0.6ms preprocess, 50.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_158_jpg.rf.0de7df666b9a2c4e63baada2bf7a6c4f.jpg: 640x640 1 person, 1 suitcase, 1 refrigerator, 41.8ms\n",
      "Speed: 0.7ms preprocess, 41.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-127_jpg.rf.022b78f3bcdb6aeba49e4d1e9605233e.jpg: 640x640 3 trucks, 2 surfboards, 42.3ms\n",
      "Speed: 0.6ms preprocess, 42.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-38_jpg.rf.731a7f476aa82dc019b3d59f977c11cb.jpg: 640x640 2 persons, 1 car, 1 truck, 1 fire hydrant, 1 bottle, 62.5ms\n",
      "Speed: 2.6ms preprocess, 62.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-1670-_png_jpg.rf.dd5cb0a4d6da02d34f1dc003fb4ebca6.jpg: 640x640 3 persons, 1 traffic light, 1 tennis racket, 50.1ms\n",
      "Speed: 1.0ms preprocess, 50.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-79_jpg.rf.c1ef8cde2ddaef68e79e186a1623c813.jpg: 640x640 1 person, 44.2ms\n",
      "Speed: 0.7ms preprocess, 44.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-844-_jpg.rf.c183c41efcdbea3de1c46ea27a41887a.jpg: 640x640 1 truck, 51.6ms\n",
      "Speed: 1.2ms preprocess, 51.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/006012_jpg.rf.eb12c4a250f91e1f6efb9781b2c78604.jpg: 640x640 3 persons, 50.2ms\n",
      "Speed: 0.7ms preprocess, 50.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-60_jpg.rf.0ac7cc2f1ec94df3110191b40c42d32d.jpg: 640x640 5 persons, 1 truck, 43.6ms\n",
      "Speed: 0.6ms preprocess, 43.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/727_jpg.rf.50453fc49894c5dab11c12563b61938b.jpg: 640x640 1 car, 1 bus, 2 trucks, 1 traffic light, 41.7ms\n",
      "Speed: 0.6ms preprocess, 41.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-9_jpg.rf.77e3475fc101643c603dd270881c431a.jpg: 640x640 2 persons, 1 bus, 1 train, 1 truck, 1 cow, 1 elephant, 42.6ms\n",
      "Speed: 0.6ms preprocess, 42.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_7211_PNG_jpg.rf.53137660a8abb36a2036583aebaccc01.jpg: 640x640 4 persons, 50.0ms\n",
      "Speed: 0.7ms preprocess, 50.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-17_jpg.rf.8fbd72f033989d9c7665a5e28a8fd2d4.jpg: 640x640 5 persons, 1 train, 1 truck, 1 dog, 39.4ms\n",
      "Speed: 0.6ms preprocess, 39.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-I1-MS09uaqsLdGTFkgnS0Rcg1mmPyAj95ySg_eckoM_jpeg_jpg.rf.fb09ca92aa0016318337101cb73199ae.jpg: 640x640 3 persons, 1 truck, 41.4ms\n",
      "Speed: 0.7ms preprocess, 41.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-235_jpg.rf.f06d5cefa3f6f6b1ca0b4f707b71f016.jpg: 640x640 1 person, 1 truck, 55.4ms\n",
      "Speed: 0.7ms preprocess, 55.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/01437_jpg.rf.f33846f08de75ae3d897f2902747c725.jpg: 640x640 3 persons, 1 bottle, 50.7ms\n",
      "Speed: 0.6ms preprocess, 50.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Libreria_09_20_altavista_jpg.rf.d79257bf1899bfd0f07a2851670fc455.jpg: 640x640 2 persons, 2 refrigerators, 5 books, 45.6ms\n",
      "Speed: 0.7ms preprocess, 45.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Mask2_mov-44_jpg.rf.efe33691399bb1db064665e6f1d61bc1.jpg: 640x640 2 persons, 1 dining table, 43.0ms\n",
      "Speed: 0.6ms preprocess, 43.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-42_jpg.rf.ea069358ab213d776e9e9fb675dd9493.jpg: 640x640 4 persons, 3 trains, 72.6ms\n",
      "Speed: 0.7ms preprocess, 72.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-234_jpg.rf.d98b2edbf5883bd854d4bdd4b9427b6a.jpg: 640x640 2 persons, 1 toothbrush, 39.2ms\n",
      "Speed: 0.7ms preprocess, 39.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-14_jpg.rf.4249d6aee12719fea3c83506c8ccdaa3.jpg: 640x640 2 persons, 1 motorcycle, 40.5ms\n",
      "Speed: 0.6ms preprocess, 40.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-507_jpg.rf.a859758779df04ea778068a73b402d3c.jpg: 640x640 3 persons, 1 tv, 48.9ms\n",
      "Speed: 1.9ms preprocess, 48.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-13_jpg.rf.bdcb46ab993ee2815a07132eda834c6a.jpg: 640x640 1 person, 1 car, 1 truck, 1 bottle, 53.4ms\n",
      "Speed: 0.7ms preprocess, 53.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-710_jpg.rf.a632153f709e275551380bd68e23dc55.jpg: 640x640 7 persons, 3 trucks, 39.2ms\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-0_jpg.rf.11d5df8c120c11a75e9f69a06f8fff16.jpg: 640x640 2 persons, 41.9ms\n",
      "Speed: 0.6ms preprocess, 41.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-560_jpg.rf.2f8d44461cd667c44659a5751d05bd04.jpg: 640x640 4 persons, 80.3ms\n",
      "Speed: 0.7ms preprocess, 80.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_39_jpg.rf.ede6d4b674c4f2034325cd0fdbcb2dbd.jpg: 640x640 1 person, 2 toothbrushs, 43.2ms\n",
      "Speed: 0.7ms preprocess, 43.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-332_jpg.rf.381a86d4a7e17d896fb3923599b89b4a.jpg: 640x640 2 persons, 1 wine glass, 49.7ms\n",
      "Speed: 0.6ms preprocess, 49.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-268-_jpg.rf.aa82a588d7af1763c37ec1570a2d218c.jpg: 640x640 1 person, 1 truck, 1 clock, 41.1ms\n",
      "Speed: 2.8ms preprocess, 41.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_23_jpg.rf.8d8c02a91212d9c1f43fcae6d17defe0.jpg: 640x640 1 person, 2 cars, 40.9ms\n",
      "Speed: 0.6ms preprocess, 40.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_743_jpg.rf.816375116a2ff7c77fecebf9206daf94.jpg: 640x640 2 persons, 1 train, 54.1ms\n",
      "Speed: 0.6ms preprocess, 54.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mask-wearing-1632933572733_png_jpg.rf.ade0dc53cbb1070b9623428cd6d4ce74.jpg: 640x640 1 person, 3 chairs, 1 vase, 50.4ms\n",
      "Speed: 0.7ms preprocess, 50.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox4_mp4-112_jpg.rf.dfb0c2b0da41e5c1cc6287d06ee92aea.jpg: 640x640 3 persons, 1 motorcycle, 1 truck, 1 surfboard, 1 couch, 1 bed, 67.7ms\n",
      "Speed: 0.6ms preprocess, 67.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-646_jpg.rf.527616d746832ff14fc3555475685d1f.jpg: 640x640 1 person, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-423_jpg.rf.edc550e0423567c04fede8578fedb011.jpg: 640x640 1 person, 1 truck, 54.3ms\n",
      "Speed: 0.7ms preprocess, 54.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2_jpg.rf.7baa8d1dade31fde5df99a239a274fab.jpg: 640x640 1 person, 49.5ms\n",
      "Speed: 0.8ms preprocess, 49.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/494_jpg.rf.9528435ded55bbe6bae4d2f3d478ca71.jpg: 640x640 2 persons, 2 trains, 49.0ms\n",
      "Speed: 0.7ms preprocess, 49.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-474_jpg.rf.5a19e0cfc81b8d82788a127768e8e354.jpg: 640x640 2 persons, 1 truck, 48.5ms\n",
      "Speed: 0.7ms preprocess, 48.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-684-_jpg.rf.d3a58971b9265ab6b677dba5f86593e3.jpg: 640x640 3 persons, 1 bicycle, 1 toilet, 2 laptops, 63.2ms\n",
      "Speed: 0.7ms preprocess, 63.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-897-_jpg.rf.71a3bca2df2ced388a3e28c47d6b85e7.jpg: 640x640 1 person, 1 motorcycle, 41.4ms\n",
      "Speed: 0.7ms preprocess, 41.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-15_jpg.rf.94d743aaa79935634d2cc4ea6a5bfe2c.jpg: 640x640 5 persons, 1 train, 43.6ms\n",
      "Speed: 0.7ms preprocess, 43.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-486_jpg.rf.a9d7cf6adc01f16228d02abd8c30bcf7.jpg: 640x640 1 truck, 68.0ms\n",
      "Speed: 0.7ms preprocess, 68.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-136_jpg.rf.3f565846fbd70422e73d09aab8c2c2b4.jpg: 640x640 1 person, 1 car, 1 truck, 46.1ms\n",
      "Speed: 0.8ms preprocess, 46.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-855_jpg.rf.8423bd3eccf6197cf223448ef5dba5bc.jpg: 640x640 3 persons, 50.6ms\n",
      "Speed: 0.6ms preprocess, 50.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-705-_jpg.rf.66d284e6c56937450749bb6f49c89001.jpg: 640x640 2 persons, 1 truck, 1 traffic light, 54.9ms\n",
      "Speed: 0.8ms preprocess, 54.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_1004_jpg.rf.454a08efbc20e72021db91669b18690e.jpg: 640x640 4 persons, 2 cars, 1 clock, 48.3ms\n",
      "Speed: 0.7ms preprocess, 48.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-69_jpg.rf.bf00d48267e40f1a03889865671ecba0.jpg: 640x640 3 persons, 1 baseball bat, 58.0ms\n",
      "Speed: 0.7ms preprocess, 58.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/img_038_jpg.rf.f2b56508a79bfcc1b83e3b1a54d40696.jpg: 640x640 3 persons, 1 backpack, 44.7ms\n",
      "Speed: 0.7ms preprocess, 44.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/598_jpg.rf.41202d61b1f20d12b9539e39f77df32c.jpg: 640x640 1 person, 1 chair, 39.8ms\n",
      "Speed: 0.7ms preprocess, 39.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2_jpg.rf.2eba3dc769a0689dda8f6eb3fdbd297e.jpg: 640x640 3 persons, 39.2ms\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-25_jpg.rf.6cee1b67a21808fad2318593379f9986.jpg: 640x640 1 person, 69.7ms\n",
      "Speed: 0.6ms preprocess, 69.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-64_jpg.rf.ee045f5e9670d7422490492b71801bac.jpg: 640x640 3 persons, 51.4ms\n",
      "Speed: 0.7ms preprocess, 51.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-574_jpg.rf.7c5c0939b72ebede4176b05f7443bc7c.jpg: 640x640 1 person, 47.7ms\n",
      "Speed: 0.7ms preprocess, 47.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_221_jpg.rf.ea323c63ed077f960309350f17478702.jpg: 640x640 2 persons, 2 cars, 1 clock, 42.0ms\n",
      "Speed: 0.6ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-622_jpg.rf.5cedb2fa20d0d25a6d0d775bdd1e09e2.jpg: 640x640 3 persons, 2 trucks, 72.9ms\n",
      "Speed: 0.8ms preprocess, 72.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-986-_jpg.rf.3ecb527ce78e89716a17826e5d05f682.jpg: 640x640 1 surfboard, 2 chairs, 1 dining table, 42.7ms\n",
      "Speed: 0.7ms preprocess, 42.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/helmet999863_jpg.rf.d7ca5e7209a0eaeb5d36d2b4a3f5e188.jpg: 640x640 1 person, 1 bus, 1 fire hydrant, 1 teddy bear, 43.7ms\n",
      "Speed: 0.7ms preprocess, 43.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-860-_jpg.rf.94811593888a6691da4f58ff3b7c7175.jpg: 640x640 3 persons, 2 cars, 1 airplane, 1 truck, 1 boat, 45.6ms\n",
      "Speed: 0.7ms preprocess, 45.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_647_jpg.rf.b5c65ea5f3f2326ad2beb751e0b72c04.jpg: 640x640 2 persons, 1 truck, 64.8ms\n",
      "Speed: 0.7ms preprocess, 64.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-13_jpg.rf.fd0d4d31a0ee44fc143df432649051fd.jpg: 640x640 1 person, 1 truck, 39.8ms\n",
      "Speed: 0.7ms preprocess, 39.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_000280_jpg.rf.c0c50e450c51eaea4420ea8611432a27.jpg: 640x640 2 persons, 1 car, 1 traffic light, 46.7ms\n",
      "Speed: 0.6ms preprocess, 46.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/006012_jpg.rf.2300bacf07c885b49cd596a85e5adda3.jpg: 640x640 3 persons, 49.6ms\n",
      "Speed: 0.7ms preprocess, 49.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-554_jpg.rf.5c89ae763397c5f2ccb61e63df485cb0.jpg: 640x640 3 persons, 1 chair, 57.3ms\n",
      "Speed: 0.7ms preprocess, 57.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/hqdefault_jpg.rf.9c0863c96b57eb241f4ad482dd6a545d.jpg: 640x640 1 person, 1 truck, 47.6ms\n",
      "Speed: 0.6ms preprocess, 47.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (10).jpeg: 448x640 2 persons, 34.8ms\n",
      "Speed: 0.8ms preprocess, 34.8ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-435_jpg.rf.cbe965d635b486b4ad5d720d81660470.jpg: 640x640 2 persons, 52.0ms\n",
      "Speed: 0.6ms preprocess, 52.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-0_jpg.rf.a3872a120d08419183f618c1ba5e7b48.jpg: 640x640 3 persons, 1 chair, 43.0ms\n",
      "Speed: 0.7ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-362_jpg.rf.1b5f38731953d7d7673c9329e7dcaae8.jpg: 640x640 3 persons, 1 toothbrush, 39.2ms\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (35).jpeg: 320x640 7 persons, 1 fire hydrant, 2 horses, 1 potted plant, 25.2ms\n",
      "Speed: 0.5ms preprocess, 25.2ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-668_jpg.rf.72295ead27a2932c1d17219d9100779f.jpg: 640x640 3 persons, 3 cars, 1 truck, 68.7ms\n",
      "Speed: 0.7ms preprocess, 68.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_829_jpg.rf.5378c70ffdef0f8e67e904614f4354d1.jpg: 640x640 4 persons, 3 trucks, 56.4ms\n",
      "Speed: 0.6ms preprocess, 56.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008337_jpg.rf.d9c52a1f5351aea9e22393c29ac2436c.jpg: 640x640 8 persons, 1 truck, 1 cup, 44.7ms\n",
      "Speed: 0.6ms preprocess, 44.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-27_jpg.rf.aebd9423b34f78792d7173acc6450290.jpg: 640x640 1 person, 2 trucks, 1 chair, 1 bed, 46.3ms\n",
      "Speed: 0.6ms preprocess, 46.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_176_jpg.rf.3b4e79118b1e2e1aaab28383d462f3ab.jpg: 640x640 1 person, 1 truck, 1 bed, 39.8ms\n",
      "Speed: 0.7ms preprocess, 39.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-300_jpg.rf.57170db9cbd4fda921dd4f10721efa34.jpg: 640x640 5 persons, 1 truck, 1 banana, 42.4ms\n",
      "Speed: 0.6ms preprocess, 42.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-134_jpg.rf.59120be62c1ba1208bbd3222fb65bfd7.jpg: 640x640 1 person, 40.5ms\n",
      "Speed: 0.6ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-813_jpg.rf.63b422efff31ad667fbb228d39e0a2eb.jpg: 640x640 2 persons, 1 truck, 2 bottles, 1 refrigerator, 91.1ms\n",
      "Speed: 0.6ms preprocess, 91.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-809_jpg.rf.3c8a20a2fb74b66621e6e9ab0aa92106.jpg: 640x640 (no detections), 63.2ms\n",
      "Speed: 0.8ms preprocess, 63.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/istockphoto-2148771609-612x612.jpg: 448x640 1 person, 56.0ms\n",
      "Speed: 1.1ms preprocess, 56.0ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-636_jpg.rf.fad86da27a46317102835ff1395b307a.jpg: 640x640 2 persons, 1 baseball bat, 45.9ms\n",
      "Speed: 0.9ms preprocess, 45.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-731-_jpg.rf.fa15eb46b12aa81e7eab1bbbfbc1f983.jpg: 640x640 2 persons, 1 tie, 41.9ms\n",
      "Speed: 0.6ms preprocess, 41.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0738_jpg.rf.467cbe79a9e488c7c8c336e19d88d0c4.jpg: 640x640 1 person, 1 motorcycle, 4 trucks, 1 elephant, 43.8ms\n",
      "Speed: 0.7ms preprocess, 43.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_000379_jpg.rf.3a55d8966c384074dcf9796a6b60e32d.jpg: 640x640 1 person, 1 umbrella, 72.9ms\n",
      "Speed: 0.7ms preprocess, 72.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (12).jpeg: 448x640 3 persons, 31.9ms\n",
      "Speed: 0.7ms preprocess, 31.9ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-682-_jpg.rf.7fa31c11b35ac8c5d57b09efcc6bebb1.jpg: 640x640 1 truck, 51.0ms\n",
      "Speed: 0.6ms preprocess, 51.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox2_mp4-74_jpg.rf.e5934c988b04332afcc78cbf926e9dd3.jpg: 640x640 3 trucks, 1 toothbrush, 59.6ms\n",
      "Speed: 1.3ms preprocess, 59.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-682_jpg.rf.a221074889b2fed3fd62246bf4774bce.jpg: 640x640 3 persons, 72.5ms\n",
      "Speed: 1.0ms preprocess, 72.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-816-_jpg.rf.4eb09507ed79cabd33624b75bf79325b.jpg: 640x640 3 persons, 1 fire hydrant, 55.9ms\n",
      "Speed: 0.7ms preprocess, 55.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-211_jpg.rf.09e6543350a247f05d10cc7852422156.jpg: 640x640 (no detections), 56.6ms\n",
      "Speed: 0.7ms preprocess, 56.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-235_jpg.rf.d74dc522af91254ee2d7fea16a61d4d6.jpg: 640x640 2 persons, 48.9ms\n",
      "Speed: 0.7ms preprocess, 48.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (30).jpeg: 256x640 5 persons, 1 backpack, 49.0ms\n",
      "Speed: 0.5ms preprocess, 49.0ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_784_jpg.rf.882564299bb5c1596ecdb26d5448f247.jpg: 640x640 3 persons, 1 truck, 50.3ms\n",
      "Speed: 0.6ms preprocess, 50.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-560_jpg.rf.d7214d49543b694fd28746215c01049c.jpg: 640x640 3 persons, 1 truck, 2 surfboards, 44.7ms\n",
      "Speed: 0.7ms preprocess, 44.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_000063_jpg.rf.de3b6f86a7cfb5a006cc81653ebe0868.jpg: 640x640 3 persons, 1 motorcycle, 44.9ms\n",
      "Speed: 0.6ms preprocess, 44.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_560_jpg.rf.371ae3c13657fb7104ef8761247fb62a.jpg: 640x640 1 truck, 1 horse, 70.0ms\n",
      "Speed: 1.0ms preprocess, 70.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-20_jpg.rf.338c2221006e74ae9139dcd7122b8ccf.jpg: 640x640 3 persons, 3 trucks, 55.8ms\n",
      "Speed: 0.8ms preprocess, 55.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-1680-_png_jpg.rf.aac88b5b6fa0becf6442572810f8cf76.jpg: 640x640 2 persons, 1 motorcycle, 1 microwave, 1 clock, 58.2ms\n",
      "Speed: 0.8ms preprocess, 58.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox5_mp4-34_jpg.rf.e0c7d0632b6b6ec9aae7b89a2b096bea.jpg: 640x640 1 bus, 3 trucks, 54.4ms\n",
      "Speed: 0.8ms preprocess, 54.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-560_jpg.rf.8f99653f70bc2287a75c70758e5a43e0.jpg: 640x640 6 persons, 1 train, 73.4ms\n",
      "Speed: 0.7ms preprocess, 73.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-573_jpg.rf.8c4e98277745cc2f09001aba21b3d4a8.jpg: 640x640 1 person, 2 trucks, 53.0ms\n",
      "Speed: 0.7ms preprocess, 53.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0985_jpg.rf.eacb646068f880279717582a587aaaf9.jpg: 640x640 4 persons, 53.5ms\n",
      "Speed: 0.8ms preprocess, 53.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2297-_png_jpg.rf.1d5b556861b3c2f1b54baa569a52cb1c.jpg: 640x640 1 train, 1 truck, 45.4ms\n",
      "Speed: 0.7ms preprocess, 45.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-334_jpg.rf.52a3caeae285d5f7e6da3bbc61c15e2d.jpg: 640x640 1 person, 1 banana, 72.3ms\n",
      "Speed: 0.8ms preprocess, 72.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-753-_jpg.rf.b63e0f4f634c86f02483ced3783fe0d3.jpg: 640x640 2 persons, 1 truck, 2 books, 57.1ms\n",
      "Speed: 1.2ms preprocess, 57.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-98_jpg.rf.d740dd74b71d71e5b4377878190090ad.jpg: 640x640 1 person, 2 bottles, 53.6ms\n",
      "Speed: 0.7ms preprocess, 53.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0345_jpg.rf.ab577506efdd8b488b66da38311af307.jpg: 640x640 2 persons, 1 microwave, 54.5ms\n",
      "Speed: 0.7ms preprocess, 54.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008526_jpg.rf.b9241d674aac7899827bcc5db9486bdc.jpg: 640x640 4 persons, 1 truck, 1 bed, 54.2ms\n",
      "Speed: 0.8ms preprocess, 54.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/YouTube-FreeStockFootage_Child-playing-with-parents-JoyLaughterHD-RQ_qqCZOkZk-720p_mp4-42_jpg.rf.eb3adf1c60e2f4b74334f3dbc1a1b88e.jpg: 640x640 1 person, 1 bus, 1 train, 1 bed, 68.9ms\n",
      "Speed: 3.1ms preprocess, 68.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-345_jpg.rf.b2890abeb446b6afe2377e3c7ae73b12.jpg: 640x640 1 person, 1 truck, 1 backpack, 2 books, 54.3ms\n",
      "Speed: 0.8ms preprocess, 54.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0738_jpg.rf.4d42af3573ee3bfa59b159381d35b80b.jpg: 640x640 1 person, 51.7ms\n",
      "Speed: 0.7ms preprocess, 51.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/img17_jpg.rf.be936e7557512db44c8435c729185e76.jpg: 640x640 2 persons, 1 stop sign, 66.8ms\n",
      "Speed: 0.8ms preprocess, 66.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-999-_jpg.rf.893965cca0e358ad7a8b1e883ec984d3.jpg: 640x640 1 person, 1 truck, 1 chair, 57.5ms\n",
      "Speed: 0.8ms preprocess, 57.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-135-_jpg.rf.618bee32c743ba48ed00129f77b8d2ec.jpg: 640x640 3 persons, 52.3ms\n",
      "Speed: 0.8ms preprocess, 52.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-165_jpg.rf.d1617980e6570fd2dc77a4579fe285ed.jpg: 640x640 1 person, 1 car, 2 trucks, 43.1ms\n",
      "Speed: 0.7ms preprocess, 43.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/londres_023_jpg.rf.b2a8348f8558e67e7e2320318d6d0f5a.jpg: 640x640 1 motorcycle, 3 trucks, 44.7ms\n",
      "Speed: 0.6ms preprocess, 44.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008526_jpg.rf.a1eb584550fe5b07c45425a258c66052.jpg: 640x640 4 persons, 1 truck, 1 cat, 1 bed, 53.2ms\n",
      "Speed: 0.7ms preprocess, 53.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_246_jpg.rf.a4ded3f10e08bb05dd6afcd9c758e91d.jpg: 640x640 4 persons, 1 truck, 46.3ms\n",
      "Speed: 0.8ms preprocess, 46.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-344_jpg.rf.b41be0bf431033cf33fa8c7a8cbe924b.jpg: 640x640 3 persons, 49.1ms\n",
      "Speed: 0.7ms preprocess, 49.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-188_jpg.rf.0cbf49b4f6fc57e16533b0e065f7cbc8.jpg: 640x640 4 persons, 1 bed, 57.4ms\n",
      "Speed: 0.7ms preprocess, 57.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-695_jpg.rf.e202bb814b78eea581ee382e8db90676.jpg: 640x640 2 persons, 50.1ms\n",
      "Speed: 0.7ms preprocess, 50.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_28_jpg.rf.1d1a1b4744f28cfff8a364f0ef451f06.jpg: 640x640 1 person, 1 car, 1 train, 1 truck, 46.6ms\n",
      "Speed: 0.6ms preprocess, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/bookstore_38_02_altavista_jpg.rf.2014a7d42d0d50e55923c9156f401037.jpg: 640x640 4 persons, 1 laptop, 51.0ms\n",
      "Speed: 0.6ms preprocess, 51.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_995_jpg.rf.373662c6eae51c30a6b2a6e78dc77403.jpg: 640x640 2 trains, 1 truck, 53.8ms\n",
      "Speed: 0.7ms preprocess, 53.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox2_mp4-74_jpg.rf.03de8daca553a69507d670f4bf0247e2.jpg: 640x640 2 persons, 1 airplane, 1 truck, 73.7ms\n",
      "Speed: 0.8ms preprocess, 73.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (42).jpeg: 640x640 7 persons, 54.6ms\n",
      "Speed: 1.2ms preprocess, 54.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1115-_jpg.rf.65aea4ef94ae0c57a90b44eb2056a940.jpg: 640x640 5 persons, 1 tie, 1 couch, 60.2ms\n",
      "Speed: 0.7ms preprocess, 60.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-246-_jpg.rf.c154f584dcea0a9d559484f0f2c14734.jpg: 640x640 1 person, 1 bus, 1 traffic light, 1 toilet, 1 toothbrush, 62.1ms\n",
      "Speed: 0.8ms preprocess, 62.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_23_jpg.rf.9ff1ffb8e92dbbe9e7f46de47d4a4562.jpg: 640x640 3 persons, 3 trucks, 1 chair, 1 potted plant, 1 book, 51.8ms\n",
      "Speed: 0.7ms preprocess, 51.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Image_1009_jpg.rf.7e8e17c1edb556205d0418d1e0a29522.jpg: 640x640 1 person, 51.5ms\n",
      "Speed: 0.7ms preprocess, 51.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0550_jpg.rf.d35ed2eaed77cca9c93f3d7c31064003.jpg: 640x640 1 book, 61.3ms\n",
      "Speed: 0.7ms preprocess, 61.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-213_jpg.rf.b4eaee4597b2e35ad11aedc5ccc1dbcd.jpg: 640x640 2 persons, 1 bus, 2 trains, 1 truck, 59.2ms\n",
      "Speed: 0.8ms preprocess, 59.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-3_jpg.rf.4bb721c44b98a568ce3c1fbb70a4edde.jpg: 640x640 2 persons, 1 car, 52.9ms\n",
      "Speed: 0.8ms preprocess, 52.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-113_jpg.rf.ca0ff2e1e2871ab3b689cd8dde311be7.jpg: 640x640 3 persons, 1 truck, 1 couch, 47.7ms\n",
      "Speed: 0.7ms preprocess, 47.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-589_jpg.rf.f15c26404164eec6ab99da19a4c127e5.jpg: 640x640 1 person, 1 book, 68.3ms\n",
      "Speed: 0.6ms preprocess, 68.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Nhh_img_141_jpg.rf.8ef07d1dae8ae9c7dfe47318d8b9c202.jpg: 640x640 3 persons, 1 skis, 1 refrigerator, 59.7ms\n",
      "Speed: 0.7ms preprocess, 59.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-69_jpg.rf.db2363bd2d668608b713c20e248158b5.jpg: 640x640 3 trucks, 45.4ms\n",
      "Speed: 0.7ms preprocess, 45.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-161_jpg.rf.eeb48446f8aa7bf427983cc229fc22c0.jpg: 640x640 7 cars, 3 trucks, 43.8ms\n",
      "Speed: 0.7ms preprocess, 43.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-376_jpg.rf.7a1d82d72bed353e5118263152e0896f.jpg: 640x640 2 persons, 1 train, 1 truck, 49.7ms\n",
      "Speed: 0.6ms preprocess, 49.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-136_jpg.rf.61f13f9398c539e73446daa76339f1dc.jpg: 640x640 1 truck, 51.2ms\n",
      "Speed: 0.7ms preprocess, 51.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0629_jpg.rf.4b0c8967670504f8469f6f0cf739ba32.jpg: 640x640 3 persons, 1 backpack, 51.0ms\n",
      "Speed: 0.7ms preprocess, 51.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-246_jpg.rf.abc5b268245a19116e3001ccbf93af2f.jpg: 640x640 2 cars, 1 bus, 48.9ms\n",
      "Speed: 0.7ms preprocess, 48.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-504_jpg.rf.7c1e0634deed1692079bcccf98f4477f.jpg: 640x640 3 persons, 1 truck, 1 bottle, 42.4ms\n",
      "Speed: 0.7ms preprocess, 42.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-855_jpg.rf.c1f7df1e079c07197ea93a64a0ac27ee.jpg: 640x640 1 car, 1 surfboard, 56.7ms\n",
      "Speed: 0.7ms preprocess, 56.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-523-_jpg.rf.ef21f97e44dd5015938e07992baeee1a.jpg: 640x640 1 person, 1 bus, 1 truck, 40.7ms\n",
      "Speed: 0.6ms preprocess, 40.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-361_jpg.rf.22ee204bd5283237a0631f328df73e69.jpg: 640x640 1 person, 1 bottle, 1 refrigerator, 1 book, 74.7ms\n",
      "Speed: 0.7ms preprocess, 74.7ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-812_jpg.rf.82eda1727affc6d6d65534e9291d4e50.jpg: 640x640 2 persons, 5 bottles, 3 laptops, 50.6ms\n",
      "Speed: 1.9ms preprocess, 50.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-89_jpg.rf.d151ceb241281718e46458bf107c6f8d.jpg: 640x640 1 person, 50.6ms\n",
      "Speed: 1.1ms preprocess, 50.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-61_jpg.rf.5d55405b33932b77ba587e16cb8ab56a.jpg: 640x640 1 person, 1 train, 61.7ms\n",
      "Speed: 0.7ms preprocess, 61.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_731_jpg.rf.d69ac3d276810e2023c03d8002185485.jpg: 640x640 2 persons, 1 truck, 1 bench, 53.0ms\n",
      "Speed: 0.8ms preprocess, 53.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-27_jpg.rf.8b326224cea34727d375d9e28fc34ffe.jpg: 640x640 1 person, 52.4ms\n",
      "Speed: 0.7ms preprocess, 52.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-213_jpg.rf.796b34b4516cfb4f1aefddbb912f01b5.jpg: 640x640 2 persons, 1 bus, 1 banana, 1 dining table, 63.7ms\n",
      "Speed: 0.8ms preprocess, 63.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-730_jpg.rf.26bec93a311351ca9c06119164ef8de5.jpg: 640x640 1 person, 1 car, 1 truck, 50.1ms\n",
      "Speed: 0.7ms preprocess, 50.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-242_jpg.rf.bb757a2589bdbb15858743a6ff9f7699.jpg: 640x640 4 persons, 69.4ms\n",
      "Speed: 0.7ms preprocess, 69.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-1_jpg.rf.c1fa056cf1040dad968c2b3a16cd484f.jpg: 640x640 1 bus, 48.1ms\n",
      "Speed: 0.7ms preprocess, 48.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-260-_jpg.rf.38b8a94a8fa7cd221af96410e046c7af.jpg: 640x640 2 persons, 1 truck, 2 traffic lights, 45.6ms\n",
      "Speed: 0.6ms preprocess, 45.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ka_00884_png_jpg.rf.5912129e6c0091ed6788779296afa957.jpg: 640x640 1 person, 42.9ms\n",
      "Speed: 0.7ms preprocess, 42.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_716_jpg.rf.09d95b35eeade4e91392ea5ca06d7595.jpg: 640x640 5 persons, 1 train, 1 truck, 60.3ms\n",
      "Speed: 0.7ms preprocess, 60.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (5).jpeg: 384x640 1 person, 33.0ms\n",
      "Speed: 0.9ms preprocess, 33.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_673_jpg.rf.6b9ad0d962abb35a825c6cc2c9faff5c.jpg: 640x640 1 fire hydrant, 1 dog, 1 toilet, 76.2ms\n",
      "Speed: 0.7ms preprocess, 76.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-641_jpg.rf.f8e9bcb9a5aba1a0fab955a47ea38760.jpg: 640x640 4 persons, 1 bus, 1 train, 1 banana, 58.8ms\n",
      "Speed: 0.8ms preprocess, 58.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/YouTube-FreeStockFootage_Child-playing-with-parents-JoyLaughterHD-RQ_qqCZOkZk-720p_mp4-42_jpg.rf.e48e1b080b1e11b2dd67076404d70931.jpg: 640x640 2 persons, 52.6ms\n",
      "Speed: 0.6ms preprocess, 52.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-79_jpg.rf.0fcc7de22dfa5f7992a47c7ff06b0d16.jpg: 640x640 13 persons, 2 chairs, 2 cell phones, 1 toothbrush, 74.9ms\n",
      "Speed: 0.7ms preprocess, 74.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005100_jpg.rf.94a94bc12f13609d6c57cbd13100dd8e.jpg: 640x640 2 persons, 52.6ms\n",
      "Speed: 0.8ms preprocess, 52.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox6_mp4-80_jpg.rf.bb5a118aef4a7d884142dfc74891d0bf.jpg: 640x640 3 persons, 1 truck, 54.7ms\n",
      "Speed: 0.7ms preprocess, 54.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/002458_jpg.rf.2d87971bcbefb5465fabce9ab5ec5967.jpg: 640x640 2 persons, 1 truck, 46.5ms\n",
      "Speed: 0.7ms preprocess, 46.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/amz_04178_png_jpg.rf.4da0ffe1b77c2dd1e122ab212d27b525.jpg: 640x640 10 persons, 1 truck, 51.7ms\n",
      "Speed: 0.7ms preprocess, 51.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_002711_jpg.rf.6fc864b0aeea496698e8d8f650729efa.jpg: 640x640 1 person, 4 cars, 1 bus, 71.9ms\n",
      "Speed: 0.6ms preprocess, 71.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-434-_jpg.rf.08f3862f335fb52c0e87c4664d373751.jpg: 640x640 3 persons, 1 train, 1 truck, 1 chair, 54.1ms\n",
      "Speed: 0.9ms preprocess, 54.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-1670-_png_jpg.rf.0463edb430019e01ec79eed27a6349d6.jpg: 640x640 2 persons, 52.9ms\n",
      "Speed: 0.7ms preprocess, 52.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/img17_jpg.rf.e2bb3045663745e2d3fc69ec11845310.jpg: 640x640 3 persons, 45.8ms\n",
      "Speed: 0.6ms preprocess, 45.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/p65621379_jpg.rf.1ab9898a2e211d13e721dd76c6a5a454.jpg: 640x640 1 train, 1 boat, 1 cake, 47.7ms\n",
      "Speed: 0.8ms preprocess, 47.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-571_jpg.rf.1b4a0e134397858a77534f7fbde4094e.jpg: 640x640 2 persons, 1 truck, 1 handbag, 66.9ms\n",
      "Speed: 0.6ms preprocess, 66.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-693-_jpg.rf.4cfbce6acfa32bcc3647cbb9eb6e4f45.jpg: 640x640 3 persons, 1 train, 1 cell phone, 1 book, 43.1ms\n",
      "Speed: 0.6ms preprocess, 43.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-534_jpg.rf.c77f4a8414ddf20fc782db49ce4ce80f.jpg: 640x640 1 person, 1 traffic light, 51.0ms\n",
      "Speed: 0.7ms preprocess, 51.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Industrial-3-Part-Skymaster-insitu_jpg.rf.b88a96ba000fc3a64bc6b952abf133cc.jpg: 640x640 2 persons, 54.3ms\n",
      "Speed: 0.7ms preprocess, 54.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-829_jpg.rf.fd67c22d0d1125efb6f0a23b0c460c77.jpg: 640x640 4 persons, 46.9ms\n",
      "Speed: 0.7ms preprocess, 46.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_721_jpg.rf.93654c7e0f2c3542b16242a703a5ebee.jpg: 640x640 3 persons, 1 train, 46.2ms\n",
      "Speed: 0.6ms preprocess, 46.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/w1240-p16x9-fa978043deff83fed485af12d16e39c61398fc30_jpg.rf.94b38eda22e01dadf9abc84c3fb975e7.jpg: 640x640 1 person, 1 truck, 1 fire hydrant, 1 bottle, 48.1ms\n",
      "Speed: 0.7ms preprocess, 48.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-821-_jpg.rf.95240607a312071bac88e151ac7950c4.jpg: 640x640 2 persons, 60.5ms\n",
      "Speed: 0.7ms preprocess, 60.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_257_jpg.rf.fd3219a7fb8439fe4f600d235ca920e5.jpg: 640x640 2 persons, 1 truck, 1 dog, 51.2ms\n",
      "Speed: 0.8ms preprocess, 51.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-813-_jpg.rf.5e884cd4df5ca5b9638ff04197fca7b5.jpg: 640x640 2 persons, 82.8ms\n",
      "Speed: 0.7ms preprocess, 82.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/01261_jpg.rf.e4057437ee374e03ad9d0faeccbdcc72.jpg: 640x640 4 persons, 1 bed, 54.1ms\n",
      "Speed: 0.7ms preprocess, 54.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-44_jpg.rf.92002390c73044c6cbf117f81e542eb6.jpg: 640x640 5 persons, 1 car, 1 truck, 62.6ms\n",
      "Speed: 0.7ms preprocess, 62.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/1288788-une-employee-aide-des-voyageurs-en-provenance-de-chine-le-26-janvier-2020-a-l-aeroport-de-roissy_jpg.rf.35ed51188a266a262a24924aa32463a0.jpg: 640x640 5 persons, 1 bicycle, 1 traffic light, 1 tie, 1 bed, 51.8ms\n",
      "Speed: 0.8ms preprocess, 51.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0449_jpg.rf.c52784087552daffc6c5f1e472955011.jpg: 640x640 1 person, 1 train, 1 umbrella, 52.2ms\n",
      "Speed: 0.7ms preprocess, 52.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-148_jpg.rf.6439627b3462df42bbf01dd91b0a27da.jpg: 640x640 2 cars, 4 trucks, 45.5ms\n",
      "Speed: 0.7ms preprocess, 45.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008652_jpg.rf.d00034b7c4abe7242379f832445178bd.jpg: 640x640 2 persons, 1 bus, 1 train, 1 truck, 1 traffic light, 43.1ms\n",
      "Speed: 0.6ms preprocess, 43.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_937_jpg.rf.2136ef2fc5b81626a2607acc627e0120.jpg: 640x640 3 persons, 2 bicycles, 1 truck, 1 boat, 48.2ms\n",
      "Speed: 0.7ms preprocess, 48.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox3_mp4-49_jpg.rf.4c81fb7708e129cbed49607d657d75d4.jpg: 640x640 2 persons, 1 car, 2 trucks, 1 bottle, 45.7ms\n",
      "Speed: 0.6ms preprocess, 45.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-161_jpg.rf.ebbf17a82bd9ded610ceda99ba217ace.jpg: 640x640 1 person, 1 truck, 49.8ms\n",
      "Speed: 0.8ms preprocess, 49.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-27_jpg.rf.388af137d979efeec7eb6bac90f3728b.jpg: 640x640 2 persons, 1 potted plant, 68.8ms\n",
      "Speed: 0.7ms preprocess, 68.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/maksssksksss795_png_jpg.rf.d3b354627736744726846a775f91d887.jpg: 640x640 4 persons, 1 car, 51.8ms\n",
      "Speed: 0.9ms preprocess, 51.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/003184_jpg.rf.e8a5cc8317ac032f832ce528240edf35.jpg: 640x640 4 persons, 1 car, 2 boats, 52.6ms\n",
      "Speed: 0.7ms preprocess, 52.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_191_jpg.rf.59271cba397d6b83766e3a41807fdf2d.jpg: 640x640 1 person, 50.0ms\n",
      "Speed: 0.7ms preprocess, 50.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/01437_jpg.rf.7839171efbe212f40b2c6ce1f3c8819b.jpg: 640x640 3 persons, 1 car, 1 truck, 58.5ms\n",
      "Speed: 1.2ms preprocess, 58.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005577_jpg.rf.6e948a65b0aa8a6128bec802e1131620.jpg: 640x640 3 persons, 1 truck, 52.7ms\n",
      "Speed: 0.8ms preprocess, 52.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-668_jpg.rf.4aa90caeca7a6635021aea2a4f3ccf13.jpg: 640x640 2 persons, 1 car, 1 tie, 1 laptop, 48.9ms\n",
      "Speed: 0.8ms preprocess, 48.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_9949-1-_mp4-24_jpg.rf.27201295f6c7e177dea5595dcf07baac.jpg: 640x640 3 persons, 90.6ms\n",
      "Speed: 0.8ms preprocess, 90.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-254_jpg.rf.a085617a9e38ff51004011a35f3ec95b.jpg: 640x640 1 car, 1 bus, 1 truck, 52.2ms\n",
      "Speed: 0.8ms preprocess, 52.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_435_jpg.rf.ea65b0ca9d098b801b88082988050c4e.jpg: 640x640 2 persons, 3 trucks, 1 suitcase, 52.1ms\n",
      "Speed: 0.7ms preprocess, 52.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ka_00884_png_jpg.rf.b2cbc7ec9bfafab8b58cdff0bdedfee9.jpg: 640x640 1 person, 1 bottle, 52.0ms\n",
      "Speed: 0.7ms preprocess, 52.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-44_jpg.rf.c4c437c06a7372f5fa6c627e99611d50.jpg: 640x640 1 person, 51.0ms\n",
      "Speed: 0.7ms preprocess, 51.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Apple-Tests-Face-ID-Feature-While-Wearing-a-Mask-Shorts_mp4-51_jpg.rf.74c8055c0e237b07789f149d71a06444.jpg: 640x640 2 persons, 2 trucks, 3 books, 46.0ms\n",
      "Speed: 0.7ms preprocess, 46.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_246_jpg.rf.a68c648c98fdb41086ba79ce0ab91e85.jpg: 640x640 2 persons, 56.6ms\n",
      "Speed: 0.7ms preprocess, 56.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-165_jpg.rf.13e8f0c11975618d318500a65f96805e.jpg: 640x640 2 persons, 1 truck, 1 tv, 54.8ms\n",
      "Speed: 0.7ms preprocess, 54.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-295_jpg.rf.043d8e22fd6b25809e103de40cb9e0e4.jpg: 640x640 1 person, 57.7ms\n",
      "Speed: 0.8ms preprocess, 57.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-29_jpg.rf.b3d72d5b8af0726c69bd9a4387dcc631.jpg: 640x640 1 person, 1 train, 1 truck, 56.8ms\n",
      "Speed: 0.7ms preprocess, 56.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-9_jpg.rf.ee7ddc04f4e0e9379b1df6e6c3777ca8.jpg: 640x640 5 persons, 43.5ms\n",
      "Speed: 0.6ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_1212_jpg.rf.834b93389dad99ebaa558080c8e4b328.jpg: 640x640 5 persons, 1 book, 67.5ms\n",
      "Speed: 0.6ms preprocess, 67.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-19_jpg.rf.6a01da119397d148788b4614bbb4207b.jpg: 640x640 1 person, 2 motorcycles, 1 handbag, 1 chair, 2 tvs, 50.8ms\n",
      "Speed: 0.6ms preprocess, 50.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2270-_png_jpg.rf.4b73cc556e91bc8c587c923e348717f9.jpg: 640x640 5 persons, 1 bus, 1 tie, 1 cell phone, 41.4ms\n",
      "Speed: 0.7ms preprocess, 41.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/amz_04178_png_jpg.rf.88d441f41b0483c66b08e900051c62e8.jpg: 640x640 3 persons, 1 boat, 42.6ms\n",
      "Speed: 0.7ms preprocess, 42.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-628_jpg.rf.3066dfbffd038ad19ac75ace3882321e.jpg: 640x640 6 persons, 1 truck, 1 cell phone, 57.5ms\n",
      "Speed: 0.7ms preprocess, 57.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/627_jpg.rf.152dc625cfce3681ec3b2b907efea26c.jpg: 640x640 3 persons, 1 train, 53.8ms\n",
      "Speed: 0.7ms preprocess, 53.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-118-_jpg.rf.5ad695976c91b0a98153249e56b202d7.jpg: 640x640 1 snowboard, 47.0ms\n",
      "Speed: 0.7ms preprocess, 47.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008629_jpg.rf.73412855b479071b5aa4da5c592b92f9.jpg: 640x640 4 persons, 1 car, 1 motorcycle, 45.9ms\n",
      "Speed: 0.7ms preprocess, 45.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-649-_jpg.rf.489dbb82d11a1199603b21cd507c75f4.jpg: 640x640 1 person, 1 car, 1 truck, 57.3ms\n",
      "Speed: 0.8ms preprocess, 57.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class5_012_jpg.rf.8f62f85be581e150ad39081778d76bd2.jpg: 640x640 2 persons, 1 truck, 1 fire hydrant, 74.4ms\n",
      "Speed: 0.8ms preprocess, 74.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/006858_jpg.rf.ac43228cb397ef00766c39531a03e4d5.jpg: 640x640 5 persons, 55.4ms\n",
      "Speed: 0.7ms preprocess, 55.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-709_jpg.rf.53c48ecb7866e3081701207f656fccc2.jpg: 640x640 3 persons, 66.1ms\n",
      "Speed: 0.8ms preprocess, 66.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_1006_jpg.rf.5e39c8122bbd1356d4a8e7d8277d89fb.jpg: 640x640 1 person, 1 truck, 50.5ms\n",
      "Speed: 0.9ms preprocess, 50.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-376_jpg.rf.13083f5db5d0a9b433f3fde9c9234854.jpg: 640x640 1 person, 1 car, 1 truck, 61.2ms\n",
      "Speed: 0.8ms preprocess, 61.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-409_jpg.rf.d70eb48869e92e3299d38a708da10fd6.jpg: 640x640 1 person, 3 trucks, 2 refrigerators, 73.0ms\n",
      "Speed: 0.6ms preprocess, 73.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1050-_jpg.rf.02208e58055900f0e9f2e8ded960c690.jpg: 640x640 1 truck, 2 toilets, 1 book, 53.4ms\n",
      "Speed: 0.7ms preprocess, 53.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_875_jpg.rf.82ae9f3b1c857b673efe63fc38fc63ad.jpg: 640x640 1 bus, 3 trucks, 52.2ms\n",
      "Speed: 0.8ms preprocess, 52.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2_jpg.rf.b6161c4d7722be0e92af7b88e8391da5.jpg: 640x640 3 persons, 48.4ms\n",
      "Speed: 0.7ms preprocess, 48.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-976-_jpg.rf.aa9cd497223593bb3d528673dbeb75f5.jpg: 640x640 2 trucks, 61.7ms\n",
      "Speed: 0.6ms preprocess, 61.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-1_jpg.rf.9e6880a33264ccea03e74b2773ed712e.jpg: 640x640 2 persons, 50.9ms\n",
      "Speed: 0.7ms preprocess, 50.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-21_jpg.rf.8d52d679afa730b1b4da0ec945fcaaa2.jpg: 640x640 6 persons, 1 remote, 42.3ms\n",
      "Speed: 0.7ms preprocess, 42.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0214_jpg.rf.9b019f9472eb1fe3abc0c60fb3369e67.jpg: 640x640 1 person, 1 truck, 40.8ms\n",
      "Speed: 0.6ms preprocess, 40.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_9949-1-_mp4-6_jpg.rf.724b80a9e2863bfa9d11c8307e518414.jpg: 640x640 1 person, 1 bicycle, 1 boat, 42.9ms\n",
      "Speed: 0.7ms preprocess, 42.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_566_jpg.rf.97e9b469fb0cd059278ff9cc8850f51b.jpg: 640x640 1 car, 1 bus, 49.7ms\n",
      "Speed: 0.6ms preprocess, 49.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-5_jpg.rf.6d957ecf12077688ccc87f61d8607ad8.jpg: 640x640 2 persons, 1 train, 1 truck, 1 fire hydrant, 1 clock, 49.0ms\n",
      "Speed: 0.6ms preprocess, 49.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-618-_jpg.rf.45e203c3c474c1f50e6c4309badfc748.jpg: 640x640 2 buss, 53.0ms\n",
      "Speed: 0.7ms preprocess, 53.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_004301_jpg.rf.f6d3387ae733775532ac78bc18756f07.jpg: 640x640 11 persons, 2 cars, 1 truck, 59.5ms\n",
      "Speed: 0.7ms preprocess, 59.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_833_jpg.rf.c8c598680e131743899f326fe3628267.jpg: 640x640 2 persons, 55.4ms\n",
      "Speed: 0.9ms preprocess, 55.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-21_jpg.rf.3742720f5b18a07792795b1692cb46ec.jpg: 640x640 2 persons, 53.9ms\n",
      "Speed: 0.8ms preprocess, 53.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-636_jpg.rf.318c65bf83a7e87d99faa6dc38982a11.jpg: 640x640 2 persons, 1 potted plant, 58.1ms\n",
      "Speed: 0.8ms preprocess, 58.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_296_jpg.rf.42613c980aa18fdbc30590a9668011a9.jpg: 640x640 1 person, 2 tvs, 48.7ms\n",
      "Speed: 1.0ms preprocess, 48.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_566_jpg.rf.4f5d3f4e6da64c3b0192d3298d4d04ed.jpg: 640x640 1 person, 2 trucks, 45.9ms\n",
      "Speed: 0.6ms preprocess, 45.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_170_jpg.rf.84419ed066dab16fde6168d5d08d2e82.jpg: 640x640 1 person, 3 trains, 90.3ms\n",
      "Speed: 0.7ms preprocess, 90.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_796_jpg.rf.ef8c514974bb1395603f1a6a17a5638e.jpg: 640x640 2 persons, 45.4ms\n",
      "Speed: 0.6ms preprocess, 45.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/img_038_jpg.rf.bb15533a376bd72bc9380db78dfcc649.jpg: 640x640 2 persons, 1 chair, 41.8ms\n",
      "Speed: 0.7ms preprocess, 41.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_647_jpg.rf.b7ec397ad10c0d25b310680991e5b619.jpg: 640x640 2 persons, 1 train, 1 truck, 49.0ms\n",
      "Speed: 0.8ms preprocess, 49.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/003184_jpg.rf.ddcabf097616516ad576f90948a0ac0f.jpg: 640x640 4 persons, 1 horse, 1 chair, 1 book, 62.0ms\n",
      "Speed: 0.7ms preprocess, 62.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-116_jpg.rf.ed1c428003f3de7b62ccf0219d4c1316.jpg: 640x640 1 person, 1 bicycle, 56.2ms\n",
      "Speed: 0.6ms preprocess, 56.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mms_00692_jpg.rf.e9bae2709866463852036216b355d28a.jpg: 640x640 8 persons, 1 fire hydrant, 1 giraffe, 50.9ms\n",
      "Speed: 0.8ms preprocess, 50.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/588_jpg.rf.41b1339bcf0dd61de82fed10cd87f2cd.jpg: 640x640 3 persons, 1 car, 65.1ms\n",
      "Speed: 0.9ms preprocess, 65.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2252-_png_jpg.rf.f1af5d3457c140c4af5f63f7ac6f79f4.jpg: 640x640 3 persons, 1 truck, 78.5ms\n",
      "Speed: 0.7ms preprocess, 78.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-166_jpg.rf.321ab14cf6825c69840e598eeb0d213d.jpg: 640x640 1 person, 1 truck, 48.1ms\n",
      "Speed: 0.9ms preprocess, 48.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-848_jpg.rf.edb70b1c78b78eb0e137fa8bd4b17575.jpg: 640x640 2 persons, 2 trucks, 57.0ms\n",
      "Speed: 0.7ms preprocess, 57.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-166_jpg.rf.df613bc7b9e5c9efeaf51be152012acd.jpg: 640x640 1 person, 1 truck, 59.3ms\n",
      "Speed: 0.7ms preprocess, 59.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-27_jpg.rf.31a8dfa029527628d7a5167f194237cd.jpg: 640x640 13 persons, 1 bicycle, 55.6ms\n",
      "Speed: 0.8ms preprocess, 55.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-391_jpg.rf.f4e10bd17cbc14d9d28a70c5e2e91150.jpg: 640x640 1 dog, 50.8ms\n",
      "Speed: 0.7ms preprocess, 50.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-5_jpg.rf.b4cab1e1d0da03a20276493660d6114a.jpg: 640x640 1 person, 1 bus, 1 truck, 68.3ms\n",
      "Speed: 0.9ms preprocess, 68.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-837_jpg.rf.1014828b1c5f9174e5dad2b8e744b86b.jpg: 640x640 8 persons, 2 cars, 55.7ms\n",
      "Speed: 0.8ms preprocess, 55.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-14_jpg.rf.77fd7a99151657fe274f08f9506927d9.jpg: 640x640 1 person, 1 cat, 45.6ms\n",
      "Speed: 0.6ms preprocess, 45.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-579_jpg.rf.0553c682a240e85b7d1367fec9da21e6.jpg: 640x640 2 persons, 1 truck, 1 cat, 73.1ms\n",
      "Speed: 0.7ms preprocess, 73.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-384_jpg.rf.b3afeb9b45c1193d7c67d95ef24dab3d.jpg: 640x640 1 person, 1 train, 1 truck, 51.3ms\n",
      "Speed: 0.7ms preprocess, 51.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_000063_jpg.rf.ac4540391143af1302719e3168371e12.jpg: 640x640 8 persons, 1 handbag, 42.5ms\n",
      "Speed: 0.8ms preprocess, 42.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-10_jpg.rf.1379c718e5cd5a6021da12fa73e6138b.jpg: 640x640 3 persons, 44.2ms\n",
      "Speed: 1.0ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-2270-_png_jpg.rf.5bbc03681c0dfcdd978be9723da2cee2.jpg: 640x640 4 persons, 1 truck, 1 tie, 56.8ms\n",
      "Speed: 0.8ms preprocess, 56.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mo-justin-mask-NoMask_mov-34_jpg.rf.62cb0c331cd8bc5de64633216f8bf022.jpg: 640x640 4 persons, 1 tie, 1 laptop, 55.7ms\n",
      "Speed: 0.8ms preprocess, 55.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-821-_jpg.rf.a04939802a615158c97664c40de41013.jpg: 640x640 1 truck, 1 bed, 41.8ms\n",
      "Speed: 0.7ms preprocess, 41.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1-_mp4-115_jpg.rf.2aa43302e55d176724bc0d99dcea9663.jpg: 640x640 (no detections), 71.0ms\n",
      "Speed: 0.6ms preprocess, 71.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-175_jpg.rf.923def3bc3a0cbe771c4f938bea6c297.jpg: 640x640 2 persons, 1 car, 2 traffic lights, 1 clock, 52.4ms\n",
      "Speed: 0.7ms preprocess, 52.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-274_jpg.rf.6bcb25893f13d04e647f79a8f7484cf1.jpg: 640x640 2 persons, 48.3ms\n",
      "Speed: 0.7ms preprocess, 48.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-619-_jpg.rf.8181765b21d618233610f2c91a6057a4.jpg: 640x640 5 persons, 1 horse, 52.3ms\n",
      "Speed: 0.8ms preprocess, 52.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (40).jpeg: 640x576 1 person, 64.4ms\n",
      "Speed: 1.0ms preprocess, 64.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 576)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0214_jpg.rf.60a3f329d3b1db0658aa045ba6a77fdc.jpg: 640x640 1 person, 1 truck, 54.3ms\n",
      "Speed: 0.7ms preprocess, 54.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-29_jpg.rf.e7e1d35bf4bfa2049c06947bcf6ef682.jpg: 640x640 3 persons, 56.6ms\n",
      "Speed: 0.7ms preprocess, 56.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_704_jpg.rf.dd50958a6a62180bb467e72956b08c78.jpg: 640x640 1 person, 1 truck, 1 bird, 50.1ms\n",
      "Speed: 0.8ms preprocess, 50.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-331-_jpg.rf.6e4ab1a9fee846e9c5516261f7b60b85.jpg: 640x640 2 persons, 46.6ms\n",
      "Speed: 0.7ms preprocess, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-300_jpg.rf.d3c699a1d7e40b695296cddeb22f4a4a.jpg: 640x640 2 persons, 1 car, 68.4ms\n",
      "Speed: 0.7ms preprocess, 68.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-0_jpg.rf.8e364de5178639165a16329b5c1b0f82.jpg: 640x640 2 persons, 1 truck, 51.8ms\n",
      "Speed: 0.7ms preprocess, 51.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-3-_mp4-162_jpg.rf.9029ca82bb02bc31a4768f0f3e3655e4.jpg: 640x640 2 persons, 1 truck, 1 book, 56.4ms\n",
      "Speed: 0.6ms preprocess, 56.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-564_jpg.rf.b7ff2445bf314eaa4fb6aedb31537f37.jpg: 640x640 4 persons, 57.7ms\n",
      "Speed: 0.7ms preprocess, 57.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_379_jpg.rf.a90539fc04296d6c7fd0364dd45e5d3b.jpg: 640x640 1 truck, 1 tie, 1 vase, 62.3ms\n",
      "Speed: 0.8ms preprocess, 62.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-165_jpg.rf.573132679269e58f0cb580a01fde37e7.jpg: 640x640 2 persons, 1 truck, 54.0ms\n",
      "Speed: 0.8ms preprocess, 54.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-9_jpg.rf.10d76da3d609f47d2f5d167300168987.jpg: 640x640 3 persons, 1 train, 1 toilet, 58.2ms\n",
      "Speed: 0.7ms preprocess, 58.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox2_mp4-74_jpg.rf.07cb844218c334c3a693d5c571ceafd9.jpg: 640x640 2 persons, 1 tie, 56.7ms\n",
      "Speed: 0.8ms preprocess, 56.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-376_jpg.rf.bb669b1ccbb511a2517b6080308046b5.jpg: 640x640 1 chair, 77.5ms\n",
      "Speed: 0.8ms preprocess, 77.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-705-_jpg.rf.b064a30b3f33dd3df26665ded88b3c60.jpg: 640x640 1 person, 2 cars, 2 trucks, 67.1ms\n",
      "Speed: 0.7ms preprocess, 67.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (33).jpeg: 448x640 1 person, 34.6ms\n",
      "Speed: 3.4ms preprocess, 34.6ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-492_jpg.rf.07887b4bb1f23685611b54f5b3861be7.jpg: 640x640 1 person, 1 surfboard, 47.3ms\n",
      "Speed: 0.6ms preprocess, 47.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/amz_01638_png_jpg.rf.fc30c65fb3c1e97e7114ecb396a1004b.jpg: 640x640 5 persons, 1 horse, 45.7ms\n",
      "Speed: 0.7ms preprocess, 45.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class1_235_jpg.rf.a87e21e5f7dd890892224da02cc1098a.jpg: 640x640 5 persons, 1 chair, 80.3ms\n",
      "Speed: 0.7ms preprocess, 80.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/002654_jpg.rf.58b18dc4b2708f4f3c2f3f743a826b99.jpg: 640x640 2 persons, 1 car, 42.1ms\n",
      "Speed: 0.7ms preprocess, 42.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008444_jpg.rf.429b802dc2a4bb0171d0b296fcb04454.jpg: 640x640 4 persons, 2 trucks, 48.1ms\n",
      "Speed: 0.6ms preprocess, 48.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-210_jpg.rf.2499564f33bc763f58c65a576f4afdd0.jpg: 640x640 1 person, 1 bus, 1 truck, 58.3ms\n",
      "Speed: 0.6ms preprocess, 58.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2_jpg.rf.90ee66d55026ceb2e487c40a501b81f8.jpg: 640x640 1 person, 1 car, 39.5ms\n",
      "Speed: 0.6ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-5_jpg.rf.24d25a0ddd253fe224539c09efabd907.jpg: 640x640 2 persons, 1 banana, 45.5ms\n",
      "Speed: 0.7ms preprocess, 45.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0873_MOV-10_jpg.rf.17b2047359e0f35293c00cb035e84035.jpg: 640x640 4 persons, 38.2ms\n",
      "Speed: 0.7ms preprocess, 38.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-165_jpg.rf.5354cc400c056d38d93601f5e246639a.jpg: 640x640 6 persons, 49.1ms\n",
      "Speed: 0.7ms preprocess, 49.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/405_jpg.rf.649a7abba334ed5db702e6a7065fb81f.jpg: 640x640 2 persons, 42.7ms\n",
      "Speed: 0.7ms preprocess, 42.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-423_jpg.rf.bf9fc0c0d995c3a68c30efecc38daf40.jpg: 640x640 1 person, 1 car, 1 truck, 47.4ms\n",
      "Speed: 0.7ms preprocess, 47.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_965_jpg.rf.32be902c417d44539c1ac160a6eaf926.jpg: 640x640 2 persons, 1 car, 1 bus, 1 truck, 80.4ms\n",
      "Speed: 0.7ms preprocess, 80.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_55_jpg.rf.d928435536170e9a2edb5094f24454ad.jpg: 640x640 1 person, 1 airplane, 55.5ms\n",
      "Speed: 0.9ms preprocess, 55.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0345_jpg.rf.68e541cd4d8c01f0f1e31ef8a0e5f9a5.jpg: 640x640 3 persons, 47.9ms\n",
      "Speed: 0.8ms preprocess, 47.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-568_jpg.rf.caa58267c551be062e5cc36918405af9.jpg: 640x640 2 persons, 53.9ms\n",
      "Speed: 0.8ms preprocess, 53.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/maksssksksss710_png_jpg.rf.c7d70b8fc7c19e60cf23d796b5194b49.jpg: 640x640 2 persons, 2 trucks, 71.1ms\n",
      "Speed: 0.9ms preprocess, 71.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5848_jpg.rf.aa5200d20d0077ac8de0eb01adda820f.jpg: 640x640 2 persons, 1 car, 1 train, 1 truck, 41.9ms\n",
      "Speed: 0.7ms preprocess, 41.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/129_jpg.rf.6ffe5c397bf302ae2bf05108d292a3f8.jpg: 640x640 1 person, 45.7ms\n",
      "Speed: 0.6ms preprocess, 45.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-30_jpg.rf.527821dcd495003327e1d90baeb2f8d3.jpg: 640x640 2 persons, 59.2ms\n",
      "Speed: 12.9ms preprocess, 59.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0871_mp4-14_jpg.rf.f15ba01608aa50381954ef8be5cc2c07.jpg: 640x640 7 persons, 1 truck, 1 bottle, 52.8ms\n",
      "Speed: 0.7ms preprocess, 52.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-175_jpg.rf.cfba3ce688aeb8f4fca66b201ab8b933.jpg: 640x640 5 persons, 2 bicycles, 1 tennis racket, 59.8ms\n",
      "Speed: 0.7ms preprocess, 59.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-502_jpg.rf.ed8e508d05b59b2d3676414522c5d94f.jpg: 640x640 5 persons, 1 giraffe, 1 potted plant, 1 refrigerator, 76.0ms\n",
      "Speed: 2.9ms preprocess, 76.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-116_jpg.rf.1bc83b2e281de5b3f15be640b02cf4cf.jpg: 640x640 3 persons, 1 tie, 1 bed, 53.3ms\n",
      "Speed: 0.6ms preprocess, 53.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_93_jpg.rf.92add6f12b5a17c292b30d081e7b9505.jpg: 640x640 1 person, 1 traffic light, 57.0ms\n",
      "Speed: 0.7ms preprocess, 57.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-534_jpg.rf.e37ccfef79303e75c180307a83f87fe2.jpg: 640x640 4 persons, 42.9ms\n",
      "Speed: 0.7ms preprocess, 42.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3103_mp4-17_jpg.rf.c5f53596221dcf72094046a2d08b6c0b.jpg: 640x640 10 persons, 1 handbag, 53.9ms\n",
      "Speed: 0.6ms preprocess, 53.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_716_jpg.rf.0cce750055b198889ee669b4a0246957.jpg: 640x640 1 person, 2 trucks, 41.9ms\n",
      "Speed: 0.7ms preprocess, 41.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5024_mp4-5_jpg.rf.d30dafa5092b6bf3be54c97d9ba8af12.jpg: 640x640 1 truck, 50.8ms\n",
      "Speed: 0.6ms preprocess, 50.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/img_037_jpg.rf.213e8a4157d9d618448c93c0326606e6.jpg: 640x640 5 persons, 1 suitcase, 43.8ms\n",
      "Speed: 0.7ms preprocess, 43.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-135_jpg.rf.ec35d9039ec826da9bc60496d2220f09.jpg: 640x640 1 person, 1 truck, 40.7ms\n",
      "Speed: 0.7ms preprocess, 40.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-185_jpg.rf.26277f4a69505170ed97b9da60fb22fc.jpg: 640x640 1 person, 5 trucks, 60.6ms\n",
      "Speed: 0.7ms preprocess, 60.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_575_jpg.rf.68c40d183d915fcd15ec4ace1e77e341.jpg: 640x640 2 persons, 1 traffic light, 1 frisbee, 46.2ms\n",
      "Speed: 0.7ms preprocess, 46.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-661_jpg.rf.b0177efa16cf7ba6922a4e938fca6d00.jpg: 640x640 2 trucks, 4 surfboards, 56.1ms\n",
      "Speed: 0.7ms preprocess, 56.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-185_jpg.rf.5f0cdc069950fef0612a420cc85778b2.jpg: 640x640 4 persons, 1 truck, 56.8ms\n",
      "Speed: 0.7ms preprocess, 56.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008382_jpg.rf.88abdb29b7db6d6218399b4adebdbe66.jpg: 640x640 1 person, 1 train, 41.1ms\n",
      "Speed: 0.7ms preprocess, 41.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2009_000063_jpg.rf.bc5d41d82310a6d4decffa753de9b2eb.jpg: 640x640 6 persons, 1 car, 63.2ms\n",
      "Speed: 0.7ms preprocess, 63.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-25_jpg.rf.c6a708cbe0bf9c7ff4dc904902fadad6.jpg: 640x640 1 truck, 1 suitcase, 2 laptops, 1 cell phone, 61.1ms\n",
      "Speed: 0.7ms preprocess, 61.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-5_jpg.rf.ae62adc4da946a9f83c961d284e9c682.jpg: 640x640 2 persons, 1 truck, 43.2ms\n",
      "Speed: 0.7ms preprocess, 43.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008364_jpg.rf.bedc4a85a4f7f5d50ebf3f3f62cf1500.jpg: 640x640 1 person, 1 train, 1 truck, 38.3ms\n",
      "Speed: 0.6ms preprocess, 38.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_0873_MOV-10_jpg.rf.14fa8d79b68f5e05ad10827bf55d7d2b.jpg: 640x640 3 persons, 60.3ms\n",
      "Speed: 0.6ms preprocess, 60.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/londres_023_jpg.rf.641b8788c23f32c17ebc1af916994b22.jpg: 640x640 1 car, 2 trucks, 48.6ms\n",
      "Speed: 0.7ms preprocess, 48.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-17_jpg.rf.6fac032fb27d942d8578e0493d5e8fd1.jpg: 640x640 1 person, 1 truck, 46.6ms\n",
      "Speed: 0.7ms preprocess, 46.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-213_jpg.rf.ef85d2ebc3d99728261d542a76cf2771.jpg: 640x640 1 truck, 1 traffic light, 46.1ms\n",
      "Speed: 0.6ms preprocess, 46.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_314_jpg.rf.9fa27d90cca210cd18e6dd6138e5d413.jpg: 640x640 (no detections), 49.5ms\n",
      "Speed: 0.7ms preprocess, 49.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/01437_jpg.rf.f026cf7ba5513aa3755d04963571a8cc.jpg: 640x640 4 persons, 74.1ms\n",
      "Speed: 0.7ms preprocess, 74.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_9949-1-_mp4-6_jpg.rf.a680f2403994b4c82fa353a5bd97e81c.jpg: 640x640 4 persons, 1 car, 51.5ms\n",
      "Speed: 0.8ms preprocess, 51.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class1_199_jpg.rf.613bff69919975a0c19a8b77c7f2b139.jpg: 640x640 4 persons, 1 tennis racket, 1 chair, 65.8ms\n",
      "Speed: 0.9ms preprocess, 65.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/helmet999863_jpg.rf.4b2aa3285cf92a59ef1032ca51f5758b.jpg: 640x640 2 persons, 1 horse, 2 refrigerators, 56.6ms\n",
      "Speed: 0.7ms preprocess, 56.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Movie-on-10-31-22-at-10_08-AM_mov-10_jpg.rf.74c78a30315920d466512661db205c5a.jpg: 640x640 3 persons, 1 train, 1 clock, 53.7ms\n",
      "Speed: 0.7ms preprocess, 53.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (3).jpeg: 448x640 (no detections), 39.5ms\n",
      "Speed: 0.8ms preprocess, 39.5ms inference, 0.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_426_jpg.rf.c89dce1cff780e9d86a5bf5f3b16459c.jpg: 640x640 1 person, 3 trucks, 56.3ms\n",
      "Speed: 0.8ms preprocess, 56.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_704_jpg.rf.9b57097ebfe61a67ed7c13df984f6991.jpg: 640x640 1 person, 2 trucks, 11 books, 51.6ms\n",
      "Speed: 0.7ms preprocess, 51.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-1670-_png_jpg.rf.7da967f9aeaa62defc36543b9e6000af.jpg: 640x640 (no detections), 57.3ms\n",
      "Speed: 0.7ms preprocess, 57.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class1_235_jpg.rf.b8c6421174b3ec692ff917bb380968e2.jpg: 640x640 1 person, 58.8ms\n",
      "Speed: 0.7ms preprocess, 58.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-682-_jpg.rf.420357ac3472a3dfe9631df6dcb809d0.jpg: 640x640 1 person, 2 tvs, 2 books, 48.1ms\n",
      "Speed: 0.6ms preprocess, 48.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-731-_jpg.rf.15548357954fc8dcbf4e316024c0fa8a.jpg: 640x640 5 persons, 1 truck, 1 surfboard, 42.9ms\n",
      "Speed: 0.6ms preprocess, 42.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (16).jpeg: 320x640 5 persons, 57.0ms\n",
      "Speed: 0.5ms preprocess, 57.0ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/smartmi-3pcs-filter-mask-pm25-haze-dustproof-mask-with-vent_jpg.rf.65cfa771ef85d3e3a5301e5ed0ccbd75.jpg: 640x640 2 persons, 41.3ms\n",
      "Speed: 0.6ms preprocess, 41.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-829_jpg.rf.85e5bd83de072b517118d5cc45694535.jpg: 640x640 3 persons, 1 truck, 48.6ms\n",
      "Speed: 0.7ms preprocess, 48.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-55_jpg.rf.4f50d4817d682aa2176809573e5f3a19.jpg: 640x640 3 persons, 63.1ms\n",
      "Speed: 0.8ms preprocess, 63.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-1975-_png_jpg.rf.cd700127b5005f75f2eaff2705c1cbb6.jpg: 640x640 3 persons, 1 car, 1 train, 66.7ms\n",
      "Speed: 0.7ms preprocess, 66.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/helmet999595_jpg.rf.3b2175a64b841eb925ff14f9388ca177.jpg: 640x640 3 persons, 1 sink, 59.0ms\n",
      "Speed: 1.3ms preprocess, 59.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-554_jpg.rf.6a371cf2476f48ed6ab0209f0a0b252d.jpg: 640x640 3 persons, 52.5ms\n",
      "Speed: 1.0ms preprocess, 52.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/airport_inside_0345_jpg.rf.0ec6de25e596ed13beec56137db2cb19.jpg: 640x640 2 trains, 1 bird, 1 dining table, 53.6ms\n",
      "Speed: 0.7ms preprocess, 53.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (11).jpeg: 416x640 2 persons, 46.1ms\n",
      "Speed: 3.9ms preprocess, 46.1ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_937_jpg.rf.4e072512d29ae92199a58d2700039e5e.jpg: 640x640 5 persons, 54.4ms\n",
      "Speed: 0.7ms preprocess, 54.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/class2_093_jpg.rf.4c9e0190598044e61fc3f2eaab39796e.jpg: 640x640 11 persons, 1 bicycle, 52.9ms\n",
      "Speed: 0.7ms preprocess, 52.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_527_jpg.rf.d77ff73555880aaa63b1577d5850168f.jpg: 640x640 8 persons, 1 truck, 70.5ms\n",
      "Speed: 0.7ms preprocess, 70.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-812_jpg.rf.0856e633437c9d132a0acd414754619d.jpg: 640x640 1 person, 1 suitcase, 2 bottles, 62.9ms\n",
      "Speed: 0.8ms preprocess, 62.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/000415_jpg.rf.6b9ff926deef3b67d6cb46c8bd2b2366.jpg: 640x640 2 persons, 57.6ms\n",
      "Speed: 0.7ms preprocess, 57.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1099-_jpg.rf.feeacd8e655f29f874d6bf1ae57cf022.jpg: 640x640 3 persons, 1 traffic light, 1 elephant, 51.7ms\n",
      "Speed: 0.7ms preprocess, 51.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/1582_jpg.rf.6dc2f84282eecbb00c4c620ae1119d36.jpg: 640x640 5 persons, 1 bicycle, 72.6ms\n",
      "Speed: 0.7ms preprocess, 72.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-21_jpg.rf.e9d5fab8ccd4722fe717c6730013fa8b.jpg: 640x640 1 person, 1 horse, 44.7ms\n",
      "Speed: 0.7ms preprocess, 44.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox4_mp4-42_jpg.rf.146b0e51a6d2ed699aba1c2f0fccc723.jpg: 640x640 5 persons, 1 airplane, 46.7ms\n",
      "Speed: 0.8ms preprocess, 46.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_678_jpg.rf.d08dc280ff6c031f30f59a759080ddf7.jpg: 640x640 7 persons, 1 tv, 66.7ms\n",
      "Speed: 0.7ms preprocess, 66.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_5024_mp4-4_jpg.rf.d5013fea721284359d4e763e53e6692e.jpg: 640x640 1 person, 1 truck, 53.2ms\n",
      "Speed: 0.7ms preprocess, 53.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ppe_0015_jpg.rf.68233b3070821208fc67118ac4427f67.jpg: 640x640 2 persons, 1 truck, 1 surfboard, 52.6ms\n",
      "Speed: 0.8ms preprocess, 52.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-165_jpg.rf.ead7fd2e172611375922872cafae99cc.jpg: 640x640 2 trucks, 79.5ms\n",
      "Speed: 3.4ms preprocess, 79.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox3_mp4-49_jpg.rf.8f4c370974dd8ccbba690d745472f76c.jpg: 640x640 5 persons, 62.0ms\n",
      "Speed: 0.7ms preprocess, 62.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_426_jpg.rf.6eb05d6561fe07b57de084e6dd4f1479.jpg: 640x640 1 person, 1 truck, 1 cell phone, 54.2ms\n",
      "Speed: 0.8ms preprocess, 54.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/004720_jpg.rf.0dcf5ce7437210bdf3d5e2f1bab5f21e.jpg: 640x640 6 persons, 1 truck, 1 bench, 50.1ms\n",
      "Speed: 0.7ms preprocess, 50.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-550_jpg.rf.0a199dbd9cdb73adb689576c257cd853.jpg: 640x640 2 persons, 1 car, 59.8ms\n",
      "Speed: 0.7ms preprocess, 59.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/autox6_mp4-20_jpg.rf.9c0e1ceb391e1bad75ca88cf9b6ba045.jpg: 640x640 4 persons, 1 truck, 50.8ms\n",
      "Speed: 0.8ms preprocess, 50.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/RPReplay_Final1667001201_MP4-370_jpg.rf.ae7d4884327cb7b0b3acdaa7d0996d53.jpg: 640x640 4 persons, 2 trucks, 55.9ms\n",
      "Speed: 0.7ms preprocess, 55.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-651_jpg.rf.ec7ce870bc5764294823e6efcf71af20.jpg: 640x640 2 persons, 1 truck, 44.5ms\n",
      "Speed: 0.7ms preprocess, 44.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-127_jpg.rf.4f38f67392fa9e1505e94f5e4ee486f3.jpg: 640x640 2 persons, 1 bus, 1 truck, 57.5ms\n",
      "Speed: 0.8ms preprocess, 57.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-809_jpg.rf.054e02a52e43e5e78988cf5ff0e012c0.jpg: 640x640 2 persons, 1 truck, 53.1ms\n",
      "Speed: 0.9ms preprocess, 53.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-362_jpg.rf.ff5eaedf860709baf22efbed1c407ca6.jpg: 640x640 1 person, 53.9ms\n",
      "Speed: 1.2ms preprocess, 53.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/images (18).jpeg: 480x640 4 persons, 1 sports ball, 51.9ms\n",
      "Speed: 0.9ms preprocess, 51.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-2-_mp4-15_jpg.rf.049ec88d34bf5522395af8c4f14696e9.jpg: 640x640 2 persons, 1 train, 1 truck, 1 refrigerator, 54.4ms\n",
      "Speed: 0.7ms preprocess, 54.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-699_jpg.rf.f3f1ac75a5f49d3f2e92c55798b10853.jpg: 640x640 2 persons, 1 truck, 41.0ms\n",
      "Speed: 0.7ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-573_jpg.rf.713c4e4f79425510b5402a432d7bb392.jpg: 640x640 3 persons, 59.3ms\n",
      "Speed: 0.7ms preprocess, 59.3ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_647_jpg.rf.a2d892f4d8679dc8ca0bbea635a777b5.jpg: 640x640 1 bottle, 54.3ms\n",
      "Speed: 0.7ms preprocess, 54.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-5-_mp4-136_jpg.rf.aeb3616a8195ab797c209691b9440b21.jpg: 640x640 1 car, 2 trucks, 2 birds, 41.4ms\n",
      "Speed: 0.6ms preprocess, 41.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_435_jpg.rf.755d9fa0771802a3b95652a9aac68093.jpg: 640x640 1 person, 1 train, 1 truck, 50.2ms\n",
      "Speed: 0.8ms preprocess, 50.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-347-_jpg.rf.f5e15e0e36d3cc7fcfbf49d68c21f121.jpg: 640x640 2 persons, 2 benchs, 62.5ms\n",
      "Speed: 1.0ms preprocess, 62.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/2008_008444_jpg.rf.f54629aa3fa51422510e7e7ac5d5f39b.jpg: 640x640 1 person, 1 truck, 61.5ms\n",
      "Speed: 0.7ms preprocess, 61.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-376_jpg.rf.bea47bff526392e49df9e9cbcc761e7d.jpg: 640x640 3 persons, 1 truck, 1 boat, 56.4ms\n",
      "Speed: 0.7ms preprocess, 56.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-24_jpg.rf.a1ad61ea42e6b66a57d801f7d0878c0e.jpg: 640x640 2 persons, 1 bench, 55.5ms\n",
      "Speed: 0.8ms preprocess, 55.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/494_jpg.rf.ea9ca8e7391f4c12e1b63c0aa31760e9.jpg: 640x640 1 person, 1 train, 2 clocks, 50.5ms\n",
      "Speed: 0.7ms preprocess, 50.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_784_jpg.rf.664db1f56143ebf30ac8aa6cc47001f0.jpg: 640x640 2 persons, 50.7ms\n",
      "Speed: 0.7ms preprocess, 50.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-57_jpg.rf.ea273bcf5a2ff4438d449ffa5a2db852.jpg: 640x640 2 persons, 1 bus, 2 trucks, 1 cell phone, 74.7ms\n",
      "Speed: 0.9ms preprocess, 74.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-260_jpg.rf.9682bc1741d7642e66d56832930de422.jpg: 640x640 2 persons, 1 skateboard, 55.3ms\n",
      "Speed: 0.7ms preprocess, 55.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-528-_jpg.rf.fda69fe0d66335b4bfa3cc37671f3a68.jpg: 640x640 1 person, 2 trucks, 1 stop sign, 44.9ms\n",
      "Speed: 0.6ms preprocess, 44.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_937_jpg.rf.d6f7ccf07ee21b93ea80e2a5f1f20c23.jpg: 640x640 1 fire hydrant, 1 bottle, 48.5ms\n",
      "Speed: 0.7ms preprocess, 48.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-242_jpg.rf.3a9e88e1fe5ea142ca0867917f4be979.jpg: 640x640 6 persons, 1 truck, 43.3ms\n",
      "Speed: 0.8ms preprocess, 43.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-693-_jpg.rf.5aea33f98fe585818017955a22f50305.jpg: 640x640 2 persons, 2 trucks, 1 fire hydrant, 1 bottle, 1 refrigerator, 45.1ms\n",
      "Speed: 0.7ms preprocess, 45.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/135e-huxwryw6451820_jpg.rf.16d8f0c3161dae2375522c763c40b1a0.jpg: 640x640 4 persons, 1 truck, 45.4ms\n",
      "Speed: 0.7ms preprocess, 45.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/istockphoto-1346124841-612x612.jpg: 448x640 1 person, 58.9ms\n",
      "Speed: 1.0ms preprocess, 58.9ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/006858_jpg.rf.c94da6aa210f1738a87f3525da7b5985.jpg: 640x640 2 persons, 1 couch, 59.7ms\n",
      "Speed: 0.6ms preprocess, 59.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-242_jpg.rf.87ad9787a533c8f99b1c899502527ce4.jpg: 640x640 1 person, 1 truck, 43.2ms\n",
      "Speed: 0.6ms preprocess, 43.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/video_CDC-YOUTUBE_mp4-60_jpg.rf.a996d64f9fab297449534660422289c1.jpg: 640x640 7 persons, 1 traffic light, 43.7ms\n",
      "Speed: 0.7ms preprocess, 43.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-645_jpg.rf.678dd020ed3048e268f7768a6df08cf8.jpg: 640x640 1 person, 1 truck, 42.3ms\n",
      "Speed: 0.6ms preprocess, 42.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/IMG_3100_mp4-2_jpg.rf.4d46f38425296af74814d1f0506575b4.jpg: 640x640 3 persons, 1 truck, 43.4ms\n",
      "Speed: 0.7ms preprocess, 43.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-573_jpg.rf.8ad2ef64817ad42a2acf4c7878ed5e60.jpg: 640x640 3 persons, 43.9ms\n",
      "Speed: 0.6ms preprocess, 43.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/maksssksksss795_png_jpg.rf.13d6bd52e2cd1552e43ff111641e7dd0.jpg: 640x640 7 persons, 1 bicycle, 45.7ms\n",
      "Speed: 11.9ms preprocess, 45.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-574_jpg.rf.3e198affe680e93fff82325572cc6972.jpg: 640x640 2 persons, 69.5ms\n",
      "Speed: 0.7ms preprocess, 69.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_181_jpg.rf.fa33f4492145e16bacd9de0c3b864274.jpg: 640x640 1 person, 56.7ms\n",
      "Speed: 0.9ms preprocess, 56.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005310_jpg.rf.83e6f0a246ede1e981765bf75cb7b067.jpg: 640x640 2 persons, 1 bicycle, 46.9ms\n",
      "Speed: 0.7ms preprocess, 46.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-60_jpg.rf.6096630b9d195556cab35b07a3890d62.jpg: 640x640 8 persons, 1 train, 1 bed, 72.6ms\n",
      "Speed: 0.7ms preprocess, 72.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/ins30_jpg.rf.4b8b181f8922dd32cb4a4148b83f2f1d.jpg: 640x640 4 persons, 50.6ms\n",
      "Speed: 0.7ms preprocess, 50.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-131_jpg.rf.87ec337892f42d6dae5c729a66b463ac.jpg: 640x640 10 persons, 1 train, 1 tie, 46.6ms\n",
      "Speed: 0.7ms preprocess, 46.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-4-_mp4-19_jpg.rf.b39073990b499b99dfe415a49fdb90bb.jpg: 640x640 2 potted plants, 1 book, 2 vases, 45.5ms\n",
      "Speed: 0.7ms preprocess, 45.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/-3394-_png_jpg.rf.67a7a1f50f9315fa6119fc9fdc104839.jpg: 640x640 (no detections), 59.3ms\n",
      "Speed: 0.6ms preprocess, 59.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mask-wearing-1632932085584_png_jpg.rf.4bf437edc7d0549c380eca13c47dbc53.jpg: 640x640 1 person, 1 car, 1 truck, 1 chair, 48.9ms\n",
      "Speed: 0.7ms preprocess, 48.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-1062-_jpg.rf.30c06a00f2aef933ecf9aaa4b95f1320.jpg: 640x640 2 persons, 1 car, 1 bus, 46.2ms\n",
      "Speed: 0.7ms preprocess, 46.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-619-_jpg.rf.dc01af03cac6c0e921cf55d5d8e8465d.jpg: 640x640 1 person, 1 truck, 45.5ms\n",
      "Speed: 0.7ms preprocess, 45.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-812_jpg.rf.c99750442be9a6d08888a8dcbb2fa62b.jpg: 640x640 3 persons, 6 bottles, 1 book, 54.6ms\n",
      "Speed: 0.7ms preprocess, 54.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_153_jpg.rf.6925fe123249e671c0df4092e9fb87a5.jpg: 640x640 5 persons, 1 tie, 49.6ms\n",
      "Speed: 0.7ms preprocess, 49.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-976-_jpg.rf.8c3de975886ffa761d4890c65691cece.jpg: 640x640 2 persons, 73.2ms\n",
      "Speed: 0.8ms preprocess, 73.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/mask-wearing-1632933572733_png_jpg.rf.283266235dfab0e959aaf3f33253a640.jpg: 640x640 2 persons, 1 truck, 1 chair, 60.7ms\n",
      "Speed: 0.7ms preprocess, 60.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_326_jpg.rf.85023ef88dd7e276c124a328c28dc9a4.jpg: 640x640 8 persons, 1 horse, 44.9ms\n",
      "Speed: 0.7ms preprocess, 44.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/construction-986-_jpg.rf.1cb591ab919d5ad35df680d527f7979a.jpg: 640x640 1 person, 43.2ms\n",
      "Speed: 0.6ms preprocess, 43.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/w1240-p16x9-fa978043deff83fed485af12d16e39c61398fc30_jpg.rf.b4efe0e35dffd0652848516363213181.jpg: 640x640 1 person, 1 car, 1 motorcycle, 1 truck, 1 dining table, 49.5ms\n",
      "Speed: 0.7ms preprocess, 49.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/Nhh_img_141_jpg.rf.1b615e2b5d479ae03e4d97708c3387f9.jpg: 640x640 1 person, 1 cup, 1 bed, 46.9ms\n",
      "Speed: 0.6ms preprocess, 46.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/image_475_jpg.rf.02bab98c288efee2ac30a3a19deab362.jpg: 640x640 1 person, 1 truck, 1 traffic light, 69.9ms\n",
      "Speed: 0.8ms preprocess, 69.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-116_jpg.rf.b6805cadcdff7c45cb410b69a73ca293.jpg: 640x640 1 person, 63.2ms\n",
      "Speed: 0.8ms preprocess, 63.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-667_jpg.rf.fe3d1eb0c1a9987687dda320249bbae1.jpg: 640x640 8 persons, 1 handbag, 68.2ms\n",
      "Speed: 0.7ms preprocess, 68.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-29_jpg.rf.7be45ddfea22f012183920e9f2dac0a6.jpg: 640x640 2 persons, 1 bus, 1 truck, 73.0ms\n",
      "Speed: 0.7ms preprocess, 73.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-639_jpg.rf.b07c4d496847b86d0e9c241be24f3231.jpg: 640x640 3 persons, 2 surfboards, 1 banana, 54.0ms\n",
      "Speed: 0.7ms preprocess, 54.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/youtube-636_jpg.rf.40924fc22b1b9bdc87b00a0d75c84da4.jpg: 640x640 2 persons, 1 bottle, 45.3ms\n",
      "Speed: 0.7ms preprocess, 45.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/fatimatatanda/Library/CloudStorage/OneDrive-Personal/Desktop/USD/Projects/aai-501-final-project/datasets/raw_images/005310_jpg.rf.3fadf8fa69fb354db06bed4e42142276.jpg: 640x640 1 person, 1 bus, 1 truck, 52.1ms\n",
      "Speed: 0.7ms preprocess, 52.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Annotation completed and dataset organized into train, validation, and test directories.\n"
     ]
    }
   ],
   "source": [
    "# load YOLOv8 pre-trained model\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# define augmentation pipeline\n",
    "augmentation = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Normalize(mean=(0, 0, 0), std=(1, 1, 1)),  # No change to pixel values\n",
    "    ToTensorV2()  # convert to PyTorch tensor \n",
    "], bbox_params=A.BboxParams(format='yolo', label_fields=['labels']))\n",
    "\n",
    "# define function to annotate and process images\n",
    "def annotate_images(df, split, image_dirs, label_dirs, confidence_threshold=0.5):\n",
    "    data = []\n",
    "    split_df = df[df[\"split\"] == split]\n",
    "    for _, row in split_df.iterrows():\n",
    "        image_file = row[\"filename\"]\n",
    "        # load the image\n",
    "        image_path = os.path.join(source_image_dir, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # perform inference using YOLOv8\n",
    "        results = model(image_path)\n",
    "\n",
    "        # extract bounding boxes and labels\n",
    "        bboxes = []\n",
    "        labels = []\n",
    "        for result in results[0].boxes:\n",
    "            box = result.xywhn[0].cpu().numpy()  # Normalized x_center, y_center, width, height\n",
    "            class_id = int(result.cls[0].cpu().numpy())\n",
    "            confidence = float(result.conf[0].cpu().numpy())\n",
    "\n",
    "            # filter by confidence threshold\n",
    "            if confidence >= confidence_threshold:\n",
    "                bboxes.append(box.tolist())\n",
    "                labels.append(class_id)\n",
    "\n",
    "                # add annotation details to the df list\n",
    "                data.append({\n",
    "                    \"filename\": image_file,\n",
    "                    \"split\": split,\n",
    "                    \"class_id\": class_id,\n",
    "                    \"confidence\": confidence,\n",
    "                    \"x_center\": box[0],\n",
    "                    \"y_center\": box[1],\n",
    "                    \"width\": box[2],\n",
    "                    \"height\": box[3],\n",
    "                })\n",
    "\n",
    "        # apply augmentation\n",
    "        if bboxes:  # Only augment if there are bounding boxes\n",
    "            augmented = augmentation(image=image, bboxes=bboxes, labels=labels)\n",
    "            image = augmented[\"image\"]\n",
    "            bboxes = augmented[\"bboxes\"]\n",
    "            labels = augmented[\"labels\"]\n",
    "\n",
    "        # convert to numpy format for saving \n",
    "        if isinstance(image, torch.Tensor):  # If tensor, convert to numpy for opencv\n",
    "            image = image.permute(1, 2, 0).cpu().numpy() # changes the order of the tensor dimensions from (C, H, W) (Channel-Height-Width, common in PyTorch) to (H, W, C) (Height-Width-Channel, required by OpenCV and most image libraries).\n",
    "            image = (image * 255).astype(np.uint8)  # Convert to uint8 for OpenCV\n",
    "\n",
    "        # save the image to the appropriate directory\n",
    "        output_image_path = os.path.join(image_dirs[split], image_file)\n",
    "        cv2.imwrite(output_image_path, image)\n",
    "\n",
    "        # set YOLO format labels\n",
    "        label_file = os.path.splitext(image_file)[0] + \".txt\"\n",
    "        label_path = os.path.join(label_dirs[split], label_file)\n",
    "\n",
    "        # create YOLO format label for the corresponding image\n",
    "        with open(label_path, \"w\") as f:\n",
    "            for bbox, class_id in zip(bboxes, labels):\n",
    "                # Write each valid detection to the file in YOLO format\n",
    "                f.write(f\"{class_id} {bbox[0]:.6f} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f}\\n\")\n",
    "\n",
    "    return data\n",
    "# annotate and process images for all splits\n",
    "annotation_data = []\n",
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    # append each list to annotation data\n",
    "    annotation_data.extend(annotate_images(df, split, image_dirs, label_dirs, confidence_threshold=0.5))\n",
    "\n",
    "\n",
    "print(\"Annotation completed and dataset organized into train, validation, and test directories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>split</th>\n",
       "      <th>class_id</th>\n",
       "      <th>confidence</th>\n",
       "      <th>x_center</th>\n",
       "      <th>y_center</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG_0871_MOV-39_jpg.rf.41a6a9b70c2a41fa45e3960...</td>\n",
       "      <td>train</td>\n",
       "      <td>7</td>\n",
       "      <td>0.734379</td>\n",
       "      <td>0.523683</td>\n",
       "      <td>0.663333</td>\n",
       "      <td>0.118504</td>\n",
       "      <td>0.105876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004720_jpg.rf.afc486560a4004c7cfd67910af31a29c...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.743985</td>\n",
       "      <td>0.204548</td>\n",
       "      <td>0.387022</td>\n",
       "      <td>0.275569</td>\n",
       "      <td>0.277825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004720_jpg.rf.afc486560a4004c7cfd67910af31a29c...</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>0.689993</td>\n",
       "      <td>0.369293</td>\n",
       "      <td>0.614387</td>\n",
       "      <td>0.054831</td>\n",
       "      <td>0.048369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004720_jpg.rf.afc486560a4004c7cfd67910af31a29c...</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>0.587490</td>\n",
       "      <td>0.519868</td>\n",
       "      <td>0.616981</td>\n",
       "      <td>0.059734</td>\n",
       "      <td>0.045449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004720_jpg.rf.afc486560a4004c7cfd67910af31a29c...</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>0.581372</td>\n",
       "      <td>0.617744</td>\n",
       "      <td>0.605309</td>\n",
       "      <td>0.067972</td>\n",
       "      <td>0.064742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  split  class_id  \\\n",
       "0  IMG_0871_MOV-39_jpg.rf.41a6a9b70c2a41fa45e3960...  train         7   \n",
       "1  004720_jpg.rf.afc486560a4004c7cfd67910af31a29c...  train         0   \n",
       "2  004720_jpg.rf.afc486560a4004c7cfd67910af31a29c...  train         2   \n",
       "3  004720_jpg.rf.afc486560a4004c7cfd67910af31a29c...  train         2   \n",
       "4  004720_jpg.rf.afc486560a4004c7cfd67910af31a29c...  train         2   \n",
       "\n",
       "   confidence  x_center  y_center     width    height  \n",
       "0    0.734379  0.523683  0.663333  0.118504  0.105876  \n",
       "1    0.743985  0.204548  0.387022  0.275569  0.277825  \n",
       "2    0.689993  0.369293  0.614387  0.054831  0.048369  \n",
       "3    0.587490  0.519868  0.616981  0.059734  0.045449  \n",
       "4    0.581372  0.617744  0.605309  0.067972  0.064742  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_df = pd.DataFrame(annotation_data)\n",
    "annotation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
